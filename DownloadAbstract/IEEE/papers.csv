id,title,abstract,date
8512311,Quantitative Assessment of Syllabic Timing Deficits in Ataxic Dysarthria,"Parametric analysis of Cerebellar Dysarthria (CD) may be valuable and more informative compared to its clinical assessment. A quantifiable estimation of the timing deficits in repeated syllabic utterance is described in the current study. Thirty-five individuals were diagnosed with cerebellar ataxia to varying degrees and twenty-six age-matched healthy controls were recruited. To automatically detect the local maxima of each syllable in the recorded speech files, a topographic prominence incorporated concept is designed. Subsequently, four acoustic features and eight corresponding parametric measurements are extracted to identify articulatory deficits in ataxic dysarthria. A comparative study on the behaviour of these measures for dysarthric and non-dysarthric subjects is presented in this paper. The results are further explored using a dimensionreduction tool (Principal Component Analysis) to emphasize variation and bring out the strongest discriminating patterns in our feature dataset.",28-Oct-18
10781716,Non-invasive stroke diagnosis using speech data from dysarthria patients,"Acute Ischemic Stroke (AIS) is a major cause of disability and can lead to death in severe cases. A common symptom of AIS, dysarthria, significantly impacts the quality of life of patients. In this study, we developed a deep learning model using dysarthria data for cost-effective and non-invasive brain stroke diagnosis. We utilized models such as ResNet50, InceptionV4, ResNeXt50, SEResNeXt18, and AttResNet50 to effectively extract and classify speech features indicative of stroke symptoms. These models demonstrated high performance, with Sensitivity, Specificity, Precision, Accuracy, and F1-score values reaching 96.77%, 96.08%, 92.82%, 95.52%, and 93.82%, respectively. Our approach offers a non-invasive, cost-effective alternative for early stroke detection, with potential for further accuracy improvements through additional research. This method promises rapid, economical early diagnosis, which could positively impact long-term treatment and healthcare options.",17-Dec-24
10800228,Fine-Tuning Pre-Trained Audio Models for Dysarthria Severity Classification: A Second Place Solution in the Multimodal Dysarthria Severity Classification Challenge,"Dysarthria, a neurological disorder affecting speech, poses significant challenges for automatic diagnosis and severity classification due to its complexity and the scarcity of relevant datasets. This study addresses these challenges by leveraging the dataset provided by the ISCSLP 2024 Multimodal Dysarthria Severity Classification Challenge. Our approach primarily involves two key steps: splitting the training set into training and validation subsets, and fine-tuning pre-trained au-dio models to adapt them to the task. To ensure robust evaluation and prevent label leakage, we employed the StratifiedGroupKFold function from sklearn for dataset splitting, ensuring that training and validation sets do not share participants. This method allowed us to maintain consistent statistical distributions across folds. For model finetuning, we selected two pre-trained audio models, w2v-bert-2.0 and whisper-Iarge-v3, and fine-tuned them on different folds of the dataset. Our results indicate that the w2v-bert-2.0 model fine-tuned on fold-2 achieved the highest performance, with a validation Fl-score of 0.699 and an online score of 7.7452. The experimental results, including confusion matrices and embedding distributions, highlight the model's ability to distinguish between different severity levels of dysarthria. Our approach achieved a commendable second place in the competition¡¯ demonstrating the effectiveness of fine-tuning pre-trained audio models for this task. Future work will explore the integration of multimodal data and multi-task learning strategies to further enhance model performance.",23-Dec-24
10307923,Automated Detection and Severity Assessment of Dysarthria using Raw Speech,"Dysarthria is a medical condition that impairs an individual¡¯s ability to speak clearly due to muscle weakness or paralysis. To diagnose and monitor dysarthria severity, this article proposes the use of a deep learning model that utilizes raw speech waveforms. This approach eliminates the need for feature engineering and enhances the model¡¯s ability to handle noise and speech variability. The proposed system was compared to a standard convolutional neural network (CNN) model and was found to perform better in both dysarthria severity classification and dysarthria/healthy control classification tasks. The results indicate that the SincNet model achieved an accuracy of 95.7% and 99.6% in these tasks, respectively. The proposed system can aid clinicians in diagnosing and monitoring dysarthria severity and could have broader applications in speech-related disorders. The study emphasizes the importance of using raw waveform-based models for speech analysis and demonstrates the effectiveness of SincNet in automatic dysarthria/healthy control classification and dysarthria severity assessment.",23-Nov-23
6936631,Investigation on articulatory and acoustic characteristics of dysarthria,"Direct measurement of articulation contributes to figure out the mechanism of dysarthric speech production accurately, comparing to analyzing acoustic signal alone. This study makes a statistical comparison between dysarthric and normal speech, and investigates and analyzes dysarthric characteristics based on articulatory and acoustic data of continuous English utterance. The distribution of the articulatory point is calculated for each vowel, where the vowels show a relatively smaller region for dysarthria than for normal speech. This implies that the speakers with dysarthria may have some difficulties to fully use the articulatory space as the speakers without dysarthria. The rhythm and sound source are analyzed using autocorrelation function, power spectrum and linear prediction coding. The results reveal that the speakers without dysarthria can keep steady rhythm and energy in uttering consonant-vowel repetition sequences but it is hard for the speakers with dysarthria to maintain the stability. Meanwhile, the dysarthric sound source shows unstable period of the fundamental frequency, which reflects that the speakers with dysarthria could not control the glottis movement well.",27-Oct-14
10550236,Evolving Diagnostic Techniques for Speech Disorders: Investigating Dysarthria Classification Through DenseNet201 CNN Framework,"The primary subject of this research work pertains to dysarthria, a prevalent speech impairment observed in individuals diagnosed with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Prompt detection of dysarthria is essential for effective therapies and improved patient results, as it significantly impacts communication proficiency. The research employed a DenseNet201 Convolutional Neural Network (CNN) to categorize speech using the TORGO database, which has 2000 samples of individuals with and without dysarthria, representing various genders. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each dataset consists of 500 samples, which were collected during distinct sessions. The DenseNet201 convolutional neural network (CNN) technique has a notable accuracy rate of 96% in distinguishing between cases of dysarthria and non-dysarthria. This outcome underscores the potential of deep learning technology in aiding the timely identification of dysarthria and facilitating fast interventions for affected individuals. This work provides valuable insights on the progress of diagnostic capabilities and offers a potential avenue for enhancing the well-being of those experiencing speech impairments.",11-Jun-24
10902941,Analysis of Features for Dysarthria Severity Classification from Speech,"Dysarthria is a disorder that affects the ability of an individual to speak clearly. Diagnosis of the severity of dysarthria can aid in providing appropriate therapy to the individual. Therefore, the current work focuses on identifying features that can be used to estimate the severity of dysarthria. In this regard, two feature sets are considered, namely DisVoice and OpenSMILE, and the genetic algorithm is used to identify the most suitable list of features from both feature sets using 3 speech corpora, namely SSN-TDSC, Torgo, and UA Speech corpora. In order to test the effectiveness of these features, classifiers are trained on each feature set as a whole and on the features identified by the genetic algorithm, and their performance compared. It is observed that articulatory and prosodic features are most important in the diagnosis of severity of dysarthria. A maximum accuracy of 85% is obtained with the shortlisted DisVoice features and 97% with the OpenSMILE features.",5-Mar-25
10800159,Multi-Modal Dysarthria Severity Assessment Using Dual-Branch Feature Decoupling Network and Mixed Expert Framework,"Dysarthria, a motor speech disorder resulting from neurological damage, significantly impairs an individual's ability to articulate words. Assessing the severity of dysarthria is crucial for effective therapeutic interventions and rehabilitation strategies. However, current methods are time-consuming and subjective, leading to potential inconsistencies. This study proposed a dual-branch feature decoupling network and mixed expert framework for the automatic diagnosis and assessment of dysarthria. The proposed hybrid network architecture integrates a ResNet-based branch for audio data with an attention module and a 3D ResNet branch for video data, and was evaluated on the Multimodal Dysarthria Severity Assessment Challenge (MDSA) dataset, achieving significant performance improvements and ranking first in the challenge with a best score of 8.7404. The study's findings highlight the efficacy of the proposed framework in capturing essential features from multimodal data, contributing to more accurate and reliable assessments of dysarthria.",23-Dec-24
10448175,Spectral Analysis of Vowels and Fricatives at Varied Levels of Dysarthria Severity for Amyotrophic Lateral Sclerosis,"Dysarthria due to Amyotrophic Lateral Sclerosis (ALS) affects the acoustic characteristics of different speech sounds. The effects intensify with increasing severity leading to the collapse of the acoustic space of the affected individuals. With an aim to characterize such changes in the acoustic space, this paper studies the variations in band-specific and full-band spectral properties of 4 sustained vowels (/a/, /i/, /o/, /u/) and 3 sustained fricatives (/s/, /sh/, /f/) at different dysarthria severity levels. Effect of dysarthria on spectral features of these phonemes are not well explored. Statistical comparison of these features among different severities for the phonemes considered and among different vowels/fricatives for every severity level using speech data from 119 ALS and 40 healthy subjects indicate the followings. Though all band-specific and full-band features of the three fricatives and most of those features for the four vowels become statistically similar at high severity levels, certain features remain distinguishable. Spectral differences in 0-2 kHz band between /a/ and the other vowels and in the 2-6 kHz band between /a/ and /o/, /u/ persist through all severity levels. Moreover, properties of /f/ remain mostly unchanged with increasing dysarthria severity levels.",18-Mar-24
10673651,Advancing Speech Disorder Diagnostics: A Comprehensive Study on Dysarthria Classification with CNN,"This study article focuses on dysarthria, a speech problem that is often seen in patients with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early identification of dysarthria is crucial for successful treatments and better patient outcomes, since it has a substantial influence on communication ability. Using the TORGO database, which consists of 2000 samples of persons with and without dysarthria, spanning different genders, the research use a Convolutional Neural Network (CNN) to classify speech. The dataset includes both dysarthric and non-dysarthric individuals of both genders, with 500 samples each, captured during separate sessions. The CNN-based technique demonstrates an impressive 96% accuracy in differentiating between dysarthric and non-dysarthric instances, highlighting the promise of deep learning technology in assisting with the early detection of dysarthria and enabling prompt therapies for afflicted people. This study makes significant contributions to the advancement of diagnostic capacities and presents a potential opportunity to improve the quality of life for those with speech difficulties.",18-Sep-24
10581063,Progressing Speech Disorder Identification: A Thorough Investigation into Dysarthria Categorization Utilizing ResNet50 CNN,"The speech issue of dysarthria, which is frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS), is the subject of this research article. Timely detection of dysarthria is essential for effective interventions and improved patient results, as it significantly impacts communication proficiency. The study employs the TORGO database, which has 2000 samples of individuals with and without dysarthria, encompassing various genders. The researchers utilize a ResNet50 Convolutional Neural Network (CNN) to categorize speech. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each group consists of 500 samples, which were recorded over distinct sessions. The CNN-based technique achieves a remarkable 96% accuracy in distinguishing between dysarthric and non-dysarthric instances. This underscores the potential of deep learning technology in aiding the early identification of dysarthria and facilitating timely treatments for affected individuals. This study provides valuable contributions to the enhancement of diagnostic capabilities and offers a potential avenue for enhancing the quality of life for individuals experiencing speech impairments.",12-Jul-24
10625627,Enhancing the Diagnosis of Speech Disorders: An In-Depth Investigation into Dysarthria Classification Using the ResNet18 Model,"This research article concentrates on dysarthria, a speech impediment commonly observed in individuals with conditions such as cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective interventions and improved patient outcomes, as it significantly impacts communication abilities. Employing the TORGO database, comprising 2000 samples from individuals with and without dysarthria, encompassing diverse genders, the study utilizes a Convolutional Neural Network (ResNet18 Model) for speech classification. The dataset encompasses both dysarthric and non-dysarthric subjects of both genders, with 500 samples each, recorded in separate sessions. The ResNet18 Model-based approach demonstrates an impressive 96% accuracy in distinguishing between dysarthric and non-dysarthric instances, underscoring the potential of deep learning technology in aiding early dysarthria detection and facilitating timely interventions. This investigation significantly contributes to advancing diagnostic capabilities and presents a promising avenue to enhance the quality of life for individuals grappling with speech difficulties.",22-Aug-24
10095366,Statistical Analysis of Speech Disorder Specific Features to Characterise Dysarthria Severity Level,"Poor coordination of the speech production subsystems due to any neurological injury or a neuro-degenerative disease leads to dysarthria, a neuro-motor speech disorder. Dysarthric speech impairments can be mapped to the deficits caused in phonation, articulation, prosody, and glottal functioning. With the aim of reducing the subjectivity in clinical evaluations, many automated systems are proposed in the literature to assess the dysarthria severity level using these features. This work aims to analyse the suitability of these features in determining the severity level. A detailed investigation is done to rank these features for their efficacy in modelling the pathological aspects of dysarthric speech, using the technique of paraconsistent feature engineering. The study used two dysarthric speech databases, UA-Speech and TORGO. It puts light into the fact that both the prosody and articulation features are best useful for dysarthria severity estimation, which was supported by the classification accuracies obtained on using different machine learning classifiers.",5-May-23
8251336,Identification of Cerebellar Dysarthria with SISO Characterisation,"Quantitative identification of dysarthria plays a major role in the classification of its severity. This paper quantitatively analyses several components of cerebellar dysarthria. The methodology described in this study will be extended to other types of dysarthria via systematic analysis. The speech production model is characterized as a second-order singleinput and single-output (SISO), linear, time-invariant (LTI) system in our study. A comparative study on the behavior of the damping ratio and resonant frequency for dysarthric and non-dysarthric subjects is presented. The results are further analyzed using the Principal component analysis (PCA) technique to emphasize the variation and uncover strong patterns in the selected features. The effects of some other related factors like decay time and Q-factor are also highlighted.",11-Jan-18
10739183,CNN-Driven Innovations in Dysarthria Classification and Speech Disorder Management,"This research article addresses dysarthria, a speech disorder frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective treatment and improved patient outcomes, as it significantly impacts communication abilities. Utilizing the TORGO database, which comprises 2000 speech samples from both dysarthric and non-dysarthric individuals across various genders, this study employs a Convolutional Neural Network (CNN) for classification. The dataset includes 500 samples each from both groups, collected in different sessions. The CNN approach achieves an impressive 96% accuracy in distinguishing dysarthric from non-dysarthric speech, showcasing the potential of deep learning technology in facilitating early dysarthria diagnosis and enabling timely interventions. This study makes substantial contributions to enhancing diagnostic capabilities and offers a promising avenue for improving the quality of life for individuals with speech disorders.",4-Nov-24
10800051,Constant Q Transform for Audio-Visual Dysarthria Severity Assessment,"This paper describes an automatic dysarthria severity assessment system submitted for the MDSA2024 challenge. The system utilizes audio and visual features to classify the severity of dysarthria. We investigate the effectiveness of different acoustic feature combinations, such as Mel spectrogram, filterbank and constant Q transform. Different encoders for audio data processing are compared in the experiments. The results demonstrate that the Conformer encoder achieves superior performance compared to the Densenet encoder on pure audio features. We further explore model-level fusion by combining audio and visual embeddings, leading to improvements in precision¡¯ recall, and accuracy metrics. The best-achieved score on the test set is 7.5579, with an individual F1-score of 0.7028. The findings suggest that the proposed system with Conformer encoder and model-level fusion holds promise for automatic dysarthria assessment.",23-Dec-24
10781584,Dysarthria Detection with Deep Representation Learning for Patients with Parkinson¡¯s Disease,"Dysarthria is a very common motor speech symptom in Parkinson¡¯s disease impairing normal communications of patients. Detection of dysarthria could assist clinical diagnosis and intervention of Parkinson¡¯s disease, provide monitoring approach for treatment-related side effects, and lead to effective speech therapy to prevent further communication and social deficits. Applying machine learning techniques to speech analysis for patients offers more resource-efficient, accessible and objective tools for screening and assessment of dysarthria. In this study, we constructed a multi-task speech dataset recorded from 600 participants with high data diversity to facilitate the development of detection models. We established a remote data acquisition and end-to-end prediction pipeline with deep representation learning, compared the performance with different feature-based learning and classification methods, and achieved a superior accuracy of over 90%. Different affecting factors were analyzed for model performance. Our proposed framework demonstrates the potential of developing and deploying an automated self-monitoring approach of dysarthria for patients with Parkinson¡¯s disease, which could benefit a large-scale population and their disease managements.",17-Dec-24
7953122,Automatic assessment of dysarthria severity level using audio descriptors,"Dysarthria is a motor speech impairment, often characterized by speech that is generally indiscernible by human listeners. Assessment of the severity level of dysarthria provides an understanding of the patient's progression in the underlying cause and is essential for planning therapy, as well as improving automatic dysarthric speech recognition. In this paper, we propose a non-linguistic manner of automatic assessment of severity levels using audio descriptors or a set of features traditionally used to define timbre of musical instruments and have been modified to suit this purpose. Multitapered spectral estimation based features were computed and used for classification, in addition to the audio descriptors for timbre. An Artificial Neural Network (ANN) was trained to classify speech into various severity levels within Universal Access dysarthric speech corpus and the TORGO database. An average classification accuracy of 96.44% and 98.7% was obtained for UA speech corpus and TORGO database respectively.",19-Jun-17
9287741,Automated Dysarthria Severity Classification Using Deep Learning Frameworks,"Dysarthria is a neuro-motor speech disorder that renders speech unintelligible, in proportional to its severity. Assessing the severity level of dysarthria, apart from being a diagnostic step to evaluate the patient's improvement, is also capable of aiding automatic dysarthric speech recognition systems. In this paper, a detailed study on dysarthia severity classification using various deep learning architectural choices, namely deep neural network (DNN), convolutional neural network (CNN) and long short-term memory network (LSTM) is carried out. Mel frequency cepstral coefficients (MFCCs) and its derivatives are used as features. Performance of these models are compared with a baseline support vector machine (SVM) classifier using the UA-Speech corpus and the TORGO database. The highest classification accuracy of 96.18% and 93.24% are reported for TORGO and UA-Speech respectively. Detailed analysis on performance of these models shows that a proper choice of a deep learning architecture can ensure better performance than the conventionally used SVM classifier.",18-Dec-20
10584052,Deep Learning Based Speech Recognition for Hyperkinetic Dysarthria Disorder,"Speech recognition is a technology that aims to transform human speech into text and has applications in a variety of fields, including information technology, healthcare, automobiles, and others. This research explores the advantages of employing deep learning methods to provide individualized assistance technology solutions for people with dysarthria. We proposed a Convolutional Temporal Bidirectional Network (CTBNet) model for translating Russian Hyperkinetic Dysarthria Disorder (RHDD) speech into text. CTBNet encodes input audio features using 1D convolution layers, and BidirectionalGRU (Bi-GRU) layers. The encoder effectively captures both short-term and long-term spatial temporal information. More importantly, CTBNet includes with an attention-CTC decoder, that is responsible for producing output texts. We utilized a dataset of 2797 recordings of RHDD speech, with a cumulative recorded duration of 2 hours and 33 minutes, for training purposes. The CTBNet model has achieved a 15% Character Error Rate (CER) and a 59% Word Error Rate (WER) on the dataset proposed. Our experimental findings show superior performance compared to state-of-the-art models, namely, 3xCNN, and 3xLSTM, when evaluated on the same dataset.",9-Jul-24
10805075,Developing a Hyperkinetic Dysarthria Speech Classification System using Residual Learning,"Hyperkinetic dysarthria abnormalities are exceedingly widespread across the worldwide populace. One of the most effective methodologies for disordered audio speech identification is classical deep learning technique. However, the efficiency of classification is impacted by the limitations imposed by the quality of the training dataset, such as expense and limited resources, data imbalance, and data annotation difficulties. Accordingly, we suggest implementing a residual learning framework (ResN et architecture) with various conditions and hyperparameters (batch size and learning rate) that improve the training process of deeper networks compared to earlier approaches. Pre-emphasis, windowing, and lifting techniques are applied to improve the quality of Mel-Frequency Cepstral Coefficients. In addition, we have introduced the hyperkinetic dysarthria speech dataset in the Russian language, consisting of 4 hours and 4 minutes of recorded speech. The empirical findings demonstrate that ResNet40 has an overall validation accuracy of 86.7%, surpassing other research models. It is anticipated that it will be recognized as an alternative diagnostic instrument for physicians in the future as research continues to progress.",25-Dec-24
10889800,Multilingual Speaker-Invariant Dysarthria Severity Assessment Using Adversarial Domain Adaptation and Self-Supervised Learning,"Traditional assessments for dysarthria are subjective and time-consuming, highlighting the need for automated, objective approaches that can be scaled for remote and resource-constrained environments. This paper introduces an adversarial domain adaptation framework tailored for dysarthria severity assessment, addressing the challenges of high intra-class variability and limited availability of dysarthric speech data. By framing speaker variability as a domain adaptation problem, we utilise an adversarially trained feature extractor to derive speaker-invariant yet discriminatively powerful representations utilising speech features learned through self-supervised learning. Experiments on previously unseen and diverse speakers reveal that the proposed approach yields a 7.86% average improvement across multilingual datasets compared to traditional severity-discriminative training, outperforming competitive baselines by 12.33% on average. Additionally, the method inherently supports privacy-preserving applications by minimising reliance on speaker-specific information. The results demonstrate strong alignment with clinical assessments, reinforcing our model¡¯s clinical relevance and effectiveness.",7-Mar-25
10929844,AI-Enabled Speech Monitoring for Dysarthria Detection in Consumer Electronics,"Speech is essential in human communication, and recent advancements in artificial intelligence (AI) have enabled new applications for voice data, particularly in health monitoring. Building on this progress, a home-based health detection system that utilizes voice signals provides an accessible method for users to independently identify and respond to conditions such as dysarthria, without the need for hospital or clinic visits. In this study, we developed and evaluated convolutional neural network (CNN) models to classify audio data from both healthy individuals and individuals with dysarthria. The dataset comprised command-based speech samples, which were segmented into sentence-specific input. Preprocessing steps included segmentation, downsampling, and feature extraction tailored for CNN input. The models exhibited high potential in distinguishing between normal and dysarthric states, with the most effective model achieving an f1-score of 96.18¡À4.7% and an accuracy of 96.01¡À5.02%. Furthermore, sentence structure and composition significantly influenced model performance, with specific sentences demonstrating higher classification accuracy. These findings suggest that AI-driven speech analysis may support detecting and managing specific health conditions in non-clinical environments. However, further work is needed to address data imbalance and sentence variability limitations. Future research could expand on real-world applications, particularly in settings with limited traditional health monitoring.",26-Mar-25
10848959,Dysarthria Severity Classification Using Phase Based Features of LP Residual,"Classifying the severity of speech impairment due to dysarthria is crucial for optimizing care and enhancing communication abilities for affected individuals. This study explores the use of the Modified Group Delay Function (MGDF) of LP residual signal in classifying dysarthria severity-levels. Evaluations were conducted using standard UA-Speech and TORGO datasets. A stratified Convolutional Neural Network (CNN) with 5-fold cross-validation validated the results. Baseline features included Linear Frequency Cepstral Coefficients (LFCC), Mel Frequency Cepstral Coefficients (MFCC), and Whisper module. Key performance evaluation metrics were accuracy, precision, recall, and F1-score. Finally, the latency period was analyzed for practical deployment of the system, system¡¯s ability to accurately recognize and process speech from any speaker, without needing to be specifically trained or adapted to individual voice characteristics.",27-Jan-25
10200180,Automatic Early Detection of Dysarthria using Deep Neural Network,"Dysarthria is dis-coordination among articulatory muscles responsible for articulation in the production of speech. A person with dysarthric disorder cannot control their tongue, hence, are prone to slurred speech or swallowing words which lead to improper pronunciation and less intelligibility of speech. This work focuses on the automatic early detection of Dysarthria. To elucidate the main idea, it must be understood that the whole detection procedure revolves around the speech intelligibility of a person. It becomes an arduous job to distinguish between a healthy person's speech and a person who is slowly evolving with the disorder. The prime motive of the work is to provide a proper classification of the disorder in its earliest stages. The common words and phrases recorded in the Universal Access database are used for this work. Mel Frequency Cepstral Coefficients (MFCC) are extracted from both controlled and high intelligible speech data, and fed to a Deep Neural Network (DNN) classifier. MFCC fed to the DNN classifier has provided the best classification accuracy for the above experimental setup.",7-Aug-23
8682324,Learning to Detect Dysarthria from Raw Speech,"Speech classifiers of paralinguistic traits traditionally learn from diverse hand-crafted low-level features, by selecting the relevant information for the task at hand. We explore an alternative to this selection, by learning jointly the classifier, and the feature extraction. Recent work on speech recognition has shown improved performance over speech features by learning from the waveform. We extend this approach to paralinguistic classification and propose a neural network that can learn a filterbank, a normalization factor and a compression power from the raw speech, jointly with the rest of the architecture. We apply this model to dysarthria detection from sentence-level audio recordings. Starting from a strong attention-based baseline on which mel-filterbanks outperform standard low-level descriptors, we show that learning the filters or the normalization and compression improves over fixed features by 10% absolute accuracy. We also observe a gain over OpenSmile features by learning jointly the feature extraction, the normalization, and the compression factor with the architecture. This constitutes a first attempt at learning jointly all these operations from raw audio for a speech classification task.",17-Apr-19
7078586,Modeling fundamental frequency dynamics in hypokinetic dysarthria,"Hypokinetic dysarthria (Hd), which often accompanies Parkinson's Disease (PD), is characterized by hypernasality and by compromised phonation, prosody, and articulation. This paper proposes automated methods for detection of Hd. Whereas most such studies focus on measures of phonation, this paper focuses on prosody, specifically on fundamental frequency (F0) dynamics. Prosody in Hd is clinically described as involving monopitch, which has been confirmed in numerous studies reporting reduced within-utterance pitch variability. We show that a new measure of F0 dynamics, based on a superpositional pitch model that decomposes the F0 contour into a declining phrase curve and (generally, single-peaked) accent curves, performs more accurate Hd vs. Control classification than simpler versions of the model or than conventional variability statistics.",2-Apr-15
8361563,Automatic detection of speech disorder in dysarthria using extended speech feature extraction and neural networks classification,"This paper presents an automatic detection of Dysarthria, a motor speech disorder, using extended speech features called Centroid Formants. Centroid Formants are the weighted averages of the formants extracted from a speech signal. This involves extraction of the first four formants of a speech signal and averaging their weighted values. The weights are determined by the peak energies of the bands of frequency resonance, formants. The resulting weighted averages are called the Centroid Formants. In our proposed methodology, these centroid formants are used to automatically detect Dysarthric speech using neural network classification technique. The experimental results recorded after testing this algorithm are presented. The experimental data consists of 200 speech samples from 10 Dysarthric speakers and 200 speech samples from 10 age-matched healthy speakers. The experimental results show a high performance using neural networks classification. A possible future research related to this work is the use of these extended features in speaker identification and recognition of disordered speech.",21-May-18
9076507,Analysis of Time Domain Features of Dysarthria Speech,"In general, Speech can be described as the ability to express thoughts and feelings by articulating sounds in order to communicate with the person who understand the speech and accordingly interpret their action. The types of communication disorders that affects a person¡¯s ability to produce speech sounds due to the lack of control over motor functions and articulators are speech disorders. Many people of varying age groups suffer from speech disorders and require early treatment in order to correct them. This paper analyses the time domain features such as jitter and shimmer that are extracted from the speech samples of dysarthria and healthy people. This is done by looking for dissimilarities between the different speech features preset in the normal healthy person and the disordered one by employing steps such as pre-processing followed by feature extraction.",23-Apr-20
9291830,Emotional Communication Assist Interface App for People with Dysarthria,"Text to speech (TTS) helps people who have speech disorders communicate with other people. The current TTS can express emotion, but this requires extra time and effort. We developed a TTS application by which users can render messages with emotion with ease by changing the pitch angle of a smartphone. We designed two types of TTS: free input and phrase selection. Also, we calculated the TTS editing parameters for each degree of emotion on the basis of the Online Game Voice Chat Corpus (OGVC).",21-Dec-20
10661368,Fuzzy Expectation Maximization Phoneme Prediction in Diffusion Model-based Dysarthria Voice Conversion,"In this paper proposed an effective fuzzy expectation-maximization phoneme prediction method in diffusion model-based dysarthria voice conversion (FEMPPDM-DVC) which is accessible to (i) training without parallel data (ii) converting a longer duration of the audio data (iii) preserves speaker identity. By integrating Fuzzy Expectation-Maximization (FEM) clustering and Diffusion model-based dysarthria voice conversion approach, the proposed method is able gradually generate normal utterances. Feature extraction is performed using Mel-frequency cepstral coefficients (MFCCs), a robust method in acoustic feature extraction in Text-to-Speech systems. Ensures the effectiveness and accuracy, through repeated parameter adjustment using the FEM clustering algorithm. The conversion network is a diffusion model-based structure, which can convert normal utterances to dysarthria utterances in the forward diffusion process. After forward diffusion process, the dysarthria utterance will go through a reverse diffusion process to convert dysarthria voice to normal utterance. Once converted, a GAN-based vocoder is applied to convert mel-frequency spectrogram to waveform. Objective evaluation is conducted on the Saarbr¨¹cken Voice Database (SVD) dataset show that FEMDDPM-DVC is able to improve the intelligibility and naturalness of dysarthria utterances in 15 kinds of dysarthria voice. The proposed method is compared with five other dysarthria voice conversion methods, show that the proposed method has the most performance among other method.",6-Sep-24
10912315,Revolutionary Dysarthria Analysis Through Convolutional Neural Networks,"Dysarthria occurs when there are impairments in the muscles necessary for speech, including those in the lips, tongue, voice box, and breathing muscles. This condition can result in unclear speech, even in individuals who are skilled communicators. Dysarthria can range from mild speech difficulties, where speech is hard to understand, to severe cases, where speech is completely unclear. A method for distinguishing between different types of speech involves using recordings and advanced computational techniques such as convolutional neural networks (CNNs). The strengths of CNNs are leveraged to construct a highly effective model for detecting dysarthria in speech samples. The dataset utilized includes recordings from individuals with and without dysarthria. The results indicate that the CNN model performs exceptionally well, achieving precision, recall, and F1-scores of 0.99 for both categories. With an accuracy of 0.99, the model demonstrates a high level of proficiency in differentiating between speech affected by dysarthria and normal speech. These findings highlight the effectiveness and utility of this CNN-based approach in diagnosing and assessing dysarthria. It offers valuable potential for assisting healthcare professionals and enhancing personalized speech therapy interventions.",13-Mar-25
10675073,A Study of Speech Recognition Techniques for Dysarthria Speeches Based on Digit Recognition,"With the introduction of speech recognition technology into people's lives, the application of which is no longer limited to ordinary people, but begins to target special populations, such as patients with dysarthria. It has become a major research challenge to build a high-performance speech recognition system for patients with dysarthria. To address this problem, in this paper the speech data of four patients with dysarthria and four healthy speakers on digital commands are firstly collected, secondly several speech recognition experiments are separately conducted by using Aishell-2 and Wenetspeech, two pre-trained models based on the WeNet open-source architecture, as well as the four major commercial recognition API systems, at the end a method to optimize the dysarthria data by using the so-vits-svc tool is proposed. The experiments show that the current state-of-the-art speech recognition model has a high recognition rate for speech data from the general population, but there is still room for improvement in the recognition performance of speech data from individuals with dysarthria. Later the optimization method for the dysarthria data proposed in this paper effectively improves the quality of speech data. For the two above open-source pre-trained models, the recognition rates have increased by 60% and 67.64 % compared to the original data, respectively.",24-Sep-24
7897299,Fractal features for automatic detection of dysarthria,"Amytrophic lateral sclerosis (ALS) is an incurable neurodegenerative disease. Difficulty articulating speech, dysarthria, is a common early symptom of ALS. Detecting dysarthria currently requires manual analysis of several different speech tasks by pathology experts. This is time consuming and can lead to misdiagnosis. Many existing automatic classification approaches require manually preprocessing recordings, separating individual spoken utterances from a repetitive task. In this paper, we propose a fully automated approach which does not rely on manual preprocessing. The proposed method uses novel features based on fractal analysis. Acoustic and associated articulatory recordings of a standard speech diagnostic task, the diadochokinetic test (DDK), are used for classification. This study's experiments show that this approach attains 90.2% accuracy with 94.2% sensitivity and 85.1% specificity.",13-Apr-17
6190184,Assessing Dysarthria severity using global statistics and boosting,"A new method for automatic assessment of Dysarthria severity is described. It uses the forward selection method (FSM) on global statistics of low-complexity features to find effective feature sets. FSM is embedded in a boosting algorithm that combines multiple weak classifiers to achieve a single strong classifier. Unlike standard boosting, this uses nonlinear class boundaries and unique feature sets per iteration. Results on a 39 speaker dysarthria database are described.",26-Apr-12
10250600,An Intelligent System for Dysarthria Classification of Male and Female Processed Dataset using Sequential Model Parameters,"There are several current studies including various methods for treating dysarthria in various developing countries. Research-based dysarthria treatments take a multidisciplinary approach that encompasses speech therapy, assistive technology, neurosurgery, pharmaceutical therapies, non-invasive brain stimulation, machine learning and AI methods. These methods seek to raise the general quality of life, communication and speaking abilities of dysarthria sufferers. With a 90% accuracy rate, the proposed sequential model was found to have good classification performance for identifying Dysarthria. Researchers have also been looking at the use of Machine Learning (ML) and Artificial Intelligence (AI) approaches to create tools and systems that can help people with dysarthria to speak and communicate for social welfare and provide access to best remedies.",22-Sep-23
7344537,Dysarthria diagnosis via respiration and phonation,This report discusses the implementation of a computerized application - the Computerised Frenchay Dysarthria Assessment Procedure (CFDA) - which uses digital signal processing (DSP) techniques to objectively evaluate digitised speech recordings in order to detect any symptoms of dysarthria (a type of motor speech disorder). This investigation focuses specifically on two CFDA diagnostic sub-applications which assess a patient's ability to maintain a prolonged exhalation (the ¡°Respiration at Rest¡± task) as well as execute a steady state phonation (i.e. the ¡°Sustained Phonation¡± task). It is demonstrated that combining the functionality of these two sub-applications substantially increases their diagnostic effectiveness in the context of identifying a particular variety of dysarthria known as spastic dysarthria. It is further demonstrated that certain patterns of energy fluctuations are closely correlated with manifestations of spastic dysarthria. The CFDA is intended for use in real-world conditions to assist speech and language therapists when conducting clinical evaluations.,3-Dec-15
10892620,Deep Learning Based Dysarthria Detection: A Comprehensive Approach,"Making a model that can analyze numerous input features and predict whether a person will develop dysarthria is the first step in utilizing machine learning to forecast diseases like dysarthria. A motor speech disorder called dysarthria can be caused by a variety of underlying conditions, such as degenerative disorders, traumatic brain injuries, or neurological disorders. The authors used the 2000 audio signals from males and females with and without dysarthria from the TORGO data set. To extract the important features from the audio signals, the authors used the MFCC approach. To determine if dysarthria is present or absent, a machine learning model or algorithm will be fed with these MFCC coefficients.",25-Feb-25
9629802,"Brain Signals to Rescue Aphasia, Apraxia and Dysarthria Speech Recognition","In this paper, we propose a deep learning-based algorithm to improve the performance of automatic speech recognition (ASR) systems for aphasia, apraxia, and dysarthria speech by utilizing electroencephalography (EEG) features recorded synchronously with aphasia, apraxia, and dysarthria speech. We demonstrate a significant decoding performance improvement by more than 50% during test time for isolated speech recognition task and we also provide preliminary results indicating performance improvement for the more challenging continuous speech recognition task by utilizing EEG features. The results presented in this paper show the first step towards demonstrating the possibility of utilizing non-invasive neural signals to design a real-time robust speech prosthetic for stroke survivors recovering from aphasia, apraxia, and dysarthria. Our aphasia, apraxia, and dysarthria speech-EEG data set will be released to the public to help further advance this interesting and crucial research.",9-Dec-21
1660840,Hmm-Based and Svm-Based Recognition of the Speech of Talkers With Spastic Dysarthria,"This paper studies the speech of three talkers with spastic dysarthria caused by cerebral palsy. All three subjects share the symptom of low intelligibility, but causes differ. First, all subjects tend to reduce or delete word-initial consonants; one subject deletes all consonants. Second, one subject exhibits a painstaking stutter. Two algorithms were used to develop automatic isolated digit recognition systems for these subjects. HMM-based recognition was successful for two subjects, but failed for the subject who deletes all consonants. Conversely, digit recognition experiments assuming a fixed word length (using SVMs) were successful for two subjects, but failed for the subject with the stutter.",24-Jul-06
5495563,Design of a dysarthria classifier using global statistics of speech features,"Dysarthria is a neurological disorder in which the speech production system is impaired. There are five main types of dysarthrias depending on the location of the lesion in the nervous system. There is evidence suggesting a relationship between the location of the lesion and the resulting speech characteristics. This paper describes a non-intrusive classifier to identify the dysarthria type in a person using global statistics, e.g., mean, variance, etc., of speech features. A tree-based classifier was developed using multiple low-level maximum likelihood classifiers as inputs. An error of 10.5% was achieved in the classification of three types of dysarthrias.",28-Jun-10
10157285,Dysarthria Speech Disorder Classification Using Traditional and Deep Learning Models,"Dysarthria is a motor speech disorder that results in speech difficulties due to the weakness of associated muscles. This unclear speech makes it difficult for dysarthric patients to present himself understood. This neurological limitation is usually occurs due to damages to the brain or central nervous system. Speech therapy can be effectively employed to enhance the range and consistency of voice production and improve intelligibility and communicative effectiveness. Assessing the degree of severity of dysarthria provides vital information on the patient's progress which inturn assists pathologists in arriving at a treatment plan that includes developing automated voice recognition system suitable for dysarthria patients. This work performs an exhaustive study on dysarthria severity level classification using deep neural network (DNN) and convolution neural network (CNN) architectures. Mel Frequency Cepstral Coefficients (MFCCs) and their derivatives constitute feature vectors for classification. Using the UA-Speech database, the performance metrics of DNN/CNN based learning models have been compared to baseline classifiers like support vector machine (SVM) and Random Forest (RF). The highest classification accuracy of 97.6\% is reported for DNN under UA speech database. A detailed examination of the performance from the models discussed above reveal that appropriate choice of deep learning architecture ensures better results than traditional classifiers like SVM and Random Forest.",26-Jun-23
10527645,Harnessing Deep Learning Techniques for Dysarthria Detection,"Dysarthria, a motor speech disorder resulting from neurological impairments. This study explores various approaches for the automated detection of dysarthria, integrating both traditional and emerging technologies. Speech assessments by acoustic analysis, machine learning models, and deep learning techniques are considered. Machine learning models are trained on datasets containing normal and dysarthric speech for males and females, while deep learning methods, including convolutional and recurrent neural networks, are employed to automatically learn features from speech data. Our goal is to develop a reliable and accessible dysarthria detection system thatcomplements the expertise of healthcare professionals. Validation using diverse datasets is emphasized, acknowledging the importance of early detection and intervention in improving outcomes for individuals with dysarthria.",16-May-24
10696797,Next-Gen Speech Disorder Diagnostics: CNN Methods for Dysarthria Classification,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. Dysarthria has a significant impact on communication capacity, making early diagnosis essential for effective therapies and improved patient outcomes. The research used a Convolutional Neural Network (CNN) to categorise speech using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. There are 500 samples from each gender in the collection, representing dysarthric and non-dysarthric people who were recorded during different sessions. Highlighting the promise of deep learning technology in aiding early identification of dysarthria and enabling rapid therapy for affected individuals, the CNN-based approach exhibits an amazing 96% accuracy in discriminating between dysarthric and non-dysarthric cases. This study offers a promising chance to enhance the quality of life for those with speech impairments while also making substantial contributions to the development of diagnostic capabilities.",4-Oct-24
10730941,Advancing Speech Disorder Diagnostics: CNN Innovations in Dysarthria Recognition,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. The capacity to communicate is greatly affected by dysarthria, thus early diagnosis is critical for effective therapies and improved patient outcomes. The study employed a Convolutional Neural Network (CNN) for speech classification using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. With 500 samples each, collected over distinct sessions, the dataset contains both dysarthric and non-dysarthric people of both sexes. Distinguishing between dysarthric and non-dysarthric occurrences, the CNN-based approach achieves an astonishing 96% accuracy. This shows how deep learning technology may help with early dysarthria identification and enable rapid therapy for affected individuals. The findings of this study have important implications for the development of diagnostic tools and may lead to better living conditions for those who struggle with speaking.",29-Oct-24
10340908,A preliminary study on self-care telemonitoring of dysarthria in spinal muscular atrophy,"Spinal muscular atrophy (SMA) is a rare neuromuscular disease which may cause impairments in oro-facial musculature. Most of the individuals with SMA present bulbar signs such as flaccid dysarthria which mines their abilities to speak and, as consequence, their psychic balance. To support clinicians, recent work has demonstrated the feasibility of video-based techniques for assessing the oro-facial functions in patients with neurological disorders such as amyotrophic lateral sclerosis. However, no work has so far focused on automatic and quantitative monitoring of dysarthria in SMA. To overcome limitations this work¡¯s aim is to propose a cloud-based store-and-forward telemonitoring system for automatic and quantitative evaluation of oro-facial muscles in individuals with SMA. The system integrates a convolutional neural network (CNN) aimed at identifying the position of facial landmarks from video recordings acquired via a web application by an SMA patient.Clinical relevance¡ª The proposed work is in the preliminary stage, but it represents the first step towards a better understanding of the bulbar-functions¡¯ evolution in patients with SMA.",11-Dec-23
9414283,"Automatic And Perceptual Discrimination Between Dysarthria, Apraxia of Speech, and Neurotypical Speech","Automatic techniques in the context of motor speech disorders (MSDs) are typically two-class techniques aiming to discriminate between dysarthria and neurotypical speech or between dysarthria and apraxia of speech (AoS). Further, although such techniques are proposed to support the perceptual assessment of clinicians, the automatic and perceptual classification accuracy has never been compared. In this paper, we investigate a three-class automatic technique and a set of handcrafted features for the discrimination of dysarthria, AoS and neurotypical speech. Instead of following the commonly used One-versus-One or One-versus-Rest approaches for multi-class classification, a hierarchical approach is proposed. Further, a perceptual study is conducted where speech and language pathologists are asked to listen to recordings of dysarthria, AoS, and neurotypical speech and decide which class the recordings belong to. The proposed automatic technique is evaluated on the same recordings and the automatic and perceptual classification performance are compared. The presented results show that the hierarchical classification approach yields a higher classification accuracy than baseline One-versus-One and One-versus-Rest approaches. Further, the presented results show that the automatic approach yields a higher classification accuracy than the perceptual assessment of speech and language pathologists, demonstrating the potential advantages of integrating automatic tools in clinical practice.",13-May-21
8512311,Quantitative Assessment of Syllabic Timing Deficits in Ataxic Dysarthria,"Parametric analysis of Cerebellar Dysarthria (CD) may be valuable and more informative compared to its clinical assessment. A quantifiable estimation of the timing deficits in repeated syllabic utterance is described in the current study. Thirty-five individuals were diagnosed with cerebellar ataxia to varying degrees and twenty-six age-matched healthy controls were recruited. To automatically detect the local maxima of each syllable in the recorded speech files, a topographic prominence incorporated concept is designed. Subsequently, four acoustic features and eight corresponding parametric measurements are extracted to identify articulatory deficits in ataxic dysarthria. A comparative study on the behaviour of these measures for dysarthric and non-dysarthric subjects is presented in this paper. The results are further explored using a dimensionreduction tool (Principal Component Analysis) to emphasize variation and bring out the strongest discriminating patterns in our feature dataset.",28-Oct-18
10781716,Non-invasive stroke diagnosis using speech data from dysarthria patients,"Acute Ischemic Stroke (AIS) is a major cause of disability and can lead to death in severe cases. A common symptom of AIS, dysarthria, significantly impacts the quality of life of patients. In this study, we developed a deep learning model using dysarthria data for cost-effective and non-invasive brain stroke diagnosis. We utilized models such as ResNet50, InceptionV4, ResNeXt50, SEResNeXt18, and AttResNet50 to effectively extract and classify speech features indicative of stroke symptoms. These models demonstrated high performance, with Sensitivity, Specificity, Precision, Accuracy, and F1-score values reaching 96.77%, 96.08%, 92.82%, 95.52%, and 93.82%, respectively. Our approach offers a non-invasive, cost-effective alternative for early stroke detection, with potential for further accuracy improvements through additional research. This method promises rapid, economical early diagnosis, which could positively impact long-term treatment and healthcare options.",17-Dec-24
10800228,Fine-Tuning Pre-Trained Audio Models for Dysarthria Severity Classification: A Second Place Solution in the Multimodal Dysarthria Severity Classification Challenge,"Dysarthria, a neurological disorder affecting speech, poses significant challenges for automatic diagnosis and severity classification due to its complexity and the scarcity of relevant datasets. This study addresses these challenges by leveraging the dataset provided by the ISCSLP 2024 Multimodal Dysarthria Severity Classification Challenge. Our approach primarily involves two key steps: splitting the training set into training and validation subsets, and fine-tuning pre-trained au-dio models to adapt them to the task. To ensure robust evaluation and prevent label leakage, we employed the StratifiedGroupKFold function from sklearn for dataset splitting, ensuring that training and validation sets do not share participants. This method allowed us to maintain consistent statistical distributions across folds. For model finetuning, we selected two pre-trained audio models, w2v-bert-2.0 and whisper-Iarge-v3, and fine-tuned them on different folds of the dataset. Our results indicate that the w2v-bert-2.0 model fine-tuned on fold-2 achieved the highest performance, with a validation Fl-score of 0.699 and an online score of 7.7452. The experimental results, including confusion matrices and embedding distributions, highlight the model's ability to distinguish between different severity levels of dysarthria. Our approach achieved a commendable second place in the competition¡¯ demonstrating the effectiveness of fine-tuning pre-trained audio models for this task. Future work will explore the integration of multimodal data and multi-task learning strategies to further enhance model performance.",23-Dec-24
10307923,Automated Detection and Severity Assessment of Dysarthria using Raw Speech,"Dysarthria is a medical condition that impairs an individual¡¯s ability to speak clearly due to muscle weakness or paralysis. To diagnose and monitor dysarthria severity, this article proposes the use of a deep learning model that utilizes raw speech waveforms. This approach eliminates the need for feature engineering and enhances the model¡¯s ability to handle noise and speech variability. The proposed system was compared to a standard convolutional neural network (CNN) model and was found to perform better in both dysarthria severity classification and dysarthria/healthy control classification tasks. The results indicate that the SincNet model achieved an accuracy of 95.7% and 99.6% in these tasks, respectively. The proposed system can aid clinicians in diagnosing and monitoring dysarthria severity and could have broader applications in speech-related disorders. The study emphasizes the importance of using raw waveform-based models for speech analysis and demonstrates the effectiveness of SincNet in automatic dysarthria/healthy control classification and dysarthria severity assessment.",23-Nov-23
6936631,Investigation on articulatory and acoustic characteristics of dysarthria,"Direct measurement of articulation contributes to figure out the mechanism of dysarthric speech production accurately, comparing to analyzing acoustic signal alone. This study makes a statistical comparison between dysarthric and normal speech, and investigates and analyzes dysarthric characteristics based on articulatory and acoustic data of continuous English utterance. The distribution of the articulatory point is calculated for each vowel, where the vowels show a relatively smaller region for dysarthria than for normal speech. This implies that the speakers with dysarthria may have some difficulties to fully use the articulatory space as the speakers without dysarthria. The rhythm and sound source are analyzed using autocorrelation function, power spectrum and linear prediction coding. The results reveal that the speakers without dysarthria can keep steady rhythm and energy in uttering consonant-vowel repetition sequences but it is hard for the speakers with dysarthria to maintain the stability. Meanwhile, the dysarthric sound source shows unstable period of the fundamental frequency, which reflects that the speakers with dysarthria could not control the glottis movement well.",27-Oct-14
10902941,Analysis of Features for Dysarthria Severity Classification from Speech,"Dysarthria is a disorder that affects the ability of an individual to speak clearly. Diagnosis of the severity of dysarthria can aid in providing appropriate therapy to the individual. Therefore, the current work focuses on identifying features that can be used to estimate the severity of dysarthria. In this regard, two feature sets are considered, namely DisVoice and OpenSMILE, and the genetic algorithm is used to identify the most suitable list of features from both feature sets using 3 speech corpora, namely SSN-TDSC, Torgo, and UA Speech corpora. In order to test the effectiveness of these features, classifiers are trained on each feature set as a whole and on the features identified by the genetic algorithm, and their performance compared. It is observed that articulatory and prosodic features are most important in the diagnosis of severity of dysarthria. A maximum accuracy of 85% is obtained with the shortlisted DisVoice features and 97% with the OpenSMILE features.",5-Mar-25
10800159,Multi-Modal Dysarthria Severity Assessment Using Dual-Branch Feature Decoupling Network and Mixed Expert Framework,"Dysarthria, a motor speech disorder resulting from neurological damage, significantly impairs an individual's ability to articulate words. Assessing the severity of dysarthria is crucial for effective therapeutic interventions and rehabilitation strategies. However, current methods are time-consuming and subjective, leading to potential inconsistencies. This study proposed a dual-branch feature decoupling network and mixed expert framework for the automatic diagnosis and assessment of dysarthria. The proposed hybrid network architecture integrates a ResNet-based branch for audio data with an attention module and a 3D ResNet branch for video data, and was evaluated on the Multimodal Dysarthria Severity Assessment Challenge (MDSA) dataset, achieving significant performance improvements and ranking first in the challenge with a best score of 8.7404. The study's findings highlight the efficacy of the proposed framework in capturing essential features from multimodal data, contributing to more accurate and reliable assessments of dysarthria.",23-Dec-24
10448175,Spectral Analysis of Vowels and Fricatives at Varied Levels of Dysarthria Severity for Amyotrophic Lateral Sclerosis,"Dysarthria due to Amyotrophic Lateral Sclerosis (ALS) affects the acoustic characteristics of different speech sounds. The effects intensify with increasing severity leading to the collapse of the acoustic space of the affected individuals. With an aim to characterize such changes in the acoustic space, this paper studies the variations in band-specific and full-band spectral properties of 4 sustained vowels (/a/, /i/, /o/, /u/) and 3 sustained fricatives (/s/, /sh/, /f/) at different dysarthria severity levels. Effect of dysarthria on spectral features of these phonemes are not well explored. Statistical comparison of these features among different severities for the phonemes considered and among different vowels/fricatives for every severity level using speech data from 119 ALS and 40 healthy subjects indicate the followings. Though all band-specific and full-band features of the three fricatives and most of those features for the four vowels become statistically similar at high severity levels, certain features remain distinguishable. Spectral differences in 0-2 kHz band between /a/ and the other vowels and in the 2-6 kHz band between /a/ and /o/, /u/ persist through all severity levels. Moreover, properties of /f/ remain mostly unchanged with increasing dysarthria severity levels.",18-Mar-24
10673651,Advancing Speech Disorder Diagnostics: A Comprehensive Study on Dysarthria Classification with CNN,"This study article focuses on dysarthria, a speech problem that is often seen in patients with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early identification of dysarthria is crucial for successful treatments and better patient outcomes, since it has a substantial influence on communication ability. Using the TORGO database, which consists of 2000 samples of persons with and without dysarthria, spanning different genders, the research use a Convolutional Neural Network (CNN) to classify speech. The dataset includes both dysarthric and non-dysarthric individuals of both genders, with 500 samples each, captured during separate sessions. The CNN-based technique demonstrates an impressive 96% accuracy in differentiating between dysarthric and non-dysarthric instances, highlighting the promise of deep learning technology in assisting with the early detection of dysarthria and enabling prompt therapies for afflicted people. This study makes significant contributions to the advancement of diagnostic capacities and presents a potential opportunity to improve the quality of life for those with speech difficulties.",18-Sep-24
10625627,Enhancing the Diagnosis of Speech Disorders: An In-Depth Investigation into Dysarthria Classification Using the ResNet18 Model,"This research article concentrates on dysarthria, a speech impediment commonly observed in individuals with conditions such as cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective interventions and improved patient outcomes, as it significantly impacts communication abilities. Employing the TORGO database, comprising 2000 samples from individuals with and without dysarthria, encompassing diverse genders, the study utilizes a Convolutional Neural Network (ResNet18 Model) for speech classification. The dataset encompasses both dysarthric and non-dysarthric subjects of both genders, with 500 samples each, recorded in separate sessions. The ResNet18 Model-based approach demonstrates an impressive 96% accuracy in distinguishing between dysarthric and non-dysarthric instances, underscoring the potential of deep learning technology in aiding early dysarthria detection and facilitating timely interventions. This investigation significantly contributes to advancing diagnostic capabilities and presents a promising avenue to enhance the quality of life for individuals grappling with speech difficulties.",22-Aug-24
10095366,Statistical Analysis of Speech Disorder Specific Features to Characterise Dysarthria Severity Level,"Poor coordination of the speech production subsystems due to any neurological injury or a neuro-degenerative disease leads to dysarthria, a neuro-motor speech disorder. Dysarthric speech impairments can be mapped to the deficits caused in phonation, articulation, prosody, and glottal functioning. With the aim of reducing the subjectivity in clinical evaluations, many automated systems are proposed in the literature to assess the dysarthria severity level using these features. This work aims to analyse the suitability of these features in determining the severity level. A detailed investigation is done to rank these features for their efficacy in modelling the pathological aspects of dysarthric speech, using the technique of paraconsistent feature engineering. The study used two dysarthric speech databases, UA-Speech and TORGO. It puts light into the fact that both the prosody and articulation features are best useful for dysarthria severity estimation, which was supported by the classification accuracies obtained on using different machine learning classifiers.",5-May-23
8251336,Identification of Cerebellar Dysarthria with SISO Characterisation,"Quantitative identification of dysarthria plays a major role in the classification of its severity. This paper quantitatively analyses several components of cerebellar dysarthria. The methodology described in this study will be extended to other types of dysarthria via systematic analysis. The speech production model is characterized as a second-order singleinput and single-output (SISO), linear, time-invariant (LTI) system in our study. A comparative study on the behavior of the damping ratio and resonant frequency for dysarthric and non-dysarthric subjects is presented. The results are further analyzed using the Principal component analysis (PCA) technique to emphasize the variation and uncover strong patterns in the selected features. The effects of some other related factors like decay time and Q-factor are also highlighted.",11-Jan-18
10739183,CNN-Driven Innovations in Dysarthria Classification and Speech Disorder Management,"This research article addresses dysarthria, a speech disorder frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective treatment and improved patient outcomes, as it significantly impacts communication abilities. Utilizing the TORGO database, which comprises 2000 speech samples from both dysarthric and non-dysarthric individuals across various genders, this study employs a Convolutional Neural Network (CNN) for classification. The dataset includes 500 samples each from both groups, collected in different sessions. The CNN approach achieves an impressive 96% accuracy in distinguishing dysarthric from non-dysarthric speech, showcasing the potential of deep learning technology in facilitating early dysarthria diagnosis and enabling timely interventions. This study makes substantial contributions to enhancing diagnostic capabilities and offers a promising avenue for improving the quality of life for individuals with speech disorders.",4-Nov-24
10800051,Constant Q Transform for Audio-Visual Dysarthria Severity Assessment,"This paper describes an automatic dysarthria severity assessment system submitted for the MDSA2024 challenge. The system utilizes audio and visual features to classify the severity of dysarthria. We investigate the effectiveness of different acoustic feature combinations, such as Mel spectrogram, filterbank and constant Q transform. Different encoders for audio data processing are compared in the experiments. The results demonstrate that the Conformer encoder achieves superior performance compared to the Densenet encoder on pure audio features. We further explore model-level fusion by combining audio and visual embeddings, leading to improvements in precision¡¯ recall, and accuracy metrics. The best-achieved score on the test set is 7.5579, with an individual F1-score of 0.7028. The findings suggest that the proposed system with Conformer encoder and model-level fusion holds promise for automatic dysarthria assessment.",23-Dec-24
10781584,Dysarthria Detection with Deep Representation Learning for Patients with Parkinson¡¯s Disease,"Dysarthria is a very common motor speech symptom in Parkinson¡¯s disease impairing normal communications of patients. Detection of dysarthria could assist clinical diagnosis and intervention of Parkinson¡¯s disease, provide monitoring approach for treatment-related side effects, and lead to effective speech therapy to prevent further communication and social deficits. Applying machine learning techniques to speech analysis for patients offers more resource-efficient, accessible and objective tools for screening and assessment of dysarthria. In this study, we constructed a multi-task speech dataset recorded from 600 participants with high data diversity to facilitate the development of detection models. We established a remote data acquisition and end-to-end prediction pipeline with deep representation learning, compared the performance with different feature-based learning and classification methods, and achieved a superior accuracy of over 90%. Different affecting factors were analyzed for model performance. Our proposed framework demonstrates the potential of developing and deploying an automated self-monitoring approach of dysarthria for patients with Parkinson¡¯s disease, which could benefit a large-scale population and their disease managements.",17-Dec-24
7953122,Automatic assessment of dysarthria severity level using audio descriptors,"Dysarthria is a motor speech impairment, often characterized by speech that is generally indiscernible by human listeners. Assessment of the severity level of dysarthria provides an understanding of the patient's progression in the underlying cause and is essential for planning therapy, as well as improving automatic dysarthric speech recognition. In this paper, we propose a non-linguistic manner of automatic assessment of severity levels using audio descriptors or a set of features traditionally used to define timbre of musical instruments and have been modified to suit this purpose. Multitapered spectral estimation based features were computed and used for classification, in addition to the audio descriptors for timbre. An Artificial Neural Network (ANN) was trained to classify speech into various severity levels within Universal Access dysarthric speech corpus and the TORGO database. An average classification accuracy of 96.44% and 98.7% was obtained for UA speech corpus and TORGO database respectively.",19-Jun-17
9287741,Automated Dysarthria Severity Classification Using Deep Learning Frameworks,"Dysarthria is a neuro-motor speech disorder that renders speech unintelligible, in proportional to its severity. Assessing the severity level of dysarthria, apart from being a diagnostic step to evaluate the patient's improvement, is also capable of aiding automatic dysarthric speech recognition systems. In this paper, a detailed study on dysarthia severity classification using various deep learning architectural choices, namely deep neural network (DNN), convolutional neural network (CNN) and long short-term memory network (LSTM) is carried out. Mel frequency cepstral coefficients (MFCCs) and its derivatives are used as features. Performance of these models are compared with a baseline support vector machine (SVM) classifier using the UA-Speech corpus and the TORGO database. The highest classification accuracy of 96.18% and 93.24% are reported for TORGO and UA-Speech respectively. Detailed analysis on performance of these models shows that a proper choice of a deep learning architecture can ensure better performance than the conventionally used SVM classifier.",18-Dec-20
10584052,Deep Learning Based Speech Recognition for Hyperkinetic Dysarthria Disorder,"Speech recognition is a technology that aims to transform human speech into text and has applications in a variety of fields, including information technology, healthcare, automobiles, and others. This research explores the advantages of employing deep learning methods to provide individualized assistance technology solutions for people with dysarthria. We proposed a Convolutional Temporal Bidirectional Network (CTBNet) model for translating Russian Hyperkinetic Dysarthria Disorder (RHDD) speech into text. CTBNet encodes input audio features using 1D convolution layers, and BidirectionalGRU (Bi-GRU) layers. The encoder effectively captures both short-term and long-term spatial temporal information. More importantly, CTBNet includes with an attention-CTC decoder, that is responsible for producing output texts. We utilized a dataset of 2797 recordings of RHDD speech, with a cumulative recorded duration of 2 hours and 33 minutes, for training purposes. The CTBNet model has achieved a 15% Character Error Rate (CER) and a 59% Word Error Rate (WER) on the dataset proposed. Our experimental findings show superior performance compared to state-of-the-art models, namely, 3xCNN, and 3xLSTM, when evaluated on the same dataset.",9-Jul-24
10805075,Developing a Hyperkinetic Dysarthria Speech Classification System using Residual Learning,"Hyperkinetic dysarthria abnormalities are exceedingly widespread across the worldwide populace. One of the most effective methodologies for disordered audio speech identification is classical deep learning technique. However, the efficiency of classification is impacted by the limitations imposed by the quality of the training dataset, such as expense and limited resources, data imbalance, and data annotation difficulties. Accordingly, we suggest implementing a residual learning framework (ResN et architecture) with various conditions and hyperparameters (batch size and learning rate) that improve the training process of deeper networks compared to earlier approaches. Pre-emphasis, windowing, and lifting techniques are applied to improve the quality of Mel-Frequency Cepstral Coefficients. In addition, we have introduced the hyperkinetic dysarthria speech dataset in the Russian language, consisting of 4 hours and 4 minutes of recorded speech. The empirical findings demonstrate that ResNet40 has an overall validation accuracy of 86.7%, surpassing other research models. It is anticipated that it will be recognized as an alternative diagnostic instrument for physicians in the future as research continues to progress.",25-Dec-24
10889800,Multilingual Speaker-Invariant Dysarthria Severity Assessment Using Adversarial Domain Adaptation and Self-Supervised Learning,"Traditional assessments for dysarthria are subjective and time-consuming, highlighting the need for automated, objective approaches that can be scaled for remote and resource-constrained environments. This paper introduces an adversarial domain adaptation framework tailored for dysarthria severity assessment, addressing the challenges of high intra-class variability and limited availability of dysarthric speech data. By framing speaker variability as a domain adaptation problem, we utilise an adversarially trained feature extractor to derive speaker-invariant yet discriminatively powerful representations utilising speech features learned through self-supervised learning. Experiments on previously unseen and diverse speakers reveal that the proposed approach yields a 7.86% average improvement across multilingual datasets compared to traditional severity-discriminative training, outperforming competitive baselines by 12.33% on average. Additionally, the method inherently supports privacy-preserving applications by minimising reliance on speaker-specific information. The results demonstrate strong alignment with clinical assessments, reinforcing our model¡¯s clinical relevance and effectiveness.",7-Mar-25
10929844,AI-Enabled Speech Monitoring for Dysarthria Detection in Consumer Electronics,"Speech is essential in human communication, and recent advancements in artificial intelligence (AI) have enabled new applications for voice data, particularly in health monitoring. Building on this progress, a home-based health detection system that utilizes voice signals provides an accessible method for users to independently identify and respond to conditions such as dysarthria, without the need for hospital or clinic visits. In this study, we developed and evaluated convolutional neural network (CNN) models to classify audio data from both healthy individuals and individuals with dysarthria. The dataset comprised command-based speech samples, which were segmented into sentence-specific input. Preprocessing steps included segmentation, downsampling, and feature extraction tailored for CNN input. The models exhibited high potential in distinguishing between normal and dysarthric states, with the most effective model achieving an f1-score of 96.18¡À4.7% and an accuracy of 96.01¡À5.02%. Furthermore, sentence structure and composition significantly influenced model performance, with specific sentences demonstrating higher classification accuracy. These findings suggest that AI-driven speech analysis may support detecting and managing specific health conditions in non-clinical environments. However, further work is needed to address data imbalance and sentence variability limitations. Future research could expand on real-world applications, particularly in settings with limited traditional health monitoring.",26-Mar-25
10848959,Dysarthria Severity Classification Using Phase Based Features of LP Residual,"Classifying the severity of speech impairment due to dysarthria is crucial for optimizing care and enhancing communication abilities for affected individuals. This study explores the use of the Modified Group Delay Function (MGDF) of LP residual signal in classifying dysarthria severity-levels. Evaluations were conducted using standard UA-Speech and TORGO datasets. A stratified Convolutional Neural Network (CNN) with 5-fold cross-validation validated the results. Baseline features included Linear Frequency Cepstral Coefficients (LFCC), Mel Frequency Cepstral Coefficients (MFCC), and Whisper module. Key performance evaluation metrics were accuracy, precision, recall, and F1-score. Finally, the latency period was analyzed for practical deployment of the system, system¡¯s ability to accurately recognize and process speech from any speaker, without needing to be specifically trained or adapted to individual voice characteristics.",27-Jan-25
10200180,Automatic Early Detection of Dysarthria using Deep Neural Network,"Dysarthria is dis-coordination among articulatory muscles responsible for articulation in the production of speech. A person with dysarthric disorder cannot control their tongue, hence, are prone to slurred speech or swallowing words which lead to improper pronunciation and less intelligibility of speech. This work focuses on the automatic early detection of Dysarthria. To elucidate the main idea, it must be understood that the whole detection procedure revolves around the speech intelligibility of a person. It becomes an arduous job to distinguish between a healthy person's speech and a person who is slowly evolving with the disorder. The prime motive of the work is to provide a proper classification of the disorder in its earliest stages. The common words and phrases recorded in the Universal Access database are used for this work. Mel Frequency Cepstral Coefficients (MFCC) are extracted from both controlled and high intelligible speech data, and fed to a Deep Neural Network (DNN) classifier. MFCC fed to the DNN classifier has provided the best classification accuracy for the above experimental setup.",7-Aug-23
8682324,Learning to Detect Dysarthria from Raw Speech,"Speech classifiers of paralinguistic traits traditionally learn from diverse hand-crafted low-level features, by selecting the relevant information for the task at hand. We explore an alternative to this selection, by learning jointly the classifier, and the feature extraction. Recent work on speech recognition has shown improved performance over speech features by learning from the waveform. We extend this approach to paralinguistic classification and propose a neural network that can learn a filterbank, a normalization factor and a compression power from the raw speech, jointly with the rest of the architecture. We apply this model to dysarthria detection from sentence-level audio recordings. Starting from a strong attention-based baseline on which mel-filterbanks outperform standard low-level descriptors, we show that learning the filters or the normalization and compression improves over fixed features by 10% absolute accuracy. We also observe a gain over OpenSmile features by learning jointly the feature extraction, the normalization, and the compression factor with the architecture. This constitutes a first attempt at learning jointly all these operations from raw audio for a speech classification task.",17-Apr-19
7078586,Modeling fundamental frequency dynamics in hypokinetic dysarthria,"Hypokinetic dysarthria (Hd), which often accompanies Parkinson's Disease (PD), is characterized by hypernasality and by compromised phonation, prosody, and articulation. This paper proposes automated methods for detection of Hd. Whereas most such studies focus on measures of phonation, this paper focuses on prosody, specifically on fundamental frequency (F0) dynamics. Prosody in Hd is clinically described as involving monopitch, which has been confirmed in numerous studies reporting reduced within-utterance pitch variability. We show that a new measure of F0 dynamics, based on a superpositional pitch model that decomposes the F0 contour into a declining phrase curve and (generally, single-peaked) accent curves, performs more accurate Hd vs. Control classification than simpler versions of the model or than conventional variability statistics.",2-Apr-15
8361563,Automatic detection of speech disorder in dysarthria using extended speech feature extraction and neural networks classification,"This paper presents an automatic detection of Dysarthria, a motor speech disorder, using extended speech features called Centroid Formants. Centroid Formants are the weighted averages of the formants extracted from a speech signal. This involves extraction of the first four formants of a speech signal and averaging their weighted values. The weights are determined by the peak energies of the bands of frequency resonance, formants. The resulting weighted averages are called the Centroid Formants. In our proposed methodology, these centroid formants are used to automatically detect Dysarthric speech using neural network classification technique. The experimental results recorded after testing this algorithm are presented. The experimental data consists of 200 speech samples from 10 Dysarthric speakers and 200 speech samples from 10 age-matched healthy speakers. The experimental results show a high performance using neural networks classification. A possible future research related to this work is the use of these extended features in speaker identification and recognition of disordered speech.",21-May-18
9076507,Analysis of Time Domain Features of Dysarthria Speech,"In general, Speech can be described as the ability to express thoughts and feelings by articulating sounds in order to communicate with the person who understand the speech and accordingly interpret their action. The types of communication disorders that affects a person¡¯s ability to produce speech sounds due to the lack of control over motor functions and articulators are speech disorders. Many people of varying age groups suffer from speech disorders and require early treatment in order to correct them. This paper analyses the time domain features such as jitter and shimmer that are extracted from the speech samples of dysarthria and healthy people. This is done by looking for dissimilarities between the different speech features preset in the normal healthy person and the disordered one by employing steps such as pre-processing followed by feature extraction.",23-Apr-20
9291830,Emotional Communication Assist Interface App for People with Dysarthria,"Text to speech (TTS) helps people who have speech disorders communicate with other people. The current TTS can express emotion, but this requires extra time and effort. We developed a TTS application by which users can render messages with emotion with ease by changing the pitch angle of a smartphone. We designed two types of TTS: free input and phrase selection. Also, we calculated the TTS editing parameters for each degree of emotion on the basis of the Online Game Voice Chat Corpus (OGVC).",21-Dec-20
10661368,Fuzzy Expectation Maximization Phoneme Prediction in Diffusion Model-based Dysarthria Voice Conversion,"In this paper proposed an effective fuzzy expectation-maximization phoneme prediction method in diffusion model-based dysarthria voice conversion (FEMPPDM-DVC) which is accessible to (i) training without parallel data (ii) converting a longer duration of the audio data (iii) preserves speaker identity. By integrating Fuzzy Expectation-Maximization (FEM) clustering and Diffusion model-based dysarthria voice conversion approach, the proposed method is able gradually generate normal utterances. Feature extraction is performed using Mel-frequency cepstral coefficients (MFCCs), a robust method in acoustic feature extraction in Text-to-Speech systems. Ensures the effectiveness and accuracy, through repeated parameter adjustment using the FEM clustering algorithm. The conversion network is a diffusion model-based structure, which can convert normal utterances to dysarthria utterances in the forward diffusion process. After forward diffusion process, the dysarthria utterance will go through a reverse diffusion process to convert dysarthria voice to normal utterance. Once converted, a GAN-based vocoder is applied to convert mel-frequency spectrogram to waveform. Objective evaluation is conducted on the Saarbr¨¹cken Voice Database (SVD) dataset show that FEMDDPM-DVC is able to improve the intelligibility and naturalness of dysarthria utterances in 15 kinds of dysarthria voice. The proposed method is compared with five other dysarthria voice conversion methods, show that the proposed method has the most performance among other method.",6-Sep-24
10912315,Revolutionary Dysarthria Analysis Through Convolutional Neural Networks,"Dysarthria occurs when there are impairments in the muscles necessary for speech, including those in the lips, tongue, voice box, and breathing muscles. This condition can result in unclear speech, even in individuals who are skilled communicators. Dysarthria can range from mild speech difficulties, where speech is hard to understand, to severe cases, where speech is completely unclear. A method for distinguishing between different types of speech involves using recordings and advanced computational techniques such as convolutional neural networks (CNNs). The strengths of CNNs are leveraged to construct a highly effective model for detecting dysarthria in speech samples. The dataset utilized includes recordings from individuals with and without dysarthria. The results indicate that the CNN model performs exceptionally well, achieving precision, recall, and F1-scores of 0.99 for both categories. With an accuracy of 0.99, the model demonstrates a high level of proficiency in differentiating between speech affected by dysarthria and normal speech. These findings highlight the effectiveness and utility of this CNN-based approach in diagnosing and assessing dysarthria. It offers valuable potential for assisting healthcare professionals and enhancing personalized speech therapy interventions.",13-Mar-25
10675073,A Study of Speech Recognition Techniques for Dysarthria Speeches Based on Digit Recognition,"With the introduction of speech recognition technology into people's lives, the application of which is no longer limited to ordinary people, but begins to target special populations, such as patients with dysarthria. It has become a major research challenge to build a high-performance speech recognition system for patients with dysarthria. To address this problem, in this paper the speech data of four patients with dysarthria and four healthy speakers on digital commands are firstly collected, secondly several speech recognition experiments are separately conducted by using Aishell-2 and Wenetspeech, two pre-trained models based on the WeNet open-source architecture, as well as the four major commercial recognition API systems, at the end a method to optimize the dysarthria data by using the so-vits-svc tool is proposed. The experiments show that the current state-of-the-art speech recognition model has a high recognition rate for speech data from the general population, but there is still room for improvement in the recognition performance of speech data from individuals with dysarthria. Later the optimization method for the dysarthria data proposed in this paper effectively improves the quality of speech data. For the two above open-source pre-trained models, the recognition rates have increased by 60% and 67.64 % compared to the original data, respectively.",24-Sep-24
7897299,Fractal features for automatic detection of dysarthria,"Amytrophic lateral sclerosis (ALS) is an incurable neurodegenerative disease. Difficulty articulating speech, dysarthria, is a common early symptom of ALS. Detecting dysarthria currently requires manual analysis of several different speech tasks by pathology experts. This is time consuming and can lead to misdiagnosis. Many existing automatic classification approaches require manually preprocessing recordings, separating individual spoken utterances from a repetitive task. In this paper, we propose a fully automated approach which does not rely on manual preprocessing. The proposed method uses novel features based on fractal analysis. Acoustic and associated articulatory recordings of a standard speech diagnostic task, the diadochokinetic test (DDK), are used for classification. This study's experiments show that this approach attains 90.2% accuracy with 94.2% sensitivity and 85.1% specificity.",13-Apr-17
6190184,Assessing Dysarthria severity using global statistics and boosting,"A new method for automatic assessment of Dysarthria severity is described. It uses the forward selection method (FSM) on global statistics of low-complexity features to find effective feature sets. FSM is embedded in a boosting algorithm that combines multiple weak classifiers to achieve a single strong classifier. Unlike standard boosting, this uses nonlinear class boundaries and unique feature sets per iteration. Results on a 39 speaker dysarthria database are described.",26-Apr-12
10250600,An Intelligent System for Dysarthria Classification of Male and Female Processed Dataset using Sequential Model Parameters,"There are several current studies including various methods for treating dysarthria in various developing countries. Research-based dysarthria treatments take a multidisciplinary approach that encompasses speech therapy, assistive technology, neurosurgery, pharmaceutical therapies, non-invasive brain stimulation, machine learning and AI methods. These methods seek to raise the general quality of life, communication and speaking abilities of dysarthria sufferers. With a 90% accuracy rate, the proposed sequential model was found to have good classification performance for identifying Dysarthria. Researchers have also been looking at the use of Machine Learning (ML) and Artificial Intelligence (AI) approaches to create tools and systems that can help people with dysarthria to speak and communicate for social welfare and provide access to best remedies.",22-Sep-23
7344537,Dysarthria diagnosis via respiration and phonation,This report discusses the implementation of a computerized application - the Computerised Frenchay Dysarthria Assessment Procedure (CFDA) - which uses digital signal processing (DSP) techniques to objectively evaluate digitised speech recordings in order to detect any symptoms of dysarthria (a type of motor speech disorder). This investigation focuses specifically on two CFDA diagnostic sub-applications which assess a patient's ability to maintain a prolonged exhalation (the ¡°Respiration at Rest¡± task) as well as execute a steady state phonation (i.e. the ¡°Sustained Phonation¡± task). It is demonstrated that combining the functionality of these two sub-applications substantially increases their diagnostic effectiveness in the context of identifying a particular variety of dysarthria known as spastic dysarthria. It is further demonstrated that certain patterns of energy fluctuations are closely correlated with manifestations of spastic dysarthria. The CFDA is intended for use in real-world conditions to assist speech and language therapists when conducting clinical evaluations.,3-Dec-15
10892620,Deep Learning Based Dysarthria Detection: A Comprehensive Approach,"Making a model that can analyze numerous input features and predict whether a person will develop dysarthria is the first step in utilizing machine learning to forecast diseases like dysarthria. A motor speech disorder called dysarthria can be caused by a variety of underlying conditions, such as degenerative disorders, traumatic brain injuries, or neurological disorders. The authors used the 2000 audio signals from males and females with and without dysarthria from the TORGO data set. To extract the important features from the audio signals, the authors used the MFCC approach. To determine if dysarthria is present or absent, a machine learning model or algorithm will be fed with these MFCC coefficients.",25-Feb-25
9629802,"Brain Signals to Rescue Aphasia, Apraxia and Dysarthria Speech Recognition","In this paper, we propose a deep learning-based algorithm to improve the performance of automatic speech recognition (ASR) systems for aphasia, apraxia, and dysarthria speech by utilizing electroencephalography (EEG) features recorded synchronously with aphasia, apraxia, and dysarthria speech. We demonstrate a significant decoding performance improvement by more than 50% during test time for isolated speech recognition task and we also provide preliminary results indicating performance improvement for the more challenging continuous speech recognition task by utilizing EEG features. The results presented in this paper show the first step towards demonstrating the possibility of utilizing non-invasive neural signals to design a real-time robust speech prosthetic for stroke survivors recovering from aphasia, apraxia, and dysarthria. Our aphasia, apraxia, and dysarthria speech-EEG data set will be released to the public to help further advance this interesting and crucial research.",9-Dec-21
1660840,Hmm-Based and Svm-Based Recognition of the Speech of Talkers With Spastic Dysarthria,"This paper studies the speech of three talkers with spastic dysarthria caused by cerebral palsy. All three subjects share the symptom of low intelligibility, but causes differ. First, all subjects tend to reduce or delete word-initial consonants; one subject deletes all consonants. Second, one subject exhibits a painstaking stutter. Two algorithms were used to develop automatic isolated digit recognition systems for these subjects. HMM-based recognition was successful for two subjects, but failed for the subject who deletes all consonants. Conversely, digit recognition experiments assuming a fixed word length (using SVMs) were successful for two subjects, but failed for the subject with the stutter.",24-Jul-06
5495563,Design of a dysarthria classifier using global statistics of speech features,"Dysarthria is a neurological disorder in which the speech production system is impaired. There are five main types of dysarthrias depending on the location of the lesion in the nervous system. There is evidence suggesting a relationship between the location of the lesion and the resulting speech characteristics. This paper describes a non-intrusive classifier to identify the dysarthria type in a person using global statistics, e.g., mean, variance, etc., of speech features. A tree-based classifier was developed using multiple low-level maximum likelihood classifiers as inputs. An error of 10.5% was achieved in the classification of three types of dysarthrias.",28-Jun-10
10157285,Dysarthria Speech Disorder Classification Using Traditional and Deep Learning Models,"Dysarthria is a motor speech disorder that results in speech difficulties due to the weakness of associated muscles. This unclear speech makes it difficult for dysarthric patients to present himself understood. This neurological limitation is usually occurs due to damages to the brain or central nervous system. Speech therapy can be effectively employed to enhance the range and consistency of voice production and improve intelligibility and communicative effectiveness. Assessing the degree of severity of dysarthria provides vital information on the patient's progress which inturn assists pathologists in arriving at a treatment plan that includes developing automated voice recognition system suitable for dysarthria patients. This work performs an exhaustive study on dysarthria severity level classification using deep neural network (DNN) and convolution neural network (CNN) architectures. Mel Frequency Cepstral Coefficients (MFCCs) and their derivatives constitute feature vectors for classification. Using the UA-Speech database, the performance metrics of DNN/CNN based learning models have been compared to baseline classifiers like support vector machine (SVM) and Random Forest (RF). The highest classification accuracy of 97.6\% is reported for DNN under UA speech database. A detailed examination of the performance from the models discussed above reveal that appropriate choice of deep learning architecture ensures better results than traditional classifiers like SVM and Random Forest.",26-Jun-23
10527645,Harnessing Deep Learning Techniques for Dysarthria Detection,"Dysarthria, a motor speech disorder resulting from neurological impairments. This study explores various approaches for the automated detection of dysarthria, integrating both traditional and emerging technologies. Speech assessments by acoustic analysis, machine learning models, and deep learning techniques are considered. Machine learning models are trained on datasets containing normal and dysarthric speech for males and females, while deep learning methods, including convolutional and recurrent neural networks, are employed to automatically learn features from speech data. Our goal is to develop a reliable and accessible dysarthria detection system thatcomplements the expertise of healthcare professionals. Validation using diverse datasets is emphasized, acknowledging the importance of early detection and intervention in improving outcomes for individuals with dysarthria.",16-May-24
10696797,Next-Gen Speech Disorder Diagnostics: CNN Methods for Dysarthria Classification,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. Dysarthria has a significant impact on communication capacity, making early diagnosis essential for effective therapies and improved patient outcomes. The research used a Convolutional Neural Network (CNN) to categorise speech using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. There are 500 samples from each gender in the collection, representing dysarthric and non-dysarthric people who were recorded during different sessions. Highlighting the promise of deep learning technology in aiding early identification of dysarthria and enabling rapid therapy for affected individuals, the CNN-based approach exhibits an amazing 96% accuracy in discriminating between dysarthric and non-dysarthric cases. This study offers a promising chance to enhance the quality of life for those with speech impairments while also making substantial contributions to the development of diagnostic capabilities.",4-Oct-24
10730941,Advancing Speech Disorder Diagnostics: CNN Innovations in Dysarthria Recognition,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. The capacity to communicate is greatly affected by dysarthria, thus early diagnosis is critical for effective therapies and improved patient outcomes. The study employed a Convolutional Neural Network (CNN) for speech classification using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. With 500 samples each, collected over distinct sessions, the dataset contains both dysarthric and non-dysarthric people of both sexes. Distinguishing between dysarthric and non-dysarthric occurrences, the CNN-based approach achieves an astonishing 96% accuracy. This shows how deep learning technology may help with early dysarthria identification and enable rapid therapy for affected individuals. The findings of this study have important implications for the development of diagnostic tools and may lead to better living conditions for those who struggle with speaking.",29-Oct-24
10340908,A preliminary study on self-care telemonitoring of dysarthria in spinal muscular atrophy,"Spinal muscular atrophy (SMA) is a rare neuromuscular disease which may cause impairments in oro-facial musculature. Most of the individuals with SMA present bulbar signs such as flaccid dysarthria which mines their abilities to speak and, as consequence, their psychic balance. To support clinicians, recent work has demonstrated the feasibility of video-based techniques for assessing the oro-facial functions in patients with neurological disorders such as amyotrophic lateral sclerosis. However, no work has so far focused on automatic and quantitative monitoring of dysarthria in SMA. To overcome limitations this work¡¯s aim is to propose a cloud-based store-and-forward telemonitoring system for automatic and quantitative evaluation of oro-facial muscles in individuals with SMA. The system integrates a convolutional neural network (CNN) aimed at identifying the position of facial landmarks from video recordings acquired via a web application by an SMA patient.Clinical relevance¡ª The proposed work is in the preliminary stage, but it represents the first step towards a better understanding of the bulbar-functions¡¯ evolution in patients with SMA.",11-Dec-23
9414283,"Automatic And Perceptual Discrimination Between Dysarthria, Apraxia of Speech, and Neurotypical Speech","Automatic techniques in the context of motor speech disorders (MSDs) are typically two-class techniques aiming to discriminate between dysarthria and neurotypical speech or between dysarthria and apraxia of speech (AoS). Further, although such techniques are proposed to support the perceptual assessment of clinicians, the automatic and perceptual classification accuracy has never been compared. In this paper, we investigate a three-class automatic technique and a set of handcrafted features for the discrimination of dysarthria, AoS and neurotypical speech. Instead of following the commonly used One-versus-One or One-versus-Rest approaches for multi-class classification, a hierarchical approach is proposed. Further, a perceptual study is conducted where speech and language pathologists are asked to listen to recordings of dysarthria, AoS, and neurotypical speech and decide which class the recordings belong to. The proposed automatic technique is evaluated on the same recordings and the automatic and perceptual classification performance are compared. The presented results show that the hierarchical classification approach yields a higher classification accuracy than baseline One-versus-One and One-versus-Rest approaches. Further, the presented results show that the automatic approach yields a higher classification accuracy than the perceptual assessment of speech and language pathologists, demonstrating the potential advantages of integrating automatic tools in clinical practice.",13-May-21
8512311,Quantitative Assessment of Syllabic Timing Deficits in Ataxic Dysarthria,"Parametric analysis of Cerebellar Dysarthria (CD) may be valuable and more informative compared to its clinical assessment. A quantifiable estimation of the timing deficits in repeated syllabic utterance is described in the current study. Thirty-five individuals were diagnosed with cerebellar ataxia to varying degrees and twenty-six age-matched healthy controls were recruited. To automatically detect the local maxima of each syllable in the recorded speech files, a topographic prominence incorporated concept is designed. Subsequently, four acoustic features and eight corresponding parametric measurements are extracted to identify articulatory deficits in ataxic dysarthria. A comparative study on the behaviour of these measures for dysarthric and non-dysarthric subjects is presented in this paper. The results are further explored using a dimensionreduction tool (Principal Component Analysis) to emphasize variation and bring out the strongest discriminating patterns in our feature dataset.",28-Oct-18
10781716,Non-invasive stroke diagnosis using speech data from dysarthria patients,"Acute Ischemic Stroke (AIS) is a major cause of disability and can lead to death in severe cases. A common symptom of AIS, dysarthria, significantly impacts the quality of life of patients. In this study, we developed a deep learning model using dysarthria data for cost-effective and non-invasive brain stroke diagnosis. We utilized models such as ResNet50, InceptionV4, ResNeXt50, SEResNeXt18, and AttResNet50 to effectively extract and classify speech features indicative of stroke symptoms. These models demonstrated high performance, with Sensitivity, Specificity, Precision, Accuracy, and F1-score values reaching 96.77%, 96.08%, 92.82%, 95.52%, and 93.82%, respectively. Our approach offers a non-invasive, cost-effective alternative for early stroke detection, with potential for further accuracy improvements through additional research. This method promises rapid, economical early diagnosis, which could positively impact long-term treatment and healthcare options.",17-Dec-24
10800228,Fine-Tuning Pre-Trained Audio Models for Dysarthria Severity Classification: A Second Place Solution in the Multimodal Dysarthria Severity Classification Challenge,"Dysarthria, a neurological disorder affecting speech, poses significant challenges for automatic diagnosis and severity classification due to its complexity and the scarcity of relevant datasets. This study addresses these challenges by leveraging the dataset provided by the ISCSLP 2024 Multimodal Dysarthria Severity Classification Challenge. Our approach primarily involves two key steps: splitting the training set into training and validation subsets, and fine-tuning pre-trained au-dio models to adapt them to the task. To ensure robust evaluation and prevent label leakage, we employed the StratifiedGroupKFold function from sklearn for dataset splitting, ensuring that training and validation sets do not share participants. This method allowed us to maintain consistent statistical distributions across folds. For model finetuning, we selected two pre-trained audio models, w2v-bert-2.0 and whisper-Iarge-v3, and fine-tuned them on different folds of the dataset. Our results indicate that the w2v-bert-2.0 model fine-tuned on fold-2 achieved the highest performance, with a validation Fl-score of 0.699 and an online score of 7.7452. The experimental results, including confusion matrices and embedding distributions, highlight the model's ability to distinguish between different severity levels of dysarthria. Our approach achieved a commendable second place in the competition¡¯ demonstrating the effectiveness of fine-tuning pre-trained audio models for this task. Future work will explore the integration of multimodal data and multi-task learning strategies to further enhance model performance.",23-Dec-24
10307923,Automated Detection and Severity Assessment of Dysarthria using Raw Speech,"Dysarthria is a medical condition that impairs an individual¡¯s ability to speak clearly due to muscle weakness or paralysis. To diagnose and monitor dysarthria severity, this article proposes the use of a deep learning model that utilizes raw speech waveforms. This approach eliminates the need for feature engineering and enhances the model¡¯s ability to handle noise and speech variability. The proposed system was compared to a standard convolutional neural network (CNN) model and was found to perform better in both dysarthria severity classification and dysarthria/healthy control classification tasks. The results indicate that the SincNet model achieved an accuracy of 95.7% and 99.6% in these tasks, respectively. The proposed system can aid clinicians in diagnosing and monitoring dysarthria severity and could have broader applications in speech-related disorders. The study emphasizes the importance of using raw waveform-based models for speech analysis and demonstrates the effectiveness of SincNet in automatic dysarthria/healthy control classification and dysarthria severity assessment.",23-Nov-23
6936631,Investigation on articulatory and acoustic characteristics of dysarthria,"Direct measurement of articulation contributes to figure out the mechanism of dysarthric speech production accurately, comparing to analyzing acoustic signal alone. This study makes a statistical comparison between dysarthric and normal speech, and investigates and analyzes dysarthric characteristics based on articulatory and acoustic data of continuous English utterance. The distribution of the articulatory point is calculated for each vowel, where the vowels show a relatively smaller region for dysarthria than for normal speech. This implies that the speakers with dysarthria may have some difficulties to fully use the articulatory space as the speakers without dysarthria. The rhythm and sound source are analyzed using autocorrelation function, power spectrum and linear prediction coding. The results reveal that the speakers without dysarthria can keep steady rhythm and energy in uttering consonant-vowel repetition sequences but it is hard for the speakers with dysarthria to maintain the stability. Meanwhile, the dysarthric sound source shows unstable period of the fundamental frequency, which reflects that the speakers with dysarthria could not control the glottis movement well.",27-Oct-14
10550236,Evolving Diagnostic Techniques for Speech Disorders: Investigating Dysarthria Classification Through DenseNet201 CNN Framework,"The primary subject of this research work pertains to dysarthria, a prevalent speech impairment observed in individuals diagnosed with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Prompt detection of dysarthria is essential for effective therapies and improved patient results, as it significantly impacts communication proficiency. The research employed a DenseNet201 Convolutional Neural Network (CNN) to categorize speech using the TORGO database, which has 2000 samples of individuals with and without dysarthria, representing various genders. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each dataset consists of 500 samples, which were collected during distinct sessions. The DenseNet201 convolutional neural network (CNN) technique has a notable accuracy rate of 96% in distinguishing between cases of dysarthria and non-dysarthria. This outcome underscores the potential of deep learning technology in aiding the timely identification of dysarthria and facilitating fast interventions for affected individuals. This work provides valuable insights on the progress of diagnostic capabilities and offers a potential avenue for enhancing the well-being of those experiencing speech impairments.",11-Jun-24
10902941,Analysis of Features for Dysarthria Severity Classification from Speech,"Dysarthria is a disorder that affects the ability of an individual to speak clearly. Diagnosis of the severity of dysarthria can aid in providing appropriate therapy to the individual. Therefore, the current work focuses on identifying features that can be used to estimate the severity of dysarthria. In this regard, two feature sets are considered, namely DisVoice and OpenSMILE, and the genetic algorithm is used to identify the most suitable list of features from both feature sets using 3 speech corpora, namely SSN-TDSC, Torgo, and UA Speech corpora. In order to test the effectiveness of these features, classifiers are trained on each feature set as a whole and on the features identified by the genetic algorithm, and their performance compared. It is observed that articulatory and prosodic features are most important in the diagnosis of severity of dysarthria. A maximum accuracy of 85% is obtained with the shortlisted DisVoice features and 97% with the OpenSMILE features.",5-Mar-25
10800159,Multi-Modal Dysarthria Severity Assessment Using Dual-Branch Feature Decoupling Network and Mixed Expert Framework,"Dysarthria, a motor speech disorder resulting from neurological damage, significantly impairs an individual's ability to articulate words. Assessing the severity of dysarthria is crucial for effective therapeutic interventions and rehabilitation strategies. However, current methods are time-consuming and subjective, leading to potential inconsistencies. This study proposed a dual-branch feature decoupling network and mixed expert framework for the automatic diagnosis and assessment of dysarthria. The proposed hybrid network architecture integrates a ResNet-based branch for audio data with an attention module and a 3D ResNet branch for video data, and was evaluated on the Multimodal Dysarthria Severity Assessment Challenge (MDSA) dataset, achieving significant performance improvements and ranking first in the challenge with a best score of 8.7404. The study's findings highlight the efficacy of the proposed framework in capturing essential features from multimodal data, contributing to more accurate and reliable assessments of dysarthria.",23-Dec-24
10448175,Spectral Analysis of Vowels and Fricatives at Varied Levels of Dysarthria Severity for Amyotrophic Lateral Sclerosis,"Dysarthria due to Amyotrophic Lateral Sclerosis (ALS) affects the acoustic characteristics of different speech sounds. The effects intensify with increasing severity leading to the collapse of the acoustic space of the affected individuals. With an aim to characterize such changes in the acoustic space, this paper studies the variations in band-specific and full-band spectral properties of 4 sustained vowels (/a/, /i/, /o/, /u/) and 3 sustained fricatives (/s/, /sh/, /f/) at different dysarthria severity levels. Effect of dysarthria on spectral features of these phonemes are not well explored. Statistical comparison of these features among different severities for the phonemes considered and among different vowels/fricatives for every severity level using speech data from 119 ALS and 40 healthy subjects indicate the followings. Though all band-specific and full-band features of the three fricatives and most of those features for the four vowels become statistically similar at high severity levels, certain features remain distinguishable. Spectral differences in 0-2 kHz band between /a/ and the other vowels and in the 2-6 kHz band between /a/ and /o/, /u/ persist through all severity levels. Moreover, properties of /f/ remain mostly unchanged with increasing dysarthria severity levels.",18-Mar-24
10673651,Advancing Speech Disorder Diagnostics: A Comprehensive Study on Dysarthria Classification with CNN,"This study article focuses on dysarthria, a speech problem that is often seen in patients with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early identification of dysarthria is crucial for successful treatments and better patient outcomes, since it has a substantial influence on communication ability. Using the TORGO database, which consists of 2000 samples of persons with and without dysarthria, spanning different genders, the research use a Convolutional Neural Network (CNN) to classify speech. The dataset includes both dysarthric and non-dysarthric individuals of both genders, with 500 samples each, captured during separate sessions. The CNN-based technique demonstrates an impressive 96% accuracy in differentiating between dysarthric and non-dysarthric instances, highlighting the promise of deep learning technology in assisting with the early detection of dysarthria and enabling prompt therapies for afflicted people. This study makes significant contributions to the advancement of diagnostic capacities and presents a potential opportunity to improve the quality of life for those with speech difficulties.",18-Sep-24
10581063,Progressing Speech Disorder Identification: A Thorough Investigation into Dysarthria Categorization Utilizing ResNet50 CNN,"The speech issue of dysarthria, which is frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS), is the subject of this research article. Timely detection of dysarthria is essential for effective interventions and improved patient results, as it significantly impacts communication proficiency. The study employs the TORGO database, which has 2000 samples of individuals with and without dysarthria, encompassing various genders. The researchers utilize a ResNet50 Convolutional Neural Network (CNN) to categorize speech. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each group consists of 500 samples, which were recorded over distinct sessions. The CNN-based technique achieves a remarkable 96% accuracy in distinguishing between dysarthric and non-dysarthric instances. This underscores the potential of deep learning technology in aiding the early identification of dysarthria and facilitating timely treatments for affected individuals. This study provides valuable contributions to the enhancement of diagnostic capabilities and offers a potential avenue for enhancing the quality of life for individuals experiencing speech impairments.",12-Jul-24
10625627,Enhancing the Diagnosis of Speech Disorders: An In-Depth Investigation into Dysarthria Classification Using the ResNet18 Model,"This research article concentrates on dysarthria, a speech impediment commonly observed in individuals with conditions such as cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective interventions and improved patient outcomes, as it significantly impacts communication abilities. Employing the TORGO database, comprising 2000 samples from individuals with and without dysarthria, encompassing diverse genders, the study utilizes a Convolutional Neural Network (ResNet18 Model) for speech classification. The dataset encompasses both dysarthric and non-dysarthric subjects of both genders, with 500 samples each, recorded in separate sessions. The ResNet18 Model-based approach demonstrates an impressive 96% accuracy in distinguishing between dysarthric and non-dysarthric instances, underscoring the potential of deep learning technology in aiding early dysarthria detection and facilitating timely interventions. This investigation significantly contributes to advancing diagnostic capabilities and presents a promising avenue to enhance the quality of life for individuals grappling with speech difficulties.",22-Aug-24
10095366,Statistical Analysis of Speech Disorder Specific Features to Characterise Dysarthria Severity Level,"Poor coordination of the speech production subsystems due to any neurological injury or a neuro-degenerative disease leads to dysarthria, a neuro-motor speech disorder. Dysarthric speech impairments can be mapped to the deficits caused in phonation, articulation, prosody, and glottal functioning. With the aim of reducing the subjectivity in clinical evaluations, many automated systems are proposed in the literature to assess the dysarthria severity level using these features. This work aims to analyse the suitability of these features in determining the severity level. A detailed investigation is done to rank these features for their efficacy in modelling the pathological aspects of dysarthric speech, using the technique of paraconsistent feature engineering. The study used two dysarthric speech databases, UA-Speech and TORGO. It puts light into the fact that both the prosody and articulation features are best useful for dysarthria severity estimation, which was supported by the classification accuracies obtained on using different machine learning classifiers.",5-May-23
8251336,Identification of Cerebellar Dysarthria with SISO Characterisation,"Quantitative identification of dysarthria plays a major role in the classification of its severity. This paper quantitatively analyses several components of cerebellar dysarthria. The methodology described in this study will be extended to other types of dysarthria via systematic analysis. The speech production model is characterized as a second-order singleinput and single-output (SISO), linear, time-invariant (LTI) system in our study. A comparative study on the behavior of the damping ratio and resonant frequency for dysarthric and non-dysarthric subjects is presented. The results are further analyzed using the Principal component analysis (PCA) technique to emphasize the variation and uncover strong patterns in the selected features. The effects of some other related factors like decay time and Q-factor are also highlighted.",11-Jan-18
10739183,CNN-Driven Innovations in Dysarthria Classification and Speech Disorder Management,"This research article addresses dysarthria, a speech disorder frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective treatment and improved patient outcomes, as it significantly impacts communication abilities. Utilizing the TORGO database, which comprises 2000 speech samples from both dysarthric and non-dysarthric individuals across various genders, this study employs a Convolutional Neural Network (CNN) for classification. The dataset includes 500 samples each from both groups, collected in different sessions. The CNN approach achieves an impressive 96% accuracy in distinguishing dysarthric from non-dysarthric speech, showcasing the potential of deep learning technology in facilitating early dysarthria diagnosis and enabling timely interventions. This study makes substantial contributions to enhancing diagnostic capabilities and offers a promising avenue for improving the quality of life for individuals with speech disorders.",4-Nov-24
10800051,Constant Q Transform for Audio-Visual Dysarthria Severity Assessment,"This paper describes an automatic dysarthria severity assessment system submitted for the MDSA2024 challenge. The system utilizes audio and visual features to classify the severity of dysarthria. We investigate the effectiveness of different acoustic feature combinations, such as Mel spectrogram, filterbank and constant Q transform. Different encoders for audio data processing are compared in the experiments. The results demonstrate that the Conformer encoder achieves superior performance compared to the Densenet encoder on pure audio features. We further explore model-level fusion by combining audio and visual embeddings, leading to improvements in precision¡¯ recall, and accuracy metrics. The best-achieved score on the test set is 7.5579, with an individual F1-score of 0.7028. The findings suggest that the proposed system with Conformer encoder and model-level fusion holds promise for automatic dysarthria assessment.",23-Dec-24
10781584,Dysarthria Detection with Deep Representation Learning for Patients with Parkinson¡¯s Disease,"Dysarthria is a very common motor speech symptom in Parkinson¡¯s disease impairing normal communications of patients. Detection of dysarthria could assist clinical diagnosis and intervention of Parkinson¡¯s disease, provide monitoring approach for treatment-related side effects, and lead to effective speech therapy to prevent further communication and social deficits. Applying machine learning techniques to speech analysis for patients offers more resource-efficient, accessible and objective tools for screening and assessment of dysarthria. In this study, we constructed a multi-task speech dataset recorded from 600 participants with high data diversity to facilitate the development of detection models. We established a remote data acquisition and end-to-end prediction pipeline with deep representation learning, compared the performance with different feature-based learning and classification methods, and achieved a superior accuracy of over 90%. Different affecting factors were analyzed for model performance. Our proposed framework demonstrates the potential of developing and deploying an automated self-monitoring approach of dysarthria for patients with Parkinson¡¯s disease, which could benefit a large-scale population and their disease managements.",17-Dec-24
7953122,Automatic assessment of dysarthria severity level using audio descriptors,"Dysarthria is a motor speech impairment, often characterized by speech that is generally indiscernible by human listeners. Assessment of the severity level of dysarthria provides an understanding of the patient's progression in the underlying cause and is essential for planning therapy, as well as improving automatic dysarthric speech recognition. In this paper, we propose a non-linguistic manner of automatic assessment of severity levels using audio descriptors or a set of features traditionally used to define timbre of musical instruments and have been modified to suit this purpose. Multitapered spectral estimation based features were computed and used for classification, in addition to the audio descriptors for timbre. An Artificial Neural Network (ANN) was trained to classify speech into various severity levels within Universal Access dysarthric speech corpus and the TORGO database. An average classification accuracy of 96.44% and 98.7% was obtained for UA speech corpus and TORGO database respectively.",19-Jun-17
9287741,Automated Dysarthria Severity Classification Using Deep Learning Frameworks,"Dysarthria is a neuro-motor speech disorder that renders speech unintelligible, in proportional to its severity. Assessing the severity level of dysarthria, apart from being a diagnostic step to evaluate the patient's improvement, is also capable of aiding automatic dysarthric speech recognition systems. In this paper, a detailed study on dysarthia severity classification using various deep learning architectural choices, namely deep neural network (DNN), convolutional neural network (CNN) and long short-term memory network (LSTM) is carried out. Mel frequency cepstral coefficients (MFCCs) and its derivatives are used as features. Performance of these models are compared with a baseline support vector machine (SVM) classifier using the UA-Speech corpus and the TORGO database. The highest classification accuracy of 96.18% and 93.24% are reported for TORGO and UA-Speech respectively. Detailed analysis on performance of these models shows that a proper choice of a deep learning architecture can ensure better performance than the conventionally used SVM classifier.",18-Dec-20
10584052,Deep Learning Based Speech Recognition for Hyperkinetic Dysarthria Disorder,"Speech recognition is a technology that aims to transform human speech into text and has applications in a variety of fields, including information technology, healthcare, automobiles, and others. This research explores the advantages of employing deep learning methods to provide individualized assistance technology solutions for people with dysarthria. We proposed a Convolutional Temporal Bidirectional Network (CTBNet) model for translating Russian Hyperkinetic Dysarthria Disorder (RHDD) speech into text. CTBNet encodes input audio features using 1D convolution layers, and BidirectionalGRU (Bi-GRU) layers. The encoder effectively captures both short-term and long-term spatial temporal information. More importantly, CTBNet includes with an attention-CTC decoder, that is responsible for producing output texts. We utilized a dataset of 2797 recordings of RHDD speech, with a cumulative recorded duration of 2 hours and 33 minutes, for training purposes. The CTBNet model has achieved a 15% Character Error Rate (CER) and a 59% Word Error Rate (WER) on the dataset proposed. Our experimental findings show superior performance compared to state-of-the-art models, namely, 3xCNN, and 3xLSTM, when evaluated on the same dataset.",9-Jul-24
10889800,Multilingual Speaker-Invariant Dysarthria Severity Assessment Using Adversarial Domain Adaptation and Self-Supervised Learning,"Traditional assessments for dysarthria are subjective and time-consuming, highlighting the need for automated, objective approaches that can be scaled for remote and resource-constrained environments. This paper introduces an adversarial domain adaptation framework tailored for dysarthria severity assessment, addressing the challenges of high intra-class variability and limited availability of dysarthric speech data. By framing speaker variability as a domain adaptation problem, we utilise an adversarially trained feature extractor to derive speaker-invariant yet discriminatively powerful representations utilising speech features learned through self-supervised learning. Experiments on previously unseen and diverse speakers reveal that the proposed approach yields a 7.86% average improvement across multilingual datasets compared to traditional severity-discriminative training, outperforming competitive baselines by 12.33% on average. Additionally, the method inherently supports privacy-preserving applications by minimising reliance on speaker-specific information. The results demonstrate strong alignment with clinical assessments, reinforcing our model¡¯s clinical relevance and effectiveness.",7-Mar-25
10929844,AI-Enabled Speech Monitoring for Dysarthria Detection in Consumer Electronics,"Speech is essential in human communication, and recent advancements in artificial intelligence (AI) have enabled new applications for voice data, particularly in health monitoring. Building on this progress, a home-based health detection system that utilizes voice signals provides an accessible method for users to independently identify and respond to conditions such as dysarthria, without the need for hospital or clinic visits. In this study, we developed and evaluated convolutional neural network (CNN) models to classify audio data from both healthy individuals and individuals with dysarthria. The dataset comprised command-based speech samples, which were segmented into sentence-specific input. Preprocessing steps included segmentation, downsampling, and feature extraction tailored for CNN input. The models exhibited high potential in distinguishing between normal and dysarthric states, with the most effective model achieving an f1-score of 96.18¡À4.7% and an accuracy of 96.01¡À5.02%. Furthermore, sentence structure and composition significantly influenced model performance, with specific sentences demonstrating higher classification accuracy. These findings suggest that AI-driven speech analysis may support detecting and managing specific health conditions in non-clinical environments. However, further work is needed to address data imbalance and sentence variability limitations. Future research could expand on real-world applications, particularly in settings with limited traditional health monitoring.",26-Mar-25
10848959,Dysarthria Severity Classification Using Phase Based Features of LP Residual,"Classifying the severity of speech impairment due to dysarthria is crucial for optimizing care and enhancing communication abilities for affected individuals. This study explores the use of the Modified Group Delay Function (MGDF) of LP residual signal in classifying dysarthria severity-levels. Evaluations were conducted using standard UA-Speech and TORGO datasets. A stratified Convolutional Neural Network (CNN) with 5-fold cross-validation validated the results. Baseline features included Linear Frequency Cepstral Coefficients (LFCC), Mel Frequency Cepstral Coefficients (MFCC), and Whisper module. Key performance evaluation metrics were accuracy, precision, recall, and F1-score. Finally, the latency period was analyzed for practical deployment of the system, system¡¯s ability to accurately recognize and process speech from any speaker, without needing to be specifically trained or adapted to individual voice characteristics.",27-Jan-25
10200180,Automatic Early Detection of Dysarthria using Deep Neural Network,"Dysarthria is dis-coordination among articulatory muscles responsible for articulation in the production of speech. A person with dysarthric disorder cannot control their tongue, hence, are prone to slurred speech or swallowing words which lead to improper pronunciation and less intelligibility of speech. This work focuses on the automatic early detection of Dysarthria. To elucidate the main idea, it must be understood that the whole detection procedure revolves around the speech intelligibility of a person. It becomes an arduous job to distinguish between a healthy person's speech and a person who is slowly evolving with the disorder. The prime motive of the work is to provide a proper classification of the disorder in its earliest stages. The common words and phrases recorded in the Universal Access database are used for this work. Mel Frequency Cepstral Coefficients (MFCC) are extracted from both controlled and high intelligible speech data, and fed to a Deep Neural Network (DNN) classifier. MFCC fed to the DNN classifier has provided the best classification accuracy for the above experimental setup.",7-Aug-23
8682324,Learning to Detect Dysarthria from Raw Speech,"Speech classifiers of paralinguistic traits traditionally learn from diverse hand-crafted low-level features, by selecting the relevant information for the task at hand. We explore an alternative to this selection, by learning jointly the classifier, and the feature extraction. Recent work on speech recognition has shown improved performance over speech features by learning from the waveform. We extend this approach to paralinguistic classification and propose a neural network that can learn a filterbank, a normalization factor and a compression power from the raw speech, jointly with the rest of the architecture. We apply this model to dysarthria detection from sentence-level audio recordings. Starting from a strong attention-based baseline on which mel-filterbanks outperform standard low-level descriptors, we show that learning the filters or the normalization and compression improves over fixed features by 10% absolute accuracy. We also observe a gain over OpenSmile features by learning jointly the feature extraction, the normalization, and the compression factor with the architecture. This constitutes a first attempt at learning jointly all these operations from raw audio for a speech classification task.",17-Apr-19
7078586,Modeling fundamental frequency dynamics in hypokinetic dysarthria,"Hypokinetic dysarthria (Hd), which often accompanies Parkinson's Disease (PD), is characterized by hypernasality and by compromised phonation, prosody, and articulation. This paper proposes automated methods for detection of Hd. Whereas most such studies focus on measures of phonation, this paper focuses on prosody, specifically on fundamental frequency (F0) dynamics. Prosody in Hd is clinically described as involving monopitch, which has been confirmed in numerous studies reporting reduced within-utterance pitch variability. We show that a new measure of F0 dynamics, based on a superpositional pitch model that decomposes the F0 contour into a declining phrase curve and (generally, single-peaked) accent curves, performs more accurate Hd vs. Control classification than simpler versions of the model or than conventional variability statistics.",2-Apr-15
8361563,Automatic detection of speech disorder in dysarthria using extended speech feature extraction and neural networks classification,"This paper presents an automatic detection of Dysarthria, a motor speech disorder, using extended speech features called Centroid Formants. Centroid Formants are the weighted averages of the formants extracted from a speech signal. This involves extraction of the first four formants of a speech signal and averaging their weighted values. The weights are determined by the peak energies of the bands of frequency resonance, formants. The resulting weighted averages are called the Centroid Formants. In our proposed methodology, these centroid formants are used to automatically detect Dysarthric speech using neural network classification technique. The experimental results recorded after testing this algorithm are presented. The experimental data consists of 200 speech samples from 10 Dysarthric speakers and 200 speech samples from 10 age-matched healthy speakers. The experimental results show a high performance using neural networks classification. A possible future research related to this work is the use of these extended features in speaker identification and recognition of disordered speech.",21-May-18
9076507,Analysis of Time Domain Features of Dysarthria Speech,"In general, Speech can be described as the ability to express thoughts and feelings by articulating sounds in order to communicate with the person who understand the speech and accordingly interpret their action. The types of communication disorders that affects a person¡¯s ability to produce speech sounds due to the lack of control over motor functions and articulators are speech disorders. Many people of varying age groups suffer from speech disorders and require early treatment in order to correct them. This paper analyses the time domain features such as jitter and shimmer that are extracted from the speech samples of dysarthria and healthy people. This is done by looking for dissimilarities between the different speech features preset in the normal healthy person and the disordered one by employing steps such as pre-processing followed by feature extraction.",23-Apr-20
9291830,Emotional Communication Assist Interface App for People with Dysarthria,"Text to speech (TTS) helps people who have speech disorders communicate with other people. The current TTS can express emotion, but this requires extra time and effort. We developed a TTS application by which users can render messages with emotion with ease by changing the pitch angle of a smartphone. We designed two types of TTS: free input and phrase selection. Also, we calculated the TTS editing parameters for each degree of emotion on the basis of the Online Game Voice Chat Corpus (OGVC).",21-Dec-20
10661368,Fuzzy Expectation Maximization Phoneme Prediction in Diffusion Model-based Dysarthria Voice Conversion,"In this paper proposed an effective fuzzy expectation-maximization phoneme prediction method in diffusion model-based dysarthria voice conversion (FEMPPDM-DVC) which is accessible to (i) training without parallel data (ii) converting a longer duration of the audio data (iii) preserves speaker identity. By integrating Fuzzy Expectation-Maximization (FEM) clustering and Diffusion model-based dysarthria voice conversion approach, the proposed method is able gradually generate normal utterances. Feature extraction is performed using Mel-frequency cepstral coefficients (MFCCs), a robust method in acoustic feature extraction in Text-to-Speech systems. Ensures the effectiveness and accuracy, through repeated parameter adjustment using the FEM clustering algorithm. The conversion network is a diffusion model-based structure, which can convert normal utterances to dysarthria utterances in the forward diffusion process. After forward diffusion process, the dysarthria utterance will go through a reverse diffusion process to convert dysarthria voice to normal utterance. Once converted, a GAN-based vocoder is applied to convert mel-frequency spectrogram to waveform. Objective evaluation is conducted on the Saarbr¨¹cken Voice Database (SVD) dataset show that FEMDDPM-DVC is able to improve the intelligibility and naturalness of dysarthria utterances in 15 kinds of dysarthria voice. The proposed method is compared with five other dysarthria voice conversion methods, show that the proposed method has the most performance among other method.",6-Sep-24
10912315,Revolutionary Dysarthria Analysis Through Convolutional Neural Networks,"Dysarthria occurs when there are impairments in the muscles necessary for speech, including those in the lips, tongue, voice box, and breathing muscles. This condition can result in unclear speech, even in individuals who are skilled communicators. Dysarthria can range from mild speech difficulties, where speech is hard to understand, to severe cases, where speech is completely unclear. A method for distinguishing between different types of speech involves using recordings and advanced computational techniques such as convolutional neural networks (CNNs). The strengths of CNNs are leveraged to construct a highly effective model for detecting dysarthria in speech samples. The dataset utilized includes recordings from individuals with and without dysarthria. The results indicate that the CNN model performs exceptionally well, achieving precision, recall, and F1-scores of 0.99 for both categories. With an accuracy of 0.99, the model demonstrates a high level of proficiency in differentiating between speech affected by dysarthria and normal speech. These findings highlight the effectiveness and utility of this CNN-based approach in diagnosing and assessing dysarthria. It offers valuable potential for assisting healthcare professionals and enhancing personalized speech therapy interventions.",13-Mar-25
10675073,A Study of Speech Recognition Techniques for Dysarthria Speeches Based on Digit Recognition,"With the introduction of speech recognition technology into people's lives, the application of which is no longer limited to ordinary people, but begins to target special populations, such as patients with dysarthria. It has become a major research challenge to build a high-performance speech recognition system for patients with dysarthria. To address this problem, in this paper the speech data of four patients with dysarthria and four healthy speakers on digital commands are firstly collected, secondly several speech recognition experiments are separately conducted by using Aishell-2 and Wenetspeech, two pre-trained models based on the WeNet open-source architecture, as well as the four major commercial recognition API systems, at the end a method to optimize the dysarthria data by using the so-vits-svc tool is proposed. The experiments show that the current state-of-the-art speech recognition model has a high recognition rate for speech data from the general population, but there is still room for improvement in the recognition performance of speech data from individuals with dysarthria. Later the optimization method for the dysarthria data proposed in this paper effectively improves the quality of speech data. For the two above open-source pre-trained models, the recognition rates have increased by 60% and 67.64 % compared to the original data, respectively.",24-Sep-24
7897299,Fractal features for automatic detection of dysarthria,"Amytrophic lateral sclerosis (ALS) is an incurable neurodegenerative disease. Difficulty articulating speech, dysarthria, is a common early symptom of ALS. Detecting dysarthria currently requires manual analysis of several different speech tasks by pathology experts. This is time consuming and can lead to misdiagnosis. Many existing automatic classification approaches require manually preprocessing recordings, separating individual spoken utterances from a repetitive task. In this paper, we propose a fully automated approach which does not rely on manual preprocessing. The proposed method uses novel features based on fractal analysis. Acoustic and associated articulatory recordings of a standard speech diagnostic task, the diadochokinetic test (DDK), are used for classification. This study's experiments show that this approach attains 90.2% accuracy with 94.2% sensitivity and 85.1% specificity.",13-Apr-17
6190184,Assessing Dysarthria severity using global statistics and boosting,"A new method for automatic assessment of Dysarthria severity is described. It uses the forward selection method (FSM) on global statistics of low-complexity features to find effective feature sets. FSM is embedded in a boosting algorithm that combines multiple weak classifiers to achieve a single strong classifier. Unlike standard boosting, this uses nonlinear class boundaries and unique feature sets per iteration. Results on a 39 speaker dysarthria database are described.",26-Apr-12
10250600,An Intelligent System for Dysarthria Classification of Male and Female Processed Dataset using Sequential Model Parameters,"There are several current studies including various methods for treating dysarthria in various developing countries. Research-based dysarthria treatments take a multidisciplinary approach that encompasses speech therapy, assistive technology, neurosurgery, pharmaceutical therapies, non-invasive brain stimulation, machine learning and AI methods. These methods seek to raise the general quality of life, communication and speaking abilities of dysarthria sufferers. With a 90% accuracy rate, the proposed sequential model was found to have good classification performance for identifying Dysarthria. Researchers have also been looking at the use of Machine Learning (ML) and Artificial Intelligence (AI) approaches to create tools and systems that can help people with dysarthria to speak and communicate for social welfare and provide access to best remedies.",22-Sep-23
7344537,Dysarthria diagnosis via respiration and phonation,This report discusses the implementation of a computerized application - the Computerised Frenchay Dysarthria Assessment Procedure (CFDA) - which uses digital signal processing (DSP) techniques to objectively evaluate digitised speech recordings in order to detect any symptoms of dysarthria (a type of motor speech disorder). This investigation focuses specifically on two CFDA diagnostic sub-applications which assess a patient's ability to maintain a prolonged exhalation (the ¡°Respiration at Rest¡± task) as well as execute a steady state phonation (i.e. the ¡°Sustained Phonation¡± task). It is demonstrated that combining the functionality of these two sub-applications substantially increases their diagnostic effectiveness in the context of identifying a particular variety of dysarthria known as spastic dysarthria. It is further demonstrated that certain patterns of energy fluctuations are closely correlated with manifestations of spastic dysarthria. The CFDA is intended for use in real-world conditions to assist speech and language therapists when conducting clinical evaluations.,3-Dec-15
10892620,Deep Learning Based Dysarthria Detection: A Comprehensive Approach,"Making a model that can analyze numerous input features and predict whether a person will develop dysarthria is the first step in utilizing machine learning to forecast diseases like dysarthria. A motor speech disorder called dysarthria can be caused by a variety of underlying conditions, such as degenerative disorders, traumatic brain injuries, or neurological disorders. The authors used the 2000 audio signals from males and females with and without dysarthria from the TORGO data set. To extract the important features from the audio signals, the authors used the MFCC approach. To determine if dysarthria is present or absent, a machine learning model or algorithm will be fed with these MFCC coefficients.",25-Feb-25
9629802,"Brain Signals to Rescue Aphasia, Apraxia and Dysarthria Speech Recognition","In this paper, we propose a deep learning-based algorithm to improve the performance of automatic speech recognition (ASR) systems for aphasia, apraxia, and dysarthria speech by utilizing electroencephalography (EEG) features recorded synchronously with aphasia, apraxia, and dysarthria speech. We demonstrate a significant decoding performance improvement by more than 50% during test time for isolated speech recognition task and we also provide preliminary results indicating performance improvement for the more challenging continuous speech recognition task by utilizing EEG features. The results presented in this paper show the first step towards demonstrating the possibility of utilizing non-invasive neural signals to design a real-time robust speech prosthetic for stroke survivors recovering from aphasia, apraxia, and dysarthria. Our aphasia, apraxia, and dysarthria speech-EEG data set will be released to the public to help further advance this interesting and crucial research.",9-Dec-21
1660840,Hmm-Based and Svm-Based Recognition of the Speech of Talkers With Spastic Dysarthria,"This paper studies the speech of three talkers with spastic dysarthria caused by cerebral palsy. All three subjects share the symptom of low intelligibility, but causes differ. First, all subjects tend to reduce or delete word-initial consonants; one subject deletes all consonants. Second, one subject exhibits a painstaking stutter. Two algorithms were used to develop automatic isolated digit recognition systems for these subjects. HMM-based recognition was successful for two subjects, but failed for the subject who deletes all consonants. Conversely, digit recognition experiments assuming a fixed word length (using SVMs) were successful for two subjects, but failed for the subject with the stutter.",24-Jul-06
5495563,Design of a dysarthria classifier using global statistics of speech features,"Dysarthria is a neurological disorder in which the speech production system is impaired. There are five main types of dysarthrias depending on the location of the lesion in the nervous system. There is evidence suggesting a relationship between the location of the lesion and the resulting speech characteristics. This paper describes a non-intrusive classifier to identify the dysarthria type in a person using global statistics, e.g., mean, variance, etc., of speech features. A tree-based classifier was developed using multiple low-level maximum likelihood classifiers as inputs. An error of 10.5% was achieved in the classification of three types of dysarthrias.",28-Jun-10
10157285,Dysarthria Speech Disorder Classification Using Traditional and Deep Learning Models,"Dysarthria is a motor speech disorder that results in speech difficulties due to the weakness of associated muscles. This unclear speech makes it difficult for dysarthric patients to present himself understood. This neurological limitation is usually occurs due to damages to the brain or central nervous system. Speech therapy can be effectively employed to enhance the range and consistency of voice production and improve intelligibility and communicative effectiveness. Assessing the degree of severity of dysarthria provides vital information on the patient's progress which inturn assists pathologists in arriving at a treatment plan that includes developing automated voice recognition system suitable for dysarthria patients. This work performs an exhaustive study on dysarthria severity level classification using deep neural network (DNN) and convolution neural network (CNN) architectures. Mel Frequency Cepstral Coefficients (MFCCs) and their derivatives constitute feature vectors for classification. Using the UA-Speech database, the performance metrics of DNN/CNN based learning models have been compared to baseline classifiers like support vector machine (SVM) and Random Forest (RF). The highest classification accuracy of 97.6\% is reported for DNN under UA speech database. A detailed examination of the performance from the models discussed above reveal that appropriate choice of deep learning architecture ensures better results than traditional classifiers like SVM and Random Forest.",26-Jun-23
10527645,Harnessing Deep Learning Techniques for Dysarthria Detection,"Dysarthria, a motor speech disorder resulting from neurological impairments. This study explores various approaches for the automated detection of dysarthria, integrating both traditional and emerging technologies. Speech assessments by acoustic analysis, machine learning models, and deep learning techniques are considered. Machine learning models are trained on datasets containing normal and dysarthric speech for males and females, while deep learning methods, including convolutional and recurrent neural networks, are employed to automatically learn features from speech data. Our goal is to develop a reliable and accessible dysarthria detection system thatcomplements the expertise of healthcare professionals. Validation using diverse datasets is emphasized, acknowledging the importance of early detection and intervention in improving outcomes for individuals with dysarthria.",16-May-24
10696797,Next-Gen Speech Disorder Diagnostics: CNN Methods for Dysarthria Classification,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. Dysarthria has a significant impact on communication capacity, making early diagnosis essential for effective therapies and improved patient outcomes. The research used a Convolutional Neural Network (CNN) to categorise speech using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. There are 500 samples from each gender in the collection, representing dysarthric and non-dysarthric people who were recorded during different sessions. Highlighting the promise of deep learning technology in aiding early identification of dysarthria and enabling rapid therapy for affected individuals, the CNN-based approach exhibits an amazing 96% accuracy in discriminating between dysarthric and non-dysarthric cases. This study offers a promising chance to enhance the quality of life for those with speech impairments while also making substantial contributions to the development of diagnostic capabilities.",4-Oct-24
10730941,Advancing Speech Disorder Diagnostics: CNN Innovations in Dysarthria Recognition,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. The capacity to communicate is greatly affected by dysarthria, thus early diagnosis is critical for effective therapies and improved patient outcomes. The study employed a Convolutional Neural Network (CNN) for speech classification using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. With 500 samples each, collected over distinct sessions, the dataset contains both dysarthric and non-dysarthric people of both sexes. Distinguishing between dysarthric and non-dysarthric occurrences, the CNN-based approach achieves an astonishing 96% accuracy. This shows how deep learning technology may help with early dysarthria identification and enable rapid therapy for affected individuals. The findings of this study have important implications for the development of diagnostic tools and may lead to better living conditions for those who struggle with speaking.",29-Oct-24
10340908,A preliminary study on self-care telemonitoring of dysarthria in spinal muscular atrophy,"Spinal muscular atrophy (SMA) is a rare neuromuscular disease which may cause impairments in oro-facial musculature. Most of the individuals with SMA present bulbar signs such as flaccid dysarthria which mines their abilities to speak and, as consequence, their psychic balance. To support clinicians, recent work has demonstrated the feasibility of video-based techniques for assessing the oro-facial functions in patients with neurological disorders such as amyotrophic lateral sclerosis. However, no work has so far focused on automatic and quantitative monitoring of dysarthria in SMA. To overcome limitations this work¡¯s aim is to propose a cloud-based store-and-forward telemonitoring system for automatic and quantitative evaluation of oro-facial muscles in individuals with SMA. The system integrates a convolutional neural network (CNN) aimed at identifying the position of facial landmarks from video recordings acquired via a web application by an SMA patient.Clinical relevance¡ª The proposed work is in the preliminary stage, but it represents the first step towards a better understanding of the bulbar-functions¡¯ evolution in patients with SMA.",11-Dec-23
9414283,"Automatic And Perceptual Discrimination Between Dysarthria, Apraxia of Speech, and Neurotypical Speech","Automatic techniques in the context of motor speech disorders (MSDs) are typically two-class techniques aiming to discriminate between dysarthria and neurotypical speech or between dysarthria and apraxia of speech (AoS). Further, although such techniques are proposed to support the perceptual assessment of clinicians, the automatic and perceptual classification accuracy has never been compared. In this paper, we investigate a three-class automatic technique and a set of handcrafted features for the discrimination of dysarthria, AoS and neurotypical speech. Instead of following the commonly used One-versus-One or One-versus-Rest approaches for multi-class classification, a hierarchical approach is proposed. Further, a perceptual study is conducted where speech and language pathologists are asked to listen to recordings of dysarthria, AoS, and neurotypical speech and decide which class the recordings belong to. The proposed automatic technique is evaluated on the same recordings and the automatic and perceptual classification performance are compared. The presented results show that the hierarchical classification approach yields a higher classification accuracy than baseline One-versus-One and One-versus-Rest approaches. Further, the presented results show that the automatic approach yields a higher classification accuracy than the perceptual assessment of speech and language pathologists, demonstrating the potential advantages of integrating automatic tools in clinical practice.",13-May-21
8512311,Quantitative Assessment of Syllabic Timing Deficits in Ataxic Dysarthria,"Parametric analysis of Cerebellar Dysarthria (CD) may be valuable and more informative compared to its clinical assessment. A quantifiable estimation of the timing deficits in repeated syllabic utterance is described in the current study. Thirty-five individuals were diagnosed with cerebellar ataxia to varying degrees and twenty-six age-matched healthy controls were recruited. To automatically detect the local maxima of each syllable in the recorded speech files, a topographic prominence incorporated concept is designed. Subsequently, four acoustic features and eight corresponding parametric measurements are extracted to identify articulatory deficits in ataxic dysarthria. A comparative study on the behaviour of these measures for dysarthric and non-dysarthric subjects is presented in this paper. The results are further explored using a dimensionreduction tool (Principal Component Analysis) to emphasize variation and bring out the strongest discriminating patterns in our feature dataset.",28-Oct-18
10781716,Non-invasive stroke diagnosis using speech data from dysarthria patients,"Acute Ischemic Stroke (AIS) is a major cause of disability and can lead to death in severe cases. A common symptom of AIS, dysarthria, significantly impacts the quality of life of patients. In this study, we developed a deep learning model using dysarthria data for cost-effective and non-invasive brain stroke diagnosis. We utilized models such as ResNet50, InceptionV4, ResNeXt50, SEResNeXt18, and AttResNet50 to effectively extract and classify speech features indicative of stroke symptoms. These models demonstrated high performance, with Sensitivity, Specificity, Precision, Accuracy, and F1-score values reaching 96.77%, 96.08%, 92.82%, 95.52%, and 93.82%, respectively. Our approach offers a non-invasive, cost-effective alternative for early stroke detection, with potential for further accuracy improvements through additional research. This method promises rapid, economical early diagnosis, which could positively impact long-term treatment and healthcare options.",17-Dec-24
10800228,Fine-Tuning Pre-Trained Audio Models for Dysarthria Severity Classification: A Second Place Solution in the Multimodal Dysarthria Severity Classification Challenge,"Dysarthria, a neurological disorder affecting speech, poses significant challenges for automatic diagnosis and severity classification due to its complexity and the scarcity of relevant datasets. This study addresses these challenges by leveraging the dataset provided by the ISCSLP 2024 Multimodal Dysarthria Severity Classification Challenge. Our approach primarily involves two key steps: splitting the training set into training and validation subsets, and fine-tuning pre-trained au-dio models to adapt them to the task. To ensure robust evaluation and prevent label leakage, we employed the StratifiedGroupKFold function from sklearn for dataset splitting, ensuring that training and validation sets do not share participants. This method allowed us to maintain consistent statistical distributions across folds. For model finetuning, we selected two pre-trained audio models, w2v-bert-2.0 and whisper-Iarge-v3, and fine-tuned them on different folds of the dataset. Our results indicate that the w2v-bert-2.0 model fine-tuned on fold-2 achieved the highest performance, with a validation Fl-score of 0.699 and an online score of 7.7452. The experimental results, including confusion matrices and embedding distributions, highlight the model's ability to distinguish between different severity levels of dysarthria. Our approach achieved a commendable second place in the competition¡¯ demonstrating the effectiveness of fine-tuning pre-trained audio models for this task. Future work will explore the integration of multimodal data and multi-task learning strategies to further enhance model performance.",23-Dec-24
10307923,Automated Detection and Severity Assessment of Dysarthria using Raw Speech,"Dysarthria is a medical condition that impairs an individual¡¯s ability to speak clearly due to muscle weakness or paralysis. To diagnose and monitor dysarthria severity, this article proposes the use of a deep learning model that utilizes raw speech waveforms. This approach eliminates the need for feature engineering and enhances the model¡¯s ability to handle noise and speech variability. The proposed system was compared to a standard convolutional neural network (CNN) model and was found to perform better in both dysarthria severity classification and dysarthria/healthy control classification tasks. The results indicate that the SincNet model achieved an accuracy of 95.7% and 99.6% in these tasks, respectively. The proposed system can aid clinicians in diagnosing and monitoring dysarthria severity and could have broader applications in speech-related disorders. The study emphasizes the importance of using raw waveform-based models for speech analysis and demonstrates the effectiveness of SincNet in automatic dysarthria/healthy control classification and dysarthria severity assessment.",23-Nov-23
6936631,Investigation on articulatory and acoustic characteristics of dysarthria,"Direct measurement of articulation contributes to figure out the mechanism of dysarthric speech production accurately, comparing to analyzing acoustic signal alone. This study makes a statistical comparison between dysarthric and normal speech, and investigates and analyzes dysarthric characteristics based on articulatory and acoustic data of continuous English utterance. The distribution of the articulatory point is calculated for each vowel, where the vowels show a relatively smaller region for dysarthria than for normal speech. This implies that the speakers with dysarthria may have some difficulties to fully use the articulatory space as the speakers without dysarthria. The rhythm and sound source are analyzed using autocorrelation function, power spectrum and linear prediction coding. The results reveal that the speakers without dysarthria can keep steady rhythm and energy in uttering consonant-vowel repetition sequences but it is hard for the speakers with dysarthria to maintain the stability. Meanwhile, the dysarthric sound source shows unstable period of the fundamental frequency, which reflects that the speakers with dysarthria could not control the glottis movement well.",27-Oct-14
10550236,Evolving Diagnostic Techniques for Speech Disorders: Investigating Dysarthria Classification Through DenseNet201 CNN Framework,"The primary subject of this research work pertains to dysarthria, a prevalent speech impairment observed in individuals diagnosed with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Prompt detection of dysarthria is essential for effective therapies and improved patient results, as it significantly impacts communication proficiency. The research employed a DenseNet201 Convolutional Neural Network (CNN) to categorize speech using the TORGO database, which has 2000 samples of individuals with and without dysarthria, representing various genders. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each dataset consists of 500 samples, which were collected during distinct sessions. The DenseNet201 convolutional neural network (CNN) technique has a notable accuracy rate of 96% in distinguishing between cases of dysarthria and non-dysarthria. This outcome underscores the potential of deep learning technology in aiding the timely identification of dysarthria and facilitating fast interventions for affected individuals. This work provides valuable insights on the progress of diagnostic capabilities and offers a potential avenue for enhancing the well-being of those experiencing speech impairments.",11-Jun-24
10902941,Analysis of Features for Dysarthria Severity Classification from Speech,"Dysarthria is a disorder that affects the ability of an individual to speak clearly. Diagnosis of the severity of dysarthria can aid in providing appropriate therapy to the individual. Therefore, the current work focuses on identifying features that can be used to estimate the severity of dysarthria. In this regard, two feature sets are considered, namely DisVoice and OpenSMILE, and the genetic algorithm is used to identify the most suitable list of features from both feature sets using 3 speech corpora, namely SSN-TDSC, Torgo, and UA Speech corpora. In order to test the effectiveness of these features, classifiers are trained on each feature set as a whole and on the features identified by the genetic algorithm, and their performance compared. It is observed that articulatory and prosodic features are most important in the diagnosis of severity of dysarthria. A maximum accuracy of 85% is obtained with the shortlisted DisVoice features and 97% with the OpenSMILE features.",5-Mar-25
10800159,Multi-Modal Dysarthria Severity Assessment Using Dual-Branch Feature Decoupling Network and Mixed Expert Framework,"Dysarthria, a motor speech disorder resulting from neurological damage, significantly impairs an individual's ability to articulate words. Assessing the severity of dysarthria is crucial for effective therapeutic interventions and rehabilitation strategies. However, current methods are time-consuming and subjective, leading to potential inconsistencies. This study proposed a dual-branch feature decoupling network and mixed expert framework for the automatic diagnosis and assessment of dysarthria. The proposed hybrid network architecture integrates a ResNet-based branch for audio data with an attention module and a 3D ResNet branch for video data, and was evaluated on the Multimodal Dysarthria Severity Assessment Challenge (MDSA) dataset, achieving significant performance improvements and ranking first in the challenge with a best score of 8.7404. The study's findings highlight the efficacy of the proposed framework in capturing essential features from multimodal data, contributing to more accurate and reliable assessments of dysarthria.",23-Dec-24
10448175,Spectral Analysis of Vowels and Fricatives at Varied Levels of Dysarthria Severity for Amyotrophic Lateral Sclerosis,"Dysarthria due to Amyotrophic Lateral Sclerosis (ALS) affects the acoustic characteristics of different speech sounds. The effects intensify with increasing severity leading to the collapse of the acoustic space of the affected individuals. With an aim to characterize such changes in the acoustic space, this paper studies the variations in band-specific and full-band spectral properties of 4 sustained vowels (/a/, /i/, /o/, /u/) and 3 sustained fricatives (/s/, /sh/, /f/) at different dysarthria severity levels. Effect of dysarthria on spectral features of these phonemes are not well explored. Statistical comparison of these features among different severities for the phonemes considered and among different vowels/fricatives for every severity level using speech data from 119 ALS and 40 healthy subjects indicate the followings. Though all band-specific and full-band features of the three fricatives and most of those features for the four vowels become statistically similar at high severity levels, certain features remain distinguishable. Spectral differences in 0-2 kHz band between /a/ and the other vowels and in the 2-6 kHz band between /a/ and /o/, /u/ persist through all severity levels. Moreover, properties of /f/ remain mostly unchanged with increasing dysarthria severity levels.",18-Mar-24
10673651,Advancing Speech Disorder Diagnostics: A Comprehensive Study on Dysarthria Classification with CNN,"This study article focuses on dysarthria, a speech problem that is often seen in patients with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early identification of dysarthria is crucial for successful treatments and better patient outcomes, since it has a substantial influence on communication ability. Using the TORGO database, which consists of 2000 samples of persons with and without dysarthria, spanning different genders, the research use a Convolutional Neural Network (CNN) to classify speech. The dataset includes both dysarthric and non-dysarthric individuals of both genders, with 500 samples each, captured during separate sessions. The CNN-based technique demonstrates an impressive 96% accuracy in differentiating between dysarthric and non-dysarthric instances, highlighting the promise of deep learning technology in assisting with the early detection of dysarthria and enabling prompt therapies for afflicted people. This study makes significant contributions to the advancement of diagnostic capacities and presents a potential opportunity to improve the quality of life for those with speech difficulties.",18-Sep-24
10581063,Progressing Speech Disorder Identification: A Thorough Investigation into Dysarthria Categorization Utilizing ResNet50 CNN,"The speech issue of dysarthria, which is frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS), is the subject of this research article. Timely detection of dysarthria is essential for effective interventions and improved patient results, as it significantly impacts communication proficiency. The study employs the TORGO database, which has 2000 samples of individuals with and without dysarthria, encompassing various genders. The researchers utilize a ResNet50 Convolutional Neural Network (CNN) to categorize speech. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each group consists of 500 samples, which were recorded over distinct sessions. The CNN-based technique achieves a remarkable 96% accuracy in distinguishing between dysarthric and non-dysarthric instances. This underscores the potential of deep learning technology in aiding the early identification of dysarthria and facilitating timely treatments for affected individuals. This study provides valuable contributions to the enhancement of diagnostic capabilities and offers a potential avenue for enhancing the quality of life for individuals experiencing speech impairments.",12-Jul-24
10625627,Enhancing the Diagnosis of Speech Disorders: An In-Depth Investigation into Dysarthria Classification Using the ResNet18 Model,"This research article concentrates on dysarthria, a speech impediment commonly observed in individuals with conditions such as cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective interventions and improved patient outcomes, as it significantly impacts communication abilities. Employing the TORGO database, comprising 2000 samples from individuals with and without dysarthria, encompassing diverse genders, the study utilizes a Convolutional Neural Network (ResNet18 Model) for speech classification. The dataset encompasses both dysarthric and non-dysarthric subjects of both genders, with 500 samples each, recorded in separate sessions. The ResNet18 Model-based approach demonstrates an impressive 96% accuracy in distinguishing between dysarthric and non-dysarthric instances, underscoring the potential of deep learning technology in aiding early dysarthria detection and facilitating timely interventions. This investigation significantly contributes to advancing diagnostic capabilities and presents a promising avenue to enhance the quality of life for individuals grappling with speech difficulties.",22-Aug-24
10095366,Statistical Analysis of Speech Disorder Specific Features to Characterise Dysarthria Severity Level,"Poor coordination of the speech production subsystems due to any neurological injury or a neuro-degenerative disease leads to dysarthria, a neuro-motor speech disorder. Dysarthric speech impairments can be mapped to the deficits caused in phonation, articulation, prosody, and glottal functioning. With the aim of reducing the subjectivity in clinical evaluations, many automated systems are proposed in the literature to assess the dysarthria severity level using these features. This work aims to analyse the suitability of these features in determining the severity level. A detailed investigation is done to rank these features for their efficacy in modelling the pathological aspects of dysarthric speech, using the technique of paraconsistent feature engineering. The study used two dysarthric speech databases, UA-Speech and TORGO. It puts light into the fact that both the prosody and articulation features are best useful for dysarthria severity estimation, which was supported by the classification accuracies obtained on using different machine learning classifiers.",5-May-23
8251336,Identification of Cerebellar Dysarthria with SISO Characterisation,"Quantitative identification of dysarthria plays a major role in the classification of its severity. This paper quantitatively analyses several components of cerebellar dysarthria. The methodology described in this study will be extended to other types of dysarthria via systematic analysis. The speech production model is characterized as a second-order singleinput and single-output (SISO), linear, time-invariant (LTI) system in our study. A comparative study on the behavior of the damping ratio and resonant frequency for dysarthric and non-dysarthric subjects is presented. The results are further analyzed using the Principal component analysis (PCA) technique to emphasize the variation and uncover strong patterns in the selected features. The effects of some other related factors like decay time and Q-factor are also highlighted.",11-Jan-18
10739183,CNN-Driven Innovations in Dysarthria Classification and Speech Disorder Management,"This research article addresses dysarthria, a speech disorder frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective treatment and improved patient outcomes, as it significantly impacts communication abilities. Utilizing the TORGO database, which comprises 2000 speech samples from both dysarthric and non-dysarthric individuals across various genders, this study employs a Convolutional Neural Network (CNN) for classification. The dataset includes 500 samples each from both groups, collected in different sessions. The CNN approach achieves an impressive 96% accuracy in distinguishing dysarthric from non-dysarthric speech, showcasing the potential of deep learning technology in facilitating early dysarthria diagnosis and enabling timely interventions. This study makes substantial contributions to enhancing diagnostic capabilities and offers a promising avenue for improving the quality of life for individuals with speech disorders.",4-Nov-24
10800051,Constant Q Transform for Audio-Visual Dysarthria Severity Assessment,"This paper describes an automatic dysarthria severity assessment system submitted for the MDSA2024 challenge. The system utilizes audio and visual features to classify the severity of dysarthria. We investigate the effectiveness of different acoustic feature combinations, such as Mel spectrogram, filterbank and constant Q transform. Different encoders for audio data processing are compared in the experiments. The results demonstrate that the Conformer encoder achieves superior performance compared to the Densenet encoder on pure audio features. We further explore model-level fusion by combining audio and visual embeddings, leading to improvements in precision¡¯ recall, and accuracy metrics. The best-achieved score on the test set is 7.5579, with an individual F1-score of 0.7028. The findings suggest that the proposed system with Conformer encoder and model-level fusion holds promise for automatic dysarthria assessment.",23-Dec-24
10781584,Dysarthria Detection with Deep Representation Learning for Patients with Parkinson¡¯s Disease,"Dysarthria is a very common motor speech symptom in Parkinson¡¯s disease impairing normal communications of patients. Detection of dysarthria could assist clinical diagnosis and intervention of Parkinson¡¯s disease, provide monitoring approach for treatment-related side effects, and lead to effective speech therapy to prevent further communication and social deficits. Applying machine learning techniques to speech analysis for patients offers more resource-efficient, accessible and objective tools for screening and assessment of dysarthria. In this study, we constructed a multi-task speech dataset recorded from 600 participants with high data diversity to facilitate the development of detection models. We established a remote data acquisition and end-to-end prediction pipeline with deep representation learning, compared the performance with different feature-based learning and classification methods, and achieved a superior accuracy of over 90%. Different affecting factors were analyzed for model performance. Our proposed framework demonstrates the potential of developing and deploying an automated self-monitoring approach of dysarthria for patients with Parkinson¡¯s disease, which could benefit a large-scale population and their disease managements.",17-Dec-24
7953122,Automatic assessment of dysarthria severity level using audio descriptors,"Dysarthria is a motor speech impairment, often characterized by speech that is generally indiscernible by human listeners. Assessment of the severity level of dysarthria provides an understanding of the patient's progression in the underlying cause and is essential for planning therapy, as well as improving automatic dysarthric speech recognition. In this paper, we propose a non-linguistic manner of automatic assessment of severity levels using audio descriptors or a set of features traditionally used to define timbre of musical instruments and have been modified to suit this purpose. Multitapered spectral estimation based features were computed and used for classification, in addition to the audio descriptors for timbre. An Artificial Neural Network (ANN) was trained to classify speech into various severity levels within Universal Access dysarthric speech corpus and the TORGO database. An average classification accuracy of 96.44% and 98.7% was obtained for UA speech corpus and TORGO database respectively.",19-Jun-17
9287741,Automated Dysarthria Severity Classification Using Deep Learning Frameworks,"Dysarthria is a neuro-motor speech disorder that renders speech unintelligible, in proportional to its severity. Assessing the severity level of dysarthria, apart from being a diagnostic step to evaluate the patient's improvement, is also capable of aiding automatic dysarthric speech recognition systems. In this paper, a detailed study on dysarthia severity classification using various deep learning architectural choices, namely deep neural network (DNN), convolutional neural network (CNN) and long short-term memory network (LSTM) is carried out. Mel frequency cepstral coefficients (MFCCs) and its derivatives are used as features. Performance of these models are compared with a baseline support vector machine (SVM) classifier using the UA-Speech corpus and the TORGO database. The highest classification accuracy of 96.18% and 93.24% are reported for TORGO and UA-Speech respectively. Detailed analysis on performance of these models shows that a proper choice of a deep learning architecture can ensure better performance than the conventionally used SVM classifier.",18-Dec-20
10584052,Deep Learning Based Speech Recognition for Hyperkinetic Dysarthria Disorder,"Speech recognition is a technology that aims to transform human speech into text and has applications in a variety of fields, including information technology, healthcare, automobiles, and others. This research explores the advantages of employing deep learning methods to provide individualized assistance technology solutions for people with dysarthria. We proposed a Convolutional Temporal Bidirectional Network (CTBNet) model for translating Russian Hyperkinetic Dysarthria Disorder (RHDD) speech into text. CTBNet encodes input audio features using 1D convolution layers, and BidirectionalGRU (Bi-GRU) layers. The encoder effectively captures both short-term and long-term spatial temporal information. More importantly, CTBNet includes with an attention-CTC decoder, that is responsible for producing output texts. We utilized a dataset of 2797 recordings of RHDD speech, with a cumulative recorded duration of 2 hours and 33 minutes, for training purposes. The CTBNet model has achieved a 15% Character Error Rate (CER) and a 59% Word Error Rate (WER) on the dataset proposed. Our experimental findings show superior performance compared to state-of-the-art models, namely, 3xCNN, and 3xLSTM, when evaluated on the same dataset.",9-Jul-24
10805075,Developing a Hyperkinetic Dysarthria Speech Classification System using Residual Learning,"Hyperkinetic dysarthria abnormalities are exceedingly widespread across the worldwide populace. One of the most effective methodologies for disordered audio speech identification is classical deep learning technique. However, the efficiency of classification is impacted by the limitations imposed by the quality of the training dataset, such as expense and limited resources, data imbalance, and data annotation difficulties. Accordingly, we suggest implementing a residual learning framework (ResN et architecture) with various conditions and hyperparameters (batch size and learning rate) that improve the training process of deeper networks compared to earlier approaches. Pre-emphasis, windowing, and lifting techniques are applied to improve the quality of Mel-Frequency Cepstral Coefficients. In addition, we have introduced the hyperkinetic dysarthria speech dataset in the Russian language, consisting of 4 hours and 4 minutes of recorded speech. The empirical findings demonstrate that ResNet40 has an overall validation accuracy of 86.7%, surpassing other research models. It is anticipated that it will be recognized as an alternative diagnostic instrument for physicians in the future as research continues to progress.",25-Dec-24
10889800,Multilingual Speaker-Invariant Dysarthria Severity Assessment Using Adversarial Domain Adaptation and Self-Supervised Learning,"Traditional assessments for dysarthria are subjective and time-consuming, highlighting the need for automated, objective approaches that can be scaled for remote and resource-constrained environments. This paper introduces an adversarial domain adaptation framework tailored for dysarthria severity assessment, addressing the challenges of high intra-class variability and limited availability of dysarthric speech data. By framing speaker variability as a domain adaptation problem, we utilise an adversarially trained feature extractor to derive speaker-invariant yet discriminatively powerful representations utilising speech features learned through self-supervised learning. Experiments on previously unseen and diverse speakers reveal that the proposed approach yields a 7.86% average improvement across multilingual datasets compared to traditional severity-discriminative training, outperforming competitive baselines by 12.33% on average. Additionally, the method inherently supports privacy-preserving applications by minimising reliance on speaker-specific information. The results demonstrate strong alignment with clinical assessments, reinforcing our model¡¯s clinical relevance and effectiveness.",7-Mar-25
10929844,AI-Enabled Speech Monitoring for Dysarthria Detection in Consumer Electronics,"Speech is essential in human communication, and recent advancements in artificial intelligence (AI) have enabled new applications for voice data, particularly in health monitoring. Building on this progress, a home-based health detection system that utilizes voice signals provides an accessible method for users to independently identify and respond to conditions such as dysarthria, without the need for hospital or clinic visits. In this study, we developed and evaluated convolutional neural network (CNN) models to classify audio data from both healthy individuals and individuals with dysarthria. The dataset comprised command-based speech samples, which were segmented into sentence-specific input. Preprocessing steps included segmentation, downsampling, and feature extraction tailored for CNN input. The models exhibited high potential in distinguishing between normal and dysarthric states, with the most effective model achieving an f1-score of 96.18¡À4.7% and an accuracy of 96.01¡À5.02%. Furthermore, sentence structure and composition significantly influenced model performance, with specific sentences demonstrating higher classification accuracy. These findings suggest that AI-driven speech analysis may support detecting and managing specific health conditions in non-clinical environments. However, further work is needed to address data imbalance and sentence variability limitations. Future research could expand on real-world applications, particularly in settings with limited traditional health monitoring.",26-Mar-25
10848959,Dysarthria Severity Classification Using Phase Based Features of LP Residual,"Classifying the severity of speech impairment due to dysarthria is crucial for optimizing care and enhancing communication abilities for affected individuals. This study explores the use of the Modified Group Delay Function (MGDF) of LP residual signal in classifying dysarthria severity-levels. Evaluations were conducted using standard UA-Speech and TORGO datasets. A stratified Convolutional Neural Network (CNN) with 5-fold cross-validation validated the results. Baseline features included Linear Frequency Cepstral Coefficients (LFCC), Mel Frequency Cepstral Coefficients (MFCC), and Whisper module. Key performance evaluation metrics were accuracy, precision, recall, and F1-score. Finally, the latency period was analyzed for practical deployment of the system, system¡¯s ability to accurately recognize and process speech from any speaker, without needing to be specifically trained or adapted to individual voice characteristics.",27-Jan-25
10200180,Automatic Early Detection of Dysarthria using Deep Neural Network,"Dysarthria is dis-coordination among articulatory muscles responsible for articulation in the production of speech. A person with dysarthric disorder cannot control their tongue, hence, are prone to slurred speech or swallowing words which lead to improper pronunciation and less intelligibility of speech. This work focuses on the automatic early detection of Dysarthria. To elucidate the main idea, it must be understood that the whole detection procedure revolves around the speech intelligibility of a person. It becomes an arduous job to distinguish between a healthy person's speech and a person who is slowly evolving with the disorder. The prime motive of the work is to provide a proper classification of the disorder in its earliest stages. The common words and phrases recorded in the Universal Access database are used for this work. Mel Frequency Cepstral Coefficients (MFCC) are extracted from both controlled and high intelligible speech data, and fed to a Deep Neural Network (DNN) classifier. MFCC fed to the DNN classifier has provided the best classification accuracy for the above experimental setup.",7-Aug-23
8682324,Learning to Detect Dysarthria from Raw Speech,"Speech classifiers of paralinguistic traits traditionally learn from diverse hand-crafted low-level features, by selecting the relevant information for the task at hand. We explore an alternative to this selection, by learning jointly the classifier, and the feature extraction. Recent work on speech recognition has shown improved performance over speech features by learning from the waveform. We extend this approach to paralinguistic classification and propose a neural network that can learn a filterbank, a normalization factor and a compression power from the raw speech, jointly with the rest of the architecture. We apply this model to dysarthria detection from sentence-level audio recordings. Starting from a strong attention-based baseline on which mel-filterbanks outperform standard low-level descriptors, we show that learning the filters or the normalization and compression improves over fixed features by 10% absolute accuracy. We also observe a gain over OpenSmile features by learning jointly the feature extraction, the normalization, and the compression factor with the architecture. This constitutes a first attempt at learning jointly all these operations from raw audio for a speech classification task.",17-Apr-19
7078586,Modeling fundamental frequency dynamics in hypokinetic dysarthria,"Hypokinetic dysarthria (Hd), which often accompanies Parkinson's Disease (PD), is characterized by hypernasality and by compromised phonation, prosody, and articulation. This paper proposes automated methods for detection of Hd. Whereas most such studies focus on measures of phonation, this paper focuses on prosody, specifically on fundamental frequency (F0) dynamics. Prosody in Hd is clinically described as involving monopitch, which has been confirmed in numerous studies reporting reduced within-utterance pitch variability. We show that a new measure of F0 dynamics, based on a superpositional pitch model that decomposes the F0 contour into a declining phrase curve and (generally, single-peaked) accent curves, performs more accurate Hd vs. Control classification than simpler versions of the model or than conventional variability statistics.",2-Apr-15
8361563,Automatic detection of speech disorder in dysarthria using extended speech feature extraction and neural networks classification,"This paper presents an automatic detection of Dysarthria, a motor speech disorder, using extended speech features called Centroid Formants. Centroid Formants are the weighted averages of the formants extracted from a speech signal. This involves extraction of the first four formants of a speech signal and averaging their weighted values. The weights are determined by the peak energies of the bands of frequency resonance, formants. The resulting weighted averages are called the Centroid Formants. In our proposed methodology, these centroid formants are used to automatically detect Dysarthric speech using neural network classification technique. The experimental results recorded after testing this algorithm are presented. The experimental data consists of 200 speech samples from 10 Dysarthric speakers and 200 speech samples from 10 age-matched healthy speakers. The experimental results show a high performance using neural networks classification. A possible future research related to this work is the use of these extended features in speaker identification and recognition of disordered speech.",21-May-18
9076507,Analysis of Time Domain Features of Dysarthria Speech,"In general, Speech can be described as the ability to express thoughts and feelings by articulating sounds in order to communicate with the person who understand the speech and accordingly interpret their action. The types of communication disorders that affects a person¡¯s ability to produce speech sounds due to the lack of control over motor functions and articulators are speech disorders. Many people of varying age groups suffer from speech disorders and require early treatment in order to correct them. This paper analyses the time domain features such as jitter and shimmer that are extracted from the speech samples of dysarthria and healthy people. This is done by looking for dissimilarities between the different speech features preset in the normal healthy person and the disordered one by employing steps such as pre-processing followed by feature extraction.",23-Apr-20
9291830,Emotional Communication Assist Interface App for People with Dysarthria,"Text to speech (TTS) helps people who have speech disorders communicate with other people. The current TTS can express emotion, but this requires extra time and effort. We developed a TTS application by which users can render messages with emotion with ease by changing the pitch angle of a smartphone. We designed two types of TTS: free input and phrase selection. Also, we calculated the TTS editing parameters for each degree of emotion on the basis of the Online Game Voice Chat Corpus (OGVC).",21-Dec-20
10661368,Fuzzy Expectation Maximization Phoneme Prediction in Diffusion Model-based Dysarthria Voice Conversion,"In this paper proposed an effective fuzzy expectation-maximization phoneme prediction method in diffusion model-based dysarthria voice conversion (FEMPPDM-DVC) which is accessible to (i) training without parallel data (ii) converting a longer duration of the audio data (iii) preserves speaker identity. By integrating Fuzzy Expectation-Maximization (FEM) clustering and Diffusion model-based dysarthria voice conversion approach, the proposed method is able gradually generate normal utterances. Feature extraction is performed using Mel-frequency cepstral coefficients (MFCCs), a robust method in acoustic feature extraction in Text-to-Speech systems. Ensures the effectiveness and accuracy, through repeated parameter adjustment using the FEM clustering algorithm. The conversion network is a diffusion model-based structure, which can convert normal utterances to dysarthria utterances in the forward diffusion process. After forward diffusion process, the dysarthria utterance will go through a reverse diffusion process to convert dysarthria voice to normal utterance. Once converted, a GAN-based vocoder is applied to convert mel-frequency spectrogram to waveform. Objective evaluation is conducted on the Saarbr¨¹cken Voice Database (SVD) dataset show that FEMDDPM-DVC is able to improve the intelligibility and naturalness of dysarthria utterances in 15 kinds of dysarthria voice. The proposed method is compared with five other dysarthria voice conversion methods, show that the proposed method has the most performance among other method.",6-Sep-24
10912315,Revolutionary Dysarthria Analysis Through Convolutional Neural Networks,"Dysarthria occurs when there are impairments in the muscles necessary for speech, including those in the lips, tongue, voice box, and breathing muscles. This condition can result in unclear speech, even in individuals who are skilled communicators. Dysarthria can range from mild speech difficulties, where speech is hard to understand, to severe cases, where speech is completely unclear. A method for distinguishing between different types of speech involves using recordings and advanced computational techniques such as convolutional neural networks (CNNs). The strengths of CNNs are leveraged to construct a highly effective model for detecting dysarthria in speech samples. The dataset utilized includes recordings from individuals with and without dysarthria. The results indicate that the CNN model performs exceptionally well, achieving precision, recall, and F1-scores of 0.99 for both categories. With an accuracy of 0.99, the model demonstrates a high level of proficiency in differentiating between speech affected by dysarthria and normal speech. These findings highlight the effectiveness and utility of this CNN-based approach in diagnosing and assessing dysarthria. It offers valuable potential for assisting healthcare professionals and enhancing personalized speech therapy interventions.",13-Mar-25
10675073,A Study of Speech Recognition Techniques for Dysarthria Speeches Based on Digit Recognition,"With the introduction of speech recognition technology into people's lives, the application of which is no longer limited to ordinary people, but begins to target special populations, such as patients with dysarthria. It has become a major research challenge to build a high-performance speech recognition system for patients with dysarthria. To address this problem, in this paper the speech data of four patients with dysarthria and four healthy speakers on digital commands are firstly collected, secondly several speech recognition experiments are separately conducted by using Aishell-2 and Wenetspeech, two pre-trained models based on the WeNet open-source architecture, as well as the four major commercial recognition API systems, at the end a method to optimize the dysarthria data by using the so-vits-svc tool is proposed. The experiments show that the current state-of-the-art speech recognition model has a high recognition rate for speech data from the general population, but there is still room for improvement in the recognition performance of speech data from individuals with dysarthria. Later the optimization method for the dysarthria data proposed in this paper effectively improves the quality of speech data. For the two above open-source pre-trained models, the recognition rates have increased by 60% and 67.64 % compared to the original data, respectively.",24-Sep-24
7897299,Fractal features for automatic detection of dysarthria,"Amytrophic lateral sclerosis (ALS) is an incurable neurodegenerative disease. Difficulty articulating speech, dysarthria, is a common early symptom of ALS. Detecting dysarthria currently requires manual analysis of several different speech tasks by pathology experts. This is time consuming and can lead to misdiagnosis. Many existing automatic classification approaches require manually preprocessing recordings, separating individual spoken utterances from a repetitive task. In this paper, we propose a fully automated approach which does not rely on manual preprocessing. The proposed method uses novel features based on fractal analysis. Acoustic and associated articulatory recordings of a standard speech diagnostic task, the diadochokinetic test (DDK), are used for classification. This study's experiments show that this approach attains 90.2% accuracy with 94.2% sensitivity and 85.1% specificity.",13-Apr-17
6190184,Assessing Dysarthria severity using global statistics and boosting,"A new method for automatic assessment of Dysarthria severity is described. It uses the forward selection method (FSM) on global statistics of low-complexity features to find effective feature sets. FSM is embedded in a boosting algorithm that combines multiple weak classifiers to achieve a single strong classifier. Unlike standard boosting, this uses nonlinear class boundaries and unique feature sets per iteration. Results on a 39 speaker dysarthria database are described.",26-Apr-12
10250600,An Intelligent System for Dysarthria Classification of Male and Female Processed Dataset using Sequential Model Parameters,"There are several current studies including various methods for treating dysarthria in various developing countries. Research-based dysarthria treatments take a multidisciplinary approach that encompasses speech therapy, assistive technology, neurosurgery, pharmaceutical therapies, non-invasive brain stimulation, machine learning and AI methods. These methods seek to raise the general quality of life, communication and speaking abilities of dysarthria sufferers. With a 90% accuracy rate, the proposed sequential model was found to have good classification performance for identifying Dysarthria. Researchers have also been looking at the use of Machine Learning (ML) and Artificial Intelligence (AI) approaches to create tools and systems that can help people with dysarthria to speak and communicate for social welfare and provide access to best remedies.",22-Sep-23
7344537,Dysarthria diagnosis via respiration and phonation,This report discusses the implementation of a computerized application - the Computerised Frenchay Dysarthria Assessment Procedure (CFDA) - which uses digital signal processing (DSP) techniques to objectively evaluate digitised speech recordings in order to detect any symptoms of dysarthria (a type of motor speech disorder). This investigation focuses specifically on two CFDA diagnostic sub-applications which assess a patient's ability to maintain a prolonged exhalation (the ¡°Respiration at Rest¡± task) as well as execute a steady state phonation (i.e. the ¡°Sustained Phonation¡± task). It is demonstrated that combining the functionality of these two sub-applications substantially increases their diagnostic effectiveness in the context of identifying a particular variety of dysarthria known as spastic dysarthria. It is further demonstrated that certain patterns of energy fluctuations are closely correlated with manifestations of spastic dysarthria. The CFDA is intended for use in real-world conditions to assist speech and language therapists when conducting clinical evaluations.,3-Dec-15
10892620,Deep Learning Based Dysarthria Detection: A Comprehensive Approach,"Making a model that can analyze numerous input features and predict whether a person will develop dysarthria is the first step in utilizing machine learning to forecast diseases like dysarthria. A motor speech disorder called dysarthria can be caused by a variety of underlying conditions, such as degenerative disorders, traumatic brain injuries, or neurological disorders. The authors used the 2000 audio signals from males and females with and without dysarthria from the TORGO data set. To extract the important features from the audio signals, the authors used the MFCC approach. To determine if dysarthria is present or absent, a machine learning model or algorithm will be fed with these MFCC coefficients.",25-Feb-25
9629802,"Brain Signals to Rescue Aphasia, Apraxia and Dysarthria Speech Recognition","In this paper, we propose a deep learning-based algorithm to improve the performance of automatic speech recognition (ASR) systems for aphasia, apraxia, and dysarthria speech by utilizing electroencephalography (EEG) features recorded synchronously with aphasia, apraxia, and dysarthria speech. We demonstrate a significant decoding performance improvement by more than 50% during test time for isolated speech recognition task and we also provide preliminary results indicating performance improvement for the more challenging continuous speech recognition task by utilizing EEG features. The results presented in this paper show the first step towards demonstrating the possibility of utilizing non-invasive neural signals to design a real-time robust speech prosthetic for stroke survivors recovering from aphasia, apraxia, and dysarthria. Our aphasia, apraxia, and dysarthria speech-EEG data set will be released to the public to help further advance this interesting and crucial research.",9-Dec-21
1660840,Hmm-Based and Svm-Based Recognition of the Speech of Talkers With Spastic Dysarthria,"This paper studies the speech of three talkers with spastic dysarthria caused by cerebral palsy. All three subjects share the symptom of low intelligibility, but causes differ. First, all subjects tend to reduce or delete word-initial consonants; one subject deletes all consonants. Second, one subject exhibits a painstaking stutter. Two algorithms were used to develop automatic isolated digit recognition systems for these subjects. HMM-based recognition was successful for two subjects, but failed for the subject who deletes all consonants. Conversely, digit recognition experiments assuming a fixed word length (using SVMs) were successful for two subjects, but failed for the subject with the stutter.",24-Jul-06
5495563,Design of a dysarthria classifier using global statistics of speech features,"Dysarthria is a neurological disorder in which the speech production system is impaired. There are five main types of dysarthrias depending on the location of the lesion in the nervous system. There is evidence suggesting a relationship between the location of the lesion and the resulting speech characteristics. This paper describes a non-intrusive classifier to identify the dysarthria type in a person using global statistics, e.g., mean, variance, etc., of speech features. A tree-based classifier was developed using multiple low-level maximum likelihood classifiers as inputs. An error of 10.5% was achieved in the classification of three types of dysarthrias.",28-Jun-10
10157285,Dysarthria Speech Disorder Classification Using Traditional and Deep Learning Models,"Dysarthria is a motor speech disorder that results in speech difficulties due to the weakness of associated muscles. This unclear speech makes it difficult for dysarthric patients to present himself understood. This neurological limitation is usually occurs due to damages to the brain or central nervous system. Speech therapy can be effectively employed to enhance the range and consistency of voice production and improve intelligibility and communicative effectiveness. Assessing the degree of severity of dysarthria provides vital information on the patient's progress which inturn assists pathologists in arriving at a treatment plan that includes developing automated voice recognition system suitable for dysarthria patients. This work performs an exhaustive study on dysarthria severity level classification using deep neural network (DNN) and convolution neural network (CNN) architectures. Mel Frequency Cepstral Coefficients (MFCCs) and their derivatives constitute feature vectors for classification. Using the UA-Speech database, the performance metrics of DNN/CNN based learning models have been compared to baseline classifiers like support vector machine (SVM) and Random Forest (RF). The highest classification accuracy of 97.6\% is reported for DNN under UA speech database. A detailed examination of the performance from the models discussed above reveal that appropriate choice of deep learning architecture ensures better results than traditional classifiers like SVM and Random Forest.",26-Jun-23
10527645,Harnessing Deep Learning Techniques for Dysarthria Detection,"Dysarthria, a motor speech disorder resulting from neurological impairments. This study explores various approaches for the automated detection of dysarthria, integrating both traditional and emerging technologies. Speech assessments by acoustic analysis, machine learning models, and deep learning techniques are considered. Machine learning models are trained on datasets containing normal and dysarthric speech for males and females, while deep learning methods, including convolutional and recurrent neural networks, are employed to automatically learn features from speech data. Our goal is to develop a reliable and accessible dysarthria detection system thatcomplements the expertise of healthcare professionals. Validation using diverse datasets is emphasized, acknowledging the importance of early detection and intervention in improving outcomes for individuals with dysarthria.",16-May-24
10696797,Next-Gen Speech Disorder Diagnostics: CNN Methods for Dysarthria Classification,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. Dysarthria has a significant impact on communication capacity, making early diagnosis essential for effective therapies and improved patient outcomes. The research used a Convolutional Neural Network (CNN) to categorise speech using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. There are 500 samples from each gender in the collection, representing dysarthric and non-dysarthric people who were recorded during different sessions. Highlighting the promise of deep learning technology in aiding early identification of dysarthria and enabling rapid therapy for affected individuals, the CNN-based approach exhibits an amazing 96% accuracy in discriminating between dysarthric and non-dysarthric cases. This study offers a promising chance to enhance the quality of life for those with speech impairments while also making substantial contributions to the development of diagnostic capabilities.",4-Oct-24
10730941,Advancing Speech Disorder Diagnostics: CNN Innovations in Dysarthria Recognition,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. The capacity to communicate is greatly affected by dysarthria, thus early diagnosis is critical for effective therapies and improved patient outcomes. The study employed a Convolutional Neural Network (CNN) for speech classification using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. With 500 samples each, collected over distinct sessions, the dataset contains both dysarthric and non-dysarthric people of both sexes. Distinguishing between dysarthric and non-dysarthric occurrences, the CNN-based approach achieves an astonishing 96% accuracy. This shows how deep learning technology may help with early dysarthria identification and enable rapid therapy for affected individuals. The findings of this study have important implications for the development of diagnostic tools and may lead to better living conditions for those who struggle with speaking.",29-Oct-24
10340908,A preliminary study on self-care telemonitoring of dysarthria in spinal muscular atrophy,"Spinal muscular atrophy (SMA) is a rare neuromuscular disease which may cause impairments in oro-facial musculature. Most of the individuals with SMA present bulbar signs such as flaccid dysarthria which mines their abilities to speak and, as consequence, their psychic balance. To support clinicians, recent work has demonstrated the feasibility of video-based techniques for assessing the oro-facial functions in patients with neurological disorders such as amyotrophic lateral sclerosis. However, no work has so far focused on automatic and quantitative monitoring of dysarthria in SMA. To overcome limitations this work¡¯s aim is to propose a cloud-based store-and-forward telemonitoring system for automatic and quantitative evaluation of oro-facial muscles in individuals with SMA. The system integrates a convolutional neural network (CNN) aimed at identifying the position of facial landmarks from video recordings acquired via a web application by an SMA patient.Clinical relevance¡ª The proposed work is in the preliminary stage, but it represents the first step towards a better understanding of the bulbar-functions¡¯ evolution in patients with SMA.",11-Dec-23
9414283,"Automatic And Perceptual Discrimination Between Dysarthria, Apraxia of Speech, and Neurotypical Speech","Automatic techniques in the context of motor speech disorders (MSDs) are typically two-class techniques aiming to discriminate between dysarthria and neurotypical speech or between dysarthria and apraxia of speech (AoS). Further, although such techniques are proposed to support the perceptual assessment of clinicians, the automatic and perceptual classification accuracy has never been compared. In this paper, we investigate a three-class automatic technique and a set of handcrafted features for the discrimination of dysarthria, AoS and neurotypical speech. Instead of following the commonly used One-versus-One or One-versus-Rest approaches for multi-class classification, a hierarchical approach is proposed. Further, a perceptual study is conducted where speech and language pathologists are asked to listen to recordings of dysarthria, AoS, and neurotypical speech and decide which class the recordings belong to. The proposed automatic technique is evaluated on the same recordings and the automatic and perceptual classification performance are compared. The presented results show that the hierarchical classification approach yields a higher classification accuracy than baseline One-versus-One and One-versus-Rest approaches. Further, the presented results show that the automatic approach yields a higher classification accuracy than the perceptual assessment of speech and language pathologists, demonstrating the potential advantages of integrating automatic tools in clinical practice.",13-May-21
8512311,Quantitative Assessment of Syllabic Timing Deficits in Ataxic Dysarthria,"Parametric analysis of Cerebellar Dysarthria (CD) may be valuable and more informative compared to its clinical assessment. A quantifiable estimation of the timing deficits in repeated syllabic utterance is described in the current study. Thirty-five individuals were diagnosed with cerebellar ataxia to varying degrees and twenty-six age-matched healthy controls were recruited. To automatically detect the local maxima of each syllable in the recorded speech files, a topographic prominence incorporated concept is designed. Subsequently, four acoustic features and eight corresponding parametric measurements are extracted to identify articulatory deficits in ataxic dysarthria. A comparative study on the behaviour of these measures for dysarthric and non-dysarthric subjects is presented in this paper. The results are further explored using a dimensionreduction tool (Principal Component Analysis) to emphasize variation and bring out the strongest discriminating patterns in our feature dataset.",28-Oct-18
10781716,Non-invasive stroke diagnosis using speech data from dysarthria patients,"Acute Ischemic Stroke (AIS) is a major cause of disability and can lead to death in severe cases. A common symptom of AIS, dysarthria, significantly impacts the quality of life of patients. In this study, we developed a deep learning model using dysarthria data for cost-effective and non-invasive brain stroke diagnosis. We utilized models such as ResNet50, InceptionV4, ResNeXt50, SEResNeXt18, and AttResNet50 to effectively extract and classify speech features indicative of stroke symptoms. These models demonstrated high performance, with Sensitivity, Specificity, Precision, Accuracy, and F1-score values reaching 96.77%, 96.08%, 92.82%, 95.52%, and 93.82%, respectively. Our approach offers a non-invasive, cost-effective alternative for early stroke detection, with potential for further accuracy improvements through additional research. This method promises rapid, economical early diagnosis, which could positively impact long-term treatment and healthcare options.",17-Dec-24
10800228,Fine-Tuning Pre-Trained Audio Models for Dysarthria Severity Classification: A Second Place Solution in the Multimodal Dysarthria Severity Classification Challenge,"Dysarthria, a neurological disorder affecting speech, poses significant challenges for automatic diagnosis and severity classification due to its complexity and the scarcity of relevant datasets. This study addresses these challenges by leveraging the dataset provided by the ISCSLP 2024 Multimodal Dysarthria Severity Classification Challenge. Our approach primarily involves two key steps: splitting the training set into training and validation subsets, and fine-tuning pre-trained au-dio models to adapt them to the task. To ensure robust evaluation and prevent label leakage, we employed the StratifiedGroupKFold function from sklearn for dataset splitting, ensuring that training and validation sets do not share participants. This method allowed us to maintain consistent statistical distributions across folds. For model finetuning, we selected two pre-trained audio models, w2v-bert-2.0 and whisper-Iarge-v3, and fine-tuned them on different folds of the dataset. Our results indicate that the w2v-bert-2.0 model fine-tuned on fold-2 achieved the highest performance, with a validation Fl-score of 0.699 and an online score of 7.7452. The experimental results, including confusion matrices and embedding distributions, highlight the model's ability to distinguish between different severity levels of dysarthria. Our approach achieved a commendable second place in the competition¡¯ demonstrating the effectiveness of fine-tuning pre-trained audio models for this task. Future work will explore the integration of multimodal data and multi-task learning strategies to further enhance model performance.",23-Dec-24
10307923,Automated Detection and Severity Assessment of Dysarthria using Raw Speech,"Dysarthria is a medical condition that impairs an individual¡¯s ability to speak clearly due to muscle weakness or paralysis. To diagnose and monitor dysarthria severity, this article proposes the use of a deep learning model that utilizes raw speech waveforms. This approach eliminates the need for feature engineering and enhances the model¡¯s ability to handle noise and speech variability. The proposed system was compared to a standard convolutional neural network (CNN) model and was found to perform better in both dysarthria severity classification and dysarthria/healthy control classification tasks. The results indicate that the SincNet model achieved an accuracy of 95.7% and 99.6% in these tasks, respectively. The proposed system can aid clinicians in diagnosing and monitoring dysarthria severity and could have broader applications in speech-related disorders. The study emphasizes the importance of using raw waveform-based models for speech analysis and demonstrates the effectiveness of SincNet in automatic dysarthria/healthy control classification and dysarthria severity assessment.",23-Nov-23
6936631,Investigation on articulatory and acoustic characteristics of dysarthria,"Direct measurement of articulation contributes to figure out the mechanism of dysarthric speech production accurately, comparing to analyzing acoustic signal alone. This study makes a statistical comparison between dysarthric and normal speech, and investigates and analyzes dysarthric characteristics based on articulatory and acoustic data of continuous English utterance. The distribution of the articulatory point is calculated for each vowel, where the vowels show a relatively smaller region for dysarthria than for normal speech. This implies that the speakers with dysarthria may have some difficulties to fully use the articulatory space as the speakers without dysarthria. The rhythm and sound source are analyzed using autocorrelation function, power spectrum and linear prediction coding. The results reveal that the speakers without dysarthria can keep steady rhythm and energy in uttering consonant-vowel repetition sequences but it is hard for the speakers with dysarthria to maintain the stability. Meanwhile, the dysarthric sound source shows unstable period of the fundamental frequency, which reflects that the speakers with dysarthria could not control the glottis movement well.",27-Oct-14
10550236,Evolving Diagnostic Techniques for Speech Disorders: Investigating Dysarthria Classification Through DenseNet201 CNN Framework,"The primary subject of this research work pertains to dysarthria, a prevalent speech impairment observed in individuals diagnosed with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Prompt detection of dysarthria is essential for effective therapies and improved patient results, as it significantly impacts communication proficiency. The research employed a DenseNet201 Convolutional Neural Network (CNN) to categorize speech using the TORGO database, which has 2000 samples of individuals with and without dysarthria, representing various genders. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each dataset consists of 500 samples, which were collected during distinct sessions. The DenseNet201 convolutional neural network (CNN) technique has a notable accuracy rate of 96% in distinguishing between cases of dysarthria and non-dysarthria. This outcome underscores the potential of deep learning technology in aiding the timely identification of dysarthria and facilitating fast interventions for affected individuals. This work provides valuable insights on the progress of diagnostic capabilities and offers a potential avenue for enhancing the well-being of those experiencing speech impairments.",11-Jun-24
10902941,Analysis of Features for Dysarthria Severity Classification from Speech,"Dysarthria is a disorder that affects the ability of an individual to speak clearly. Diagnosis of the severity of dysarthria can aid in providing appropriate therapy to the individual. Therefore, the current work focuses on identifying features that can be used to estimate the severity of dysarthria. In this regard, two feature sets are considered, namely DisVoice and OpenSMILE, and the genetic algorithm is used to identify the most suitable list of features from both feature sets using 3 speech corpora, namely SSN-TDSC, Torgo, and UA Speech corpora. In order to test the effectiveness of these features, classifiers are trained on each feature set as a whole and on the features identified by the genetic algorithm, and their performance compared. It is observed that articulatory and prosodic features are most important in the diagnosis of severity of dysarthria. A maximum accuracy of 85% is obtained with the shortlisted DisVoice features and 97% with the OpenSMILE features.",5-Mar-25
10800159,Multi-Modal Dysarthria Severity Assessment Using Dual-Branch Feature Decoupling Network and Mixed Expert Framework,"Dysarthria, a motor speech disorder resulting from neurological damage, significantly impairs an individual's ability to articulate words. Assessing the severity of dysarthria is crucial for effective therapeutic interventions and rehabilitation strategies. However, current methods are time-consuming and subjective, leading to potential inconsistencies. This study proposed a dual-branch feature decoupling network and mixed expert framework for the automatic diagnosis and assessment of dysarthria. The proposed hybrid network architecture integrates a ResNet-based branch for audio data with an attention module and a 3D ResNet branch for video data, and was evaluated on the Multimodal Dysarthria Severity Assessment Challenge (MDSA) dataset, achieving significant performance improvements and ranking first in the challenge with a best score of 8.7404. The study's findings highlight the efficacy of the proposed framework in capturing essential features from multimodal data, contributing to more accurate and reliable assessments of dysarthria.",23-Dec-24
10448175,Spectral Analysis of Vowels and Fricatives at Varied Levels of Dysarthria Severity for Amyotrophic Lateral Sclerosis,"Dysarthria due to Amyotrophic Lateral Sclerosis (ALS) affects the acoustic characteristics of different speech sounds. The effects intensify with increasing severity leading to the collapse of the acoustic space of the affected individuals. With an aim to characterize such changes in the acoustic space, this paper studies the variations in band-specific and full-band spectral properties of 4 sustained vowels (/a/, /i/, /o/, /u/) and 3 sustained fricatives (/s/, /sh/, /f/) at different dysarthria severity levels. Effect of dysarthria on spectral features of these phonemes are not well explored. Statistical comparison of these features among different severities for the phonemes considered and among different vowels/fricatives for every severity level using speech data from 119 ALS and 40 healthy subjects indicate the followings. Though all band-specific and full-band features of the three fricatives and most of those features for the four vowels become statistically similar at high severity levels, certain features remain distinguishable. Spectral differences in 0-2 kHz band between /a/ and the other vowels and in the 2-6 kHz band between /a/ and /o/, /u/ persist through all severity levels. Moreover, properties of /f/ remain mostly unchanged with increasing dysarthria severity levels.",18-Mar-24
10673651,Advancing Speech Disorder Diagnostics: A Comprehensive Study on Dysarthria Classification with CNN,"This study article focuses on dysarthria, a speech problem that is often seen in patients with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early identification of dysarthria is crucial for successful treatments and better patient outcomes, since it has a substantial influence on communication ability. Using the TORGO database, which consists of 2000 samples of persons with and without dysarthria, spanning different genders, the research use a Convolutional Neural Network (CNN) to classify speech. The dataset includes both dysarthric and non-dysarthric individuals of both genders, with 500 samples each, captured during separate sessions. The CNN-based technique demonstrates an impressive 96% accuracy in differentiating between dysarthric and non-dysarthric instances, highlighting the promise of deep learning technology in assisting with the early detection of dysarthria and enabling prompt therapies for afflicted people. This study makes significant contributions to the advancement of diagnostic capacities and presents a potential opportunity to improve the quality of life for those with speech difficulties.",18-Sep-24
10581063,Progressing Speech Disorder Identification: A Thorough Investigation into Dysarthria Categorization Utilizing ResNet50 CNN,"The speech issue of dysarthria, which is frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS), is the subject of this research article. Timely detection of dysarthria is essential for effective interventions and improved patient results, as it significantly impacts communication proficiency. The study employs the TORGO database, which has 2000 samples of individuals with and without dysarthria, encompassing various genders. The researchers utilize a ResNet50 Convolutional Neural Network (CNN) to categorize speech. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each group consists of 500 samples, which were recorded over distinct sessions. The CNN-based technique achieves a remarkable 96% accuracy in distinguishing between dysarthric and non-dysarthric instances. This underscores the potential of deep learning technology in aiding the early identification of dysarthria and facilitating timely treatments for affected individuals. This study provides valuable contributions to the enhancement of diagnostic capabilities and offers a potential avenue for enhancing the quality of life for individuals experiencing speech impairments.",12-Jul-24
10625627,Enhancing the Diagnosis of Speech Disorders: An In-Depth Investigation into Dysarthria Classification Using the ResNet18 Model,"This research article concentrates on dysarthria, a speech impediment commonly observed in individuals with conditions such as cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective interventions and improved patient outcomes, as it significantly impacts communication abilities. Employing the TORGO database, comprising 2000 samples from individuals with and without dysarthria, encompassing diverse genders, the study utilizes a Convolutional Neural Network (ResNet18 Model) for speech classification. The dataset encompasses both dysarthric and non-dysarthric subjects of both genders, with 500 samples each, recorded in separate sessions. The ResNet18 Model-based approach demonstrates an impressive 96% accuracy in distinguishing between dysarthric and non-dysarthric instances, underscoring the potential of deep learning technology in aiding early dysarthria detection and facilitating timely interventions. This investigation significantly contributes to advancing diagnostic capabilities and presents a promising avenue to enhance the quality of life for individuals grappling with speech difficulties.",22-Aug-24
10095366,Statistical Analysis of Speech Disorder Specific Features to Characterise Dysarthria Severity Level,"Poor coordination of the speech production subsystems due to any neurological injury or a neuro-degenerative disease leads to dysarthria, a neuro-motor speech disorder. Dysarthric speech impairments can be mapped to the deficits caused in phonation, articulation, prosody, and glottal functioning. With the aim of reducing the subjectivity in clinical evaluations, many automated systems are proposed in the literature to assess the dysarthria severity level using these features. This work aims to analyse the suitability of these features in determining the severity level. A detailed investigation is done to rank these features for their efficacy in modelling the pathological aspects of dysarthric speech, using the technique of paraconsistent feature engineering. The study used two dysarthric speech databases, UA-Speech and TORGO. It puts light into the fact that both the prosody and articulation features are best useful for dysarthria severity estimation, which was supported by the classification accuracies obtained on using different machine learning classifiers.",5-May-23
8251336,Identification of Cerebellar Dysarthria with SISO Characterisation,"Quantitative identification of dysarthria plays a major role in the classification of its severity. This paper quantitatively analyses several components of cerebellar dysarthria. The methodology described in this study will be extended to other types of dysarthria via systematic analysis. The speech production model is characterized as a second-order singleinput and single-output (SISO), linear, time-invariant (LTI) system in our study. A comparative study on the behavior of the damping ratio and resonant frequency for dysarthric and non-dysarthric subjects is presented. The results are further analyzed using the Principal component analysis (PCA) technique to emphasize the variation and uncover strong patterns in the selected features. The effects of some other related factors like decay time and Q-factor are also highlighted.",11-Jan-18
10739183,CNN-Driven Innovations in Dysarthria Classification and Speech Disorder Management,"This research article addresses dysarthria, a speech disorder frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective treatment and improved patient outcomes, as it significantly impacts communication abilities. Utilizing the TORGO database, which comprises 2000 speech samples from both dysarthric and non-dysarthric individuals across various genders, this study employs a Convolutional Neural Network (CNN) for classification. The dataset includes 500 samples each from both groups, collected in different sessions. The CNN approach achieves an impressive 96% accuracy in distinguishing dysarthric from non-dysarthric speech, showcasing the potential of deep learning technology in facilitating early dysarthria diagnosis and enabling timely interventions. This study makes substantial contributions to enhancing diagnostic capabilities and offers a promising avenue for improving the quality of life for individuals with speech disorders.",4-Nov-24
10800051,Constant Q Transform for Audio-Visual Dysarthria Severity Assessment,"This paper describes an automatic dysarthria severity assessment system submitted for the MDSA2024 challenge. The system utilizes audio and visual features to classify the severity of dysarthria. We investigate the effectiveness of different acoustic feature combinations, such as Mel spectrogram, filterbank and constant Q transform. Different encoders for audio data processing are compared in the experiments. The results demonstrate that the Conformer encoder achieves superior performance compared to the Densenet encoder on pure audio features. We further explore model-level fusion by combining audio and visual embeddings, leading to improvements in precision¡¯ recall, and accuracy metrics. The best-achieved score on the test set is 7.5579, with an individual F1-score of 0.7028. The findings suggest that the proposed system with Conformer encoder and model-level fusion holds promise for automatic dysarthria assessment.",23-Dec-24
10781584,Dysarthria Detection with Deep Representation Learning for Patients with Parkinson¡¯s Disease,"Dysarthria is a very common motor speech symptom in Parkinson¡¯s disease impairing normal communications of patients. Detection of dysarthria could assist clinical diagnosis and intervention of Parkinson¡¯s disease, provide monitoring approach for treatment-related side effects, and lead to effective speech therapy to prevent further communication and social deficits. Applying machine learning techniques to speech analysis for patients offers more resource-efficient, accessible and objective tools for screening and assessment of dysarthria. In this study, we constructed a multi-task speech dataset recorded from 600 participants with high data diversity to facilitate the development of detection models. We established a remote data acquisition and end-to-end prediction pipeline with deep representation learning, compared the performance with different feature-based learning and classification methods, and achieved a superior accuracy of over 90%. Different affecting factors were analyzed for model performance. Our proposed framework demonstrates the potential of developing and deploying an automated self-monitoring approach of dysarthria for patients with Parkinson¡¯s disease, which could benefit a large-scale population and their disease managements.",17-Dec-24
7953122,Automatic assessment of dysarthria severity level using audio descriptors,"Dysarthria is a motor speech impairment, often characterized by speech that is generally indiscernible by human listeners. Assessment of the severity level of dysarthria provides an understanding of the patient's progression in the underlying cause and is essential for planning therapy, as well as improving automatic dysarthric speech recognition. In this paper, we propose a non-linguistic manner of automatic assessment of severity levels using audio descriptors or a set of features traditionally used to define timbre of musical instruments and have been modified to suit this purpose. Multitapered spectral estimation based features were computed and used for classification, in addition to the audio descriptors for timbre. An Artificial Neural Network (ANN) was trained to classify speech into various severity levels within Universal Access dysarthric speech corpus and the TORGO database. An average classification accuracy of 96.44% and 98.7% was obtained for UA speech corpus and TORGO database respectively.",19-Jun-17
9287741,Automated Dysarthria Severity Classification Using Deep Learning Frameworks,"Dysarthria is a neuro-motor speech disorder that renders speech unintelligible, in proportional to its severity. Assessing the severity level of dysarthria, apart from being a diagnostic step to evaluate the patient's improvement, is also capable of aiding automatic dysarthric speech recognition systems. In this paper, a detailed study on dysarthia severity classification using various deep learning architectural choices, namely deep neural network (DNN), convolutional neural network (CNN) and long short-term memory network (LSTM) is carried out. Mel frequency cepstral coefficients (MFCCs) and its derivatives are used as features. Performance of these models are compared with a baseline support vector machine (SVM) classifier using the UA-Speech corpus and the TORGO database. The highest classification accuracy of 96.18% and 93.24% are reported for TORGO and UA-Speech respectively. Detailed analysis on performance of these models shows that a proper choice of a deep learning architecture can ensure better performance than the conventionally used SVM classifier.",18-Dec-20
10584052,Deep Learning Based Speech Recognition for Hyperkinetic Dysarthria Disorder,"Speech recognition is a technology that aims to transform human speech into text and has applications in a variety of fields, including information technology, healthcare, automobiles, and others. This research explores the advantages of employing deep learning methods to provide individualized assistance technology solutions for people with dysarthria. We proposed a Convolutional Temporal Bidirectional Network (CTBNet) model for translating Russian Hyperkinetic Dysarthria Disorder (RHDD) speech into text. CTBNet encodes input audio features using 1D convolution layers, and BidirectionalGRU (Bi-GRU) layers. The encoder effectively captures both short-term and long-term spatial temporal information. More importantly, CTBNet includes with an attention-CTC decoder, that is responsible for producing output texts. We utilized a dataset of 2797 recordings of RHDD speech, with a cumulative recorded duration of 2 hours and 33 minutes, for training purposes. The CTBNet model has achieved a 15% Character Error Rate (CER) and a 59% Word Error Rate (WER) on the dataset proposed. Our experimental findings show superior performance compared to state-of-the-art models, namely, 3xCNN, and 3xLSTM, when evaluated on the same dataset.",9-Jul-24
10805075,Developing a Hyperkinetic Dysarthria Speech Classification System using Residual Learning,"Hyperkinetic dysarthria abnormalities are exceedingly widespread across the worldwide populace. One of the most effective methodologies for disordered audio speech identification is classical deep learning technique. However, the efficiency of classification is impacted by the limitations imposed by the quality of the training dataset, such as expense and limited resources, data imbalance, and data annotation difficulties. Accordingly, we suggest implementing a residual learning framework (ResN et architecture) with various conditions and hyperparameters (batch size and learning rate) that improve the training process of deeper networks compared to earlier approaches. Pre-emphasis, windowing, and lifting techniques are applied to improve the quality of Mel-Frequency Cepstral Coefficients. In addition, we have introduced the hyperkinetic dysarthria speech dataset in the Russian language, consisting of 4 hours and 4 minutes of recorded speech. The empirical findings demonstrate that ResNet40 has an overall validation accuracy of 86.7%, surpassing other research models. It is anticipated that it will be recognized as an alternative diagnostic instrument for physicians in the future as research continues to progress.",25-Dec-24
10889800,Multilingual Speaker-Invariant Dysarthria Severity Assessment Using Adversarial Domain Adaptation and Self-Supervised Learning,"Traditional assessments for dysarthria are subjective and time-consuming, highlighting the need for automated, objective approaches that can be scaled for remote and resource-constrained environments. This paper introduces an adversarial domain adaptation framework tailored for dysarthria severity assessment, addressing the challenges of high intra-class variability and limited availability of dysarthric speech data. By framing speaker variability as a domain adaptation problem, we utilise an adversarially trained feature extractor to derive speaker-invariant yet discriminatively powerful representations utilising speech features learned through self-supervised learning. Experiments on previously unseen and diverse speakers reveal that the proposed approach yields a 7.86% average improvement across multilingual datasets compared to traditional severity-discriminative training, outperforming competitive baselines by 12.33% on average. Additionally, the method inherently supports privacy-preserving applications by minimising reliance on speaker-specific information. The results demonstrate strong alignment with clinical assessments, reinforcing our model¡¯s clinical relevance and effectiveness.",7-Mar-25
10929844,AI-Enabled Speech Monitoring for Dysarthria Detection in Consumer Electronics,"Speech is essential in human communication, and recent advancements in artificial intelligence (AI) have enabled new applications for voice data, particularly in health monitoring. Building on this progress, a home-based health detection system that utilizes voice signals provides an accessible method for users to independently identify and respond to conditions such as dysarthria, without the need for hospital or clinic visits. In this study, we developed and evaluated convolutional neural network (CNN) models to classify audio data from both healthy individuals and individuals with dysarthria. The dataset comprised command-based speech samples, which were segmented into sentence-specific input. Preprocessing steps included segmentation, downsampling, and feature extraction tailored for CNN input. The models exhibited high potential in distinguishing between normal and dysarthric states, with the most effective model achieving an f1-score of 96.18¡À4.7% and an accuracy of 96.01¡À5.02%. Furthermore, sentence structure and composition significantly influenced model performance, with specific sentences demonstrating higher classification accuracy. These findings suggest that AI-driven speech analysis may support detecting and managing specific health conditions in non-clinical environments. However, further work is needed to address data imbalance and sentence variability limitations. Future research could expand on real-world applications, particularly in settings with limited traditional health monitoring.",26-Mar-25
10848959,Dysarthria Severity Classification Using Phase Based Features of LP Residual,"Classifying the severity of speech impairment due to dysarthria is crucial for optimizing care and enhancing communication abilities for affected individuals. This study explores the use of the Modified Group Delay Function (MGDF) of LP residual signal in classifying dysarthria severity-levels. Evaluations were conducted using standard UA-Speech and TORGO datasets. A stratified Convolutional Neural Network (CNN) with 5-fold cross-validation validated the results. Baseline features included Linear Frequency Cepstral Coefficients (LFCC), Mel Frequency Cepstral Coefficients (MFCC), and Whisper module. Key performance evaluation metrics were accuracy, precision, recall, and F1-score. Finally, the latency period was analyzed for practical deployment of the system, system¡¯s ability to accurately recognize and process speech from any speaker, without needing to be specifically trained or adapted to individual voice characteristics.",27-Jan-25
10200180,Automatic Early Detection of Dysarthria using Deep Neural Network,"Dysarthria is dis-coordination among articulatory muscles responsible for articulation in the production of speech. A person with dysarthric disorder cannot control their tongue, hence, are prone to slurred speech or swallowing words which lead to improper pronunciation and less intelligibility of speech. This work focuses on the automatic early detection of Dysarthria. To elucidate the main idea, it must be understood that the whole detection procedure revolves around the speech intelligibility of a person. It becomes an arduous job to distinguish between a healthy person's speech and a person who is slowly evolving with the disorder. The prime motive of the work is to provide a proper classification of the disorder in its earliest stages. The common words and phrases recorded in the Universal Access database are used for this work. Mel Frequency Cepstral Coefficients (MFCC) are extracted from both controlled and high intelligible speech data, and fed to a Deep Neural Network (DNN) classifier. MFCC fed to the DNN classifier has provided the best classification accuracy for the above experimental setup.",7-Aug-23
7078586,Modeling fundamental frequency dynamics in hypokinetic dysarthria,"Hypokinetic dysarthria (Hd), which often accompanies Parkinson's Disease (PD), is characterized by hypernasality and by compromised phonation, prosody, and articulation. This paper proposes automated methods for detection of Hd. Whereas most such studies focus on measures of phonation, this paper focuses on prosody, specifically on fundamental frequency (F0) dynamics. Prosody in Hd is clinically described as involving monopitch, which has been confirmed in numerous studies reporting reduced within-utterance pitch variability. We show that a new measure of F0 dynamics, based on a superpositional pitch model that decomposes the F0 contour into a declining phrase curve and (generally, single-peaked) accent curves, performs more accurate Hd vs. Control classification than simpler versions of the model or than conventional variability statistics.",2-Apr-15
8361563,Automatic detection of speech disorder in dysarthria using extended speech feature extraction and neural networks classification,"This paper presents an automatic detection of Dysarthria, a motor speech disorder, using extended speech features called Centroid Formants. Centroid Formants are the weighted averages of the formants extracted from a speech signal. This involves extraction of the first four formants of a speech signal and averaging their weighted values. The weights are determined by the peak energies of the bands of frequency resonance, formants. The resulting weighted averages are called the Centroid Formants. In our proposed methodology, these centroid formants are used to automatically detect Dysarthric speech using neural network classification technique. The experimental results recorded after testing this algorithm are presented. The experimental data consists of 200 speech samples from 10 Dysarthric speakers and 200 speech samples from 10 age-matched healthy speakers. The experimental results show a high performance using neural networks classification. A possible future research related to this work is the use of these extended features in speaker identification and recognition of disordered speech.",21-May-18
9076507,Analysis of Time Domain Features of Dysarthria Speech,"In general, Speech can be described as the ability to express thoughts and feelings by articulating sounds in order to communicate with the person who understand the speech and accordingly interpret their action. The types of communication disorders that affects a person¡¯s ability to produce speech sounds due to the lack of control over motor functions and articulators are speech disorders. Many people of varying age groups suffer from speech disorders and require early treatment in order to correct them. This paper analyses the time domain features such as jitter and shimmer that are extracted from the speech samples of dysarthria and healthy people. This is done by looking for dissimilarities between the different speech features preset in the normal healthy person and the disordered one by employing steps such as pre-processing followed by feature extraction.",23-Apr-20
9291830,Emotional Communication Assist Interface App for People with Dysarthria,"Text to speech (TTS) helps people who have speech disorders communicate with other people. The current TTS can express emotion, but this requires extra time and effort. We developed a TTS application by which users can render messages with emotion with ease by changing the pitch angle of a smartphone. We designed two types of TTS: free input and phrase selection. Also, we calculated the TTS editing parameters for each degree of emotion on the basis of the Online Game Voice Chat Corpus (OGVC).",21-Dec-20
10661368,Fuzzy Expectation Maximization Phoneme Prediction in Diffusion Model-based Dysarthria Voice Conversion,"In this paper proposed an effective fuzzy expectation-maximization phoneme prediction method in diffusion model-based dysarthria voice conversion (FEMPPDM-DVC) which is accessible to (i) training without parallel data (ii) converting a longer duration of the audio data (iii) preserves speaker identity. By integrating Fuzzy Expectation-Maximization (FEM) clustering and Diffusion model-based dysarthria voice conversion approach, the proposed method is able gradually generate normal utterances. Feature extraction is performed using Mel-frequency cepstral coefficients (MFCCs), a robust method in acoustic feature extraction in Text-to-Speech systems. Ensures the effectiveness and accuracy, through repeated parameter adjustment using the FEM clustering algorithm. The conversion network is a diffusion model-based structure, which can convert normal utterances to dysarthria utterances in the forward diffusion process. After forward diffusion process, the dysarthria utterance will go through a reverse diffusion process to convert dysarthria voice to normal utterance. Once converted, a GAN-based vocoder is applied to convert mel-frequency spectrogram to waveform. Objective evaluation is conducted on the Saarbr¨¹cken Voice Database (SVD) dataset show that FEMDDPM-DVC is able to improve the intelligibility and naturalness of dysarthria utterances in 15 kinds of dysarthria voice. The proposed method is compared with five other dysarthria voice conversion methods, show that the proposed method has the most performance among other method.",6-Sep-24
10912315,Revolutionary Dysarthria Analysis Through Convolutional Neural Networks,"Dysarthria occurs when there are impairments in the muscles necessary for speech, including those in the lips, tongue, voice box, and breathing muscles. This condition can result in unclear speech, even in individuals who are skilled communicators. Dysarthria can range from mild speech difficulties, where speech is hard to understand, to severe cases, where speech is completely unclear. A method for distinguishing between different types of speech involves using recordings and advanced computational techniques such as convolutional neural networks (CNNs). The strengths of CNNs are leveraged to construct a highly effective model for detecting dysarthria in speech samples. The dataset utilized includes recordings from individuals with and without dysarthria. The results indicate that the CNN model performs exceptionally well, achieving precision, recall, and F1-scores of 0.99 for both categories. With an accuracy of 0.99, the model demonstrates a high level of proficiency in differentiating between speech affected by dysarthria and normal speech. These findings highlight the effectiveness and utility of this CNN-based approach in diagnosing and assessing dysarthria. It offers valuable potential for assisting healthcare professionals and enhancing personalized speech therapy interventions.",13-Mar-25
10675073,A Study of Speech Recognition Techniques for Dysarthria Speeches Based on Digit Recognition,"With the introduction of speech recognition technology into people's lives, the application of which is no longer limited to ordinary people, but begins to target special populations, such as patients with dysarthria. It has become a major research challenge to build a high-performance speech recognition system for patients with dysarthria. To address this problem, in this paper the speech data of four patients with dysarthria and four healthy speakers on digital commands are firstly collected, secondly several speech recognition experiments are separately conducted by using Aishell-2 and Wenetspeech, two pre-trained models based on the WeNet open-source architecture, as well as the four major commercial recognition API systems, at the end a method to optimize the dysarthria data by using the so-vits-svc tool is proposed. The experiments show that the current state-of-the-art speech recognition model has a high recognition rate for speech data from the general population, but there is still room for improvement in the recognition performance of speech data from individuals with dysarthria. Later the optimization method for the dysarthria data proposed in this paper effectively improves the quality of speech data. For the two above open-source pre-trained models, the recognition rates have increased by 60% and 67.64 % compared to the original data, respectively.",24-Sep-24
7897299,Fractal features for automatic detection of dysarthria,"Amytrophic lateral sclerosis (ALS) is an incurable neurodegenerative disease. Difficulty articulating speech, dysarthria, is a common early symptom of ALS. Detecting dysarthria currently requires manual analysis of several different speech tasks by pathology experts. This is time consuming and can lead to misdiagnosis. Many existing automatic classification approaches require manually preprocessing recordings, separating individual spoken utterances from a repetitive task. In this paper, we propose a fully automated approach which does not rely on manual preprocessing. The proposed method uses novel features based on fractal analysis. Acoustic and associated articulatory recordings of a standard speech diagnostic task, the diadochokinetic test (DDK), are used for classification. This study's experiments show that this approach attains 90.2% accuracy with 94.2% sensitivity and 85.1% specificity.",13-Apr-17
6190184,Assessing Dysarthria severity using global statistics and boosting,"A new method for automatic assessment of Dysarthria severity is described. It uses the forward selection method (FSM) on global statistics of low-complexity features to find effective feature sets. FSM is embedded in a boosting algorithm that combines multiple weak classifiers to achieve a single strong classifier. Unlike standard boosting, this uses nonlinear class boundaries and unique feature sets per iteration. Results on a 39 speaker dysarthria database are described.",26-Apr-12
10250600,An Intelligent System for Dysarthria Classification of Male and Female Processed Dataset using Sequential Model Parameters,"There are several current studies including various methods for treating dysarthria in various developing countries. Research-based dysarthria treatments take a multidisciplinary approach that encompasses speech therapy, assistive technology, neurosurgery, pharmaceutical therapies, non-invasive brain stimulation, machine learning and AI methods. These methods seek to raise the general quality of life, communication and speaking abilities of dysarthria sufferers. With a 90% accuracy rate, the proposed sequential model was found to have good classification performance for identifying Dysarthria. Researchers have also been looking at the use of Machine Learning (ML) and Artificial Intelligence (AI) approaches to create tools and systems that can help people with dysarthria to speak and communicate for social welfare and provide access to best remedies.",22-Sep-23
7344537,Dysarthria diagnosis via respiration and phonation,This report discusses the implementation of a computerized application - the Computerised Frenchay Dysarthria Assessment Procedure (CFDA) - which uses digital signal processing (DSP) techniques to objectively evaluate digitised speech recordings in order to detect any symptoms of dysarthria (a type of motor speech disorder). This investigation focuses specifically on two CFDA diagnostic sub-applications which assess a patient's ability to maintain a prolonged exhalation (the ¡°Respiration at Rest¡± task) as well as execute a steady state phonation (i.e. the ¡°Sustained Phonation¡± task). It is demonstrated that combining the functionality of these two sub-applications substantially increases their diagnostic effectiveness in the context of identifying a particular variety of dysarthria known as spastic dysarthria. It is further demonstrated that certain patterns of energy fluctuations are closely correlated with manifestations of spastic dysarthria. The CFDA is intended for use in real-world conditions to assist speech and language therapists when conducting clinical evaluations.,3-Dec-15
10892620,Deep Learning Based Dysarthria Detection: A Comprehensive Approach,"Making a model that can analyze numerous input features and predict whether a person will develop dysarthria is the first step in utilizing machine learning to forecast diseases like dysarthria. A motor speech disorder called dysarthria can be caused by a variety of underlying conditions, such as degenerative disorders, traumatic brain injuries, or neurological disorders. The authors used the 2000 audio signals from males and females with and without dysarthria from the TORGO data set. To extract the important features from the audio signals, the authors used the MFCC approach. To determine if dysarthria is present or absent, a machine learning model or algorithm will be fed with these MFCC coefficients.",25-Feb-25
9629802,"Brain Signals to Rescue Aphasia, Apraxia and Dysarthria Speech Recognition","In this paper, we propose a deep learning-based algorithm to improve the performance of automatic speech recognition (ASR) systems for aphasia, apraxia, and dysarthria speech by utilizing electroencephalography (EEG) features recorded synchronously with aphasia, apraxia, and dysarthria speech. We demonstrate a significant decoding performance improvement by more than 50% during test time for isolated speech recognition task and we also provide preliminary results indicating performance improvement for the more challenging continuous speech recognition task by utilizing EEG features. The results presented in this paper show the first step towards demonstrating the possibility of utilizing non-invasive neural signals to design a real-time robust speech prosthetic for stroke survivors recovering from aphasia, apraxia, and dysarthria. Our aphasia, apraxia, and dysarthria speech-EEG data set will be released to the public to help further advance this interesting and crucial research.",9-Dec-21
1660840,Hmm-Based and Svm-Based Recognition of the Speech of Talkers With Spastic Dysarthria,"This paper studies the speech of three talkers with spastic dysarthria caused by cerebral palsy. All three subjects share the symptom of low intelligibility, but causes differ. First, all subjects tend to reduce or delete word-initial consonants; one subject deletes all consonants. Second, one subject exhibits a painstaking stutter. Two algorithms were used to develop automatic isolated digit recognition systems for these subjects. HMM-based recognition was successful for two subjects, but failed for the subject who deletes all consonants. Conversely, digit recognition experiments assuming a fixed word length (using SVMs) were successful for two subjects, but failed for the subject with the stutter.",24-Jul-06
5495563,Design of a dysarthria classifier using global statistics of speech features,"Dysarthria is a neurological disorder in which the speech production system is impaired. There are five main types of dysarthrias depending on the location of the lesion in the nervous system. There is evidence suggesting a relationship between the location of the lesion and the resulting speech characteristics. This paper describes a non-intrusive classifier to identify the dysarthria type in a person using global statistics, e.g., mean, variance, etc., of speech features. A tree-based classifier was developed using multiple low-level maximum likelihood classifiers as inputs. An error of 10.5% was achieved in the classification of three types of dysarthrias.",28-Jun-10
10157285,Dysarthria Speech Disorder Classification Using Traditional and Deep Learning Models,"Dysarthria is a motor speech disorder that results in speech difficulties due to the weakness of associated muscles. This unclear speech makes it difficult for dysarthric patients to present himself understood. This neurological limitation is usually occurs due to damages to the brain or central nervous system. Speech therapy can be effectively employed to enhance the range and consistency of voice production and improve intelligibility and communicative effectiveness. Assessing the degree of severity of dysarthria provides vital information on the patient's progress which inturn assists pathologists in arriving at a treatment plan that includes developing automated voice recognition system suitable for dysarthria patients. This work performs an exhaustive study on dysarthria severity level classification using deep neural network (DNN) and convolution neural network (CNN) architectures. Mel Frequency Cepstral Coefficients (MFCCs) and their derivatives constitute feature vectors for classification. Using the UA-Speech database, the performance metrics of DNN/CNN based learning models have been compared to baseline classifiers like support vector machine (SVM) and Random Forest (RF). The highest classification accuracy of 97.6\% is reported for DNN under UA speech database. A detailed examination of the performance from the models discussed above reveal that appropriate choice of deep learning architecture ensures better results than traditional classifiers like SVM and Random Forest.",26-Jun-23
10527645,Harnessing Deep Learning Techniques for Dysarthria Detection,"Dysarthria, a motor speech disorder resulting from neurological impairments. This study explores various approaches for the automated detection of dysarthria, integrating both traditional and emerging technologies. Speech assessments by acoustic analysis, machine learning models, and deep learning techniques are considered. Machine learning models are trained on datasets containing normal and dysarthric speech for males and females, while deep learning methods, including convolutional and recurrent neural networks, are employed to automatically learn features from speech data. Our goal is to develop a reliable and accessible dysarthria detection system thatcomplements the expertise of healthcare professionals. Validation using diverse datasets is emphasized, acknowledging the importance of early detection and intervention in improving outcomes for individuals with dysarthria.",16-May-24
10730941,Advancing Speech Disorder Diagnostics: CNN Innovations in Dysarthria Recognition,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. The capacity to communicate is greatly affected by dysarthria, thus early diagnosis is critical for effective therapies and improved patient outcomes. The study employed a Convolutional Neural Network (CNN) for speech classification using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. With 500 samples each, collected over distinct sessions, the dataset contains both dysarthric and non-dysarthric people of both sexes. Distinguishing between dysarthric and non-dysarthric occurrences, the CNN-based approach achieves an astonishing 96% accuracy. This shows how deep learning technology may help with early dysarthria identification and enable rapid therapy for affected individuals. The findings of this study have important implications for the development of diagnostic tools and may lead to better living conditions for those who struggle with speaking.",29-Oct-24
9414283,"Automatic And Perceptual Discrimination Between Dysarthria, Apraxia of Speech, and Neurotypical Speech","Automatic techniques in the context of motor speech disorders (MSDs) are typically two-class techniques aiming to discriminate between dysarthria and neurotypical speech or between dysarthria and apraxia of speech (AoS). Further, although such techniques are proposed to support the perceptual assessment of clinicians, the automatic and perceptual classification accuracy has never been compared. In this paper, we investigate a three-class automatic technique and a set of handcrafted features for the discrimination of dysarthria, AoS and neurotypical speech. Instead of following the commonly used One-versus-One or One-versus-Rest approaches for multi-class classification, a hierarchical approach is proposed. Further, a perceptual study is conducted where speech and language pathologists are asked to listen to recordings of dysarthria, AoS, and neurotypical speech and decide which class the recordings belong to. The proposed automatic technique is evaluated on the same recordings and the automatic and perceptual classification performance are compared. The presented results show that the hierarchical classification approach yields a higher classification accuracy than baseline One-versus-One and One-versus-Rest approaches. Further, the presented results show that the automatic approach yields a higher classification accuracy than the perceptual assessment of speech and language pathologists, demonstrating the potential advantages of integrating automatic tools in clinical practice.",13-May-21
8512311,Quantitative Assessment of Syllabic Timing Deficits in Ataxic Dysarthria,"Parametric analysis of Cerebellar Dysarthria (CD) may be valuable and more informative compared to its clinical assessment. A quantifiable estimation of the timing deficits in repeated syllabic utterance is described in the current study. Thirty-five individuals were diagnosed with cerebellar ataxia to varying degrees and twenty-six age-matched healthy controls were recruited. To automatically detect the local maxima of each syllable in the recorded speech files, a topographic prominence incorporated concept is designed. Subsequently, four acoustic features and eight corresponding parametric measurements are extracted to identify articulatory deficits in ataxic dysarthria. A comparative study on the behaviour of these measures for dysarthric and non-dysarthric subjects is presented in this paper. The results are further explored using a dimensionreduction tool (Principal Component Analysis) to emphasize variation and bring out the strongest discriminating patterns in our feature dataset.",28-Oct-18
10781716,Non-invasive stroke diagnosis using speech data from dysarthria patients,"Acute Ischemic Stroke (AIS) is a major cause of disability and can lead to death in severe cases. A common symptom of AIS, dysarthria, significantly impacts the quality of life of patients. In this study, we developed a deep learning model using dysarthria data for cost-effective and non-invasive brain stroke diagnosis. We utilized models such as ResNet50, InceptionV4, ResNeXt50, SEResNeXt18, and AttResNet50 to effectively extract and classify speech features indicative of stroke symptoms. These models demonstrated high performance, with Sensitivity, Specificity, Precision, Accuracy, and F1-score values reaching 96.77%, 96.08%, 92.82%, 95.52%, and 93.82%, respectively. Our approach offers a non-invasive, cost-effective alternative for early stroke detection, with potential for further accuracy improvements through additional research. This method promises rapid, economical early diagnosis, which could positively impact long-term treatment and healthcare options.",17-Dec-24
10800228,Fine-Tuning Pre-Trained Audio Models for Dysarthria Severity Classification: A Second Place Solution in the Multimodal Dysarthria Severity Classification Challenge,"Dysarthria, a neurological disorder affecting speech, poses significant challenges for automatic diagnosis and severity classification due to its complexity and the scarcity of relevant datasets. This study addresses these challenges by leveraging the dataset provided by the ISCSLP 2024 Multimodal Dysarthria Severity Classification Challenge. Our approach primarily involves two key steps: splitting the training set into training and validation subsets, and fine-tuning pre-trained au-dio models to adapt them to the task. To ensure robust evaluation and prevent label leakage, we employed the StratifiedGroupKFold function from sklearn for dataset splitting, ensuring that training and validation sets do not share participants. This method allowed us to maintain consistent statistical distributions across folds. For model finetuning, we selected two pre-trained audio models, w2v-bert-2.0 and whisper-Iarge-v3, and fine-tuned them on different folds of the dataset. Our results indicate that the w2v-bert-2.0 model fine-tuned on fold-2 achieved the highest performance, with a validation Fl-score of 0.699 and an online score of 7.7452. The experimental results, including confusion matrices and embedding distributions, highlight the model's ability to distinguish between different severity levels of dysarthria. Our approach achieved a commendable second place in the competition¡¯ demonstrating the effectiveness of fine-tuning pre-trained audio models for this task. Future work will explore the integration of multimodal data and multi-task learning strategies to further enhance model performance.",23-Dec-24
10307923,Automated Detection and Severity Assessment of Dysarthria using Raw Speech,"Dysarthria is a medical condition that impairs an individual¡¯s ability to speak clearly due to muscle weakness or paralysis. To diagnose and monitor dysarthria severity, this article proposes the use of a deep learning model that utilizes raw speech waveforms. This approach eliminates the need for feature engineering and enhances the model¡¯s ability to handle noise and speech variability. The proposed system was compared to a standard convolutional neural network (CNN) model and was found to perform better in both dysarthria severity classification and dysarthria/healthy control classification tasks. The results indicate that the SincNet model achieved an accuracy of 95.7% and 99.6% in these tasks, respectively. The proposed system can aid clinicians in diagnosing and monitoring dysarthria severity and could have broader applications in speech-related disorders. The study emphasizes the importance of using raw waveform-based models for speech analysis and demonstrates the effectiveness of SincNet in automatic dysarthria/healthy control classification and dysarthria severity assessment.",23-Nov-23
6936631,Investigation on articulatory and acoustic characteristics of dysarthria,"Direct measurement of articulation contributes to figure out the mechanism of dysarthric speech production accurately, comparing to analyzing acoustic signal alone. This study makes a statistical comparison between dysarthric and normal speech, and investigates and analyzes dysarthric characteristics based on articulatory and acoustic data of continuous English utterance. The distribution of the articulatory point is calculated for each vowel, where the vowels show a relatively smaller region for dysarthria than for normal speech. This implies that the speakers with dysarthria may have some difficulties to fully use the articulatory space as the speakers without dysarthria. The rhythm and sound source are analyzed using autocorrelation function, power spectrum and linear prediction coding. The results reveal that the speakers without dysarthria can keep steady rhythm and energy in uttering consonant-vowel repetition sequences but it is hard for the speakers with dysarthria to maintain the stability. Meanwhile, the dysarthric sound source shows unstable period of the fundamental frequency, which reflects that the speakers with dysarthria could not control the glottis movement well.",27-Oct-14
10550236,Evolving Diagnostic Techniques for Speech Disorders: Investigating Dysarthria Classification Through DenseNet201 CNN Framework,"The primary subject of this research work pertains to dysarthria, a prevalent speech impairment observed in individuals diagnosed with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Prompt detection of dysarthria is essential for effective therapies and improved patient results, as it significantly impacts communication proficiency. The research employed a DenseNet201 Convolutional Neural Network (CNN) to categorize speech using the TORGO database, which has 2000 samples of individuals with and without dysarthria, representing various genders. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each dataset consists of 500 samples, which were collected during distinct sessions. The DenseNet201 convolutional neural network (CNN) technique has a notable accuracy rate of 96% in distinguishing between cases of dysarthria and non-dysarthria. This outcome underscores the potential of deep learning technology in aiding the timely identification of dysarthria and facilitating fast interventions for affected individuals. This work provides valuable insights on the progress of diagnostic capabilities and offers a potential avenue for enhancing the well-being of those experiencing speech impairments.",11-Jun-24
10902941,Analysis of Features for Dysarthria Severity Classification from Speech,"Dysarthria is a disorder that affects the ability of an individual to speak clearly. Diagnosis of the severity of dysarthria can aid in providing appropriate therapy to the individual. Therefore, the current work focuses on identifying features that can be used to estimate the severity of dysarthria. In this regard, two feature sets are considered, namely DisVoice and OpenSMILE, and the genetic algorithm is used to identify the most suitable list of features from both feature sets using 3 speech corpora, namely SSN-TDSC, Torgo, and UA Speech corpora. In order to test the effectiveness of these features, classifiers are trained on each feature set as a whole and on the features identified by the genetic algorithm, and their performance compared. It is observed that articulatory and prosodic features are most important in the diagnosis of severity of dysarthria. A maximum accuracy of 85% is obtained with the shortlisted DisVoice features and 97% with the OpenSMILE features.",5-Mar-25
10800159,Multi-Modal Dysarthria Severity Assessment Using Dual-Branch Feature Decoupling Network and Mixed Expert Framework,"Dysarthria, a motor speech disorder resulting from neurological damage, significantly impairs an individual's ability to articulate words. Assessing the severity of dysarthria is crucial for effective therapeutic interventions and rehabilitation strategies. However, current methods are time-consuming and subjective, leading to potential inconsistencies. This study proposed a dual-branch feature decoupling network and mixed expert framework for the automatic diagnosis and assessment of dysarthria. The proposed hybrid network architecture integrates a ResNet-based branch for audio data with an attention module and a 3D ResNet branch for video data, and was evaluated on the Multimodal Dysarthria Severity Assessment Challenge (MDSA) dataset, achieving significant performance improvements and ranking first in the challenge with a best score of 8.7404. The study's findings highlight the efficacy of the proposed framework in capturing essential features from multimodal data, contributing to more accurate and reliable assessments of dysarthria.",23-Dec-24
10448175,Spectral Analysis of Vowels and Fricatives at Varied Levels of Dysarthria Severity for Amyotrophic Lateral Sclerosis,"Dysarthria due to Amyotrophic Lateral Sclerosis (ALS) affects the acoustic characteristics of different speech sounds. The effects intensify with increasing severity leading to the collapse of the acoustic space of the affected individuals. With an aim to characterize such changes in the acoustic space, this paper studies the variations in band-specific and full-band spectral properties of 4 sustained vowels (/a/, /i/, /o/, /u/) and 3 sustained fricatives (/s/, /sh/, /f/) at different dysarthria severity levels. Effect of dysarthria on spectral features of these phonemes are not well explored. Statistical comparison of these features among different severities for the phonemes considered and among different vowels/fricatives for every severity level using speech data from 119 ALS and 40 healthy subjects indicate the followings. Though all band-specific and full-band features of the three fricatives and most of those features for the four vowels become statistically similar at high severity levels, certain features remain distinguishable. Spectral differences in 0-2 kHz band between /a/ and the other vowels and in the 2-6 kHz band between /a/ and /o/, /u/ persist through all severity levels. Moreover, properties of /f/ remain mostly unchanged with increasing dysarthria severity levels.",18-Mar-24
10673651,Advancing Speech Disorder Diagnostics: A Comprehensive Study on Dysarthria Classification with CNN,"This study article focuses on dysarthria, a speech problem that is often seen in patients with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early identification of dysarthria is crucial for successful treatments and better patient outcomes, since it has a substantial influence on communication ability. Using the TORGO database, which consists of 2000 samples of persons with and without dysarthria, spanning different genders, the research use a Convolutional Neural Network (CNN) to classify speech. The dataset includes both dysarthric and non-dysarthric individuals of both genders, with 500 samples each, captured during separate sessions. The CNN-based technique demonstrates an impressive 96% accuracy in differentiating between dysarthric and non-dysarthric instances, highlighting the promise of deep learning technology in assisting with the early detection of dysarthria and enabling prompt therapies for afflicted people. This study makes significant contributions to the advancement of diagnostic capacities and presents a potential opportunity to improve the quality of life for those with speech difficulties.",18-Sep-24
10581063,Progressing Speech Disorder Identification: A Thorough Investigation into Dysarthria Categorization Utilizing ResNet50 CNN,"The speech issue of dysarthria, which is frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS), is the subject of this research article. Timely detection of dysarthria is essential for effective interventions and improved patient results, as it significantly impacts communication proficiency. The study employs the TORGO database, which has 2000 samples of individuals with and without dysarthria, encompassing various genders. The researchers utilize a ResNet50 Convolutional Neural Network (CNN) to categorize speech. The dataset comprises individuals of both genders, encompassing both dysarthric and non-dysarthric individuals. Each group consists of 500 samples, which were recorded over distinct sessions. The CNN-based technique achieves a remarkable 96% accuracy in distinguishing between dysarthric and non-dysarthric instances. This underscores the potential of deep learning technology in aiding the early identification of dysarthria and facilitating timely treatments for affected individuals. This study provides valuable contributions to the enhancement of diagnostic capabilities and offers a potential avenue for enhancing the quality of life for individuals experiencing speech impairments.",12-Jul-24
10625627,Enhancing the Diagnosis of Speech Disorders: An In-Depth Investigation into Dysarthria Classification Using the ResNet18 Model,"This research article concentrates on dysarthria, a speech impediment commonly observed in individuals with conditions such as cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective interventions and improved patient outcomes, as it significantly impacts communication abilities. Employing the TORGO database, comprising 2000 samples from individuals with and without dysarthria, encompassing diverse genders, the study utilizes a Convolutional Neural Network (ResNet18 Model) for speech classification. The dataset encompasses both dysarthric and non-dysarthric subjects of both genders, with 500 samples each, recorded in separate sessions. The ResNet18 Model-based approach demonstrates an impressive 96% accuracy in distinguishing between dysarthric and non-dysarthric instances, underscoring the potential of deep learning technology in aiding early dysarthria detection and facilitating timely interventions. This investigation significantly contributes to advancing diagnostic capabilities and presents a promising avenue to enhance the quality of life for individuals grappling with speech difficulties.",22-Aug-24
10095366,Statistical Analysis of Speech Disorder Specific Features to Characterise Dysarthria Severity Level,"Poor coordination of the speech production subsystems due to any neurological injury or a neuro-degenerative disease leads to dysarthria, a neuro-motor speech disorder. Dysarthric speech impairments can be mapped to the deficits caused in phonation, articulation, prosody, and glottal functioning. With the aim of reducing the subjectivity in clinical evaluations, many automated systems are proposed in the literature to assess the dysarthria severity level using these features. This work aims to analyse the suitability of these features in determining the severity level. A detailed investigation is done to rank these features for their efficacy in modelling the pathological aspects of dysarthric speech, using the technique of paraconsistent feature engineering. The study used two dysarthric speech databases, UA-Speech and TORGO. It puts light into the fact that both the prosody and articulation features are best useful for dysarthria severity estimation, which was supported by the classification accuracies obtained on using different machine learning classifiers.",5-May-23
8251336,Identification of Cerebellar Dysarthria with SISO Characterisation,"Quantitative identification of dysarthria plays a major role in the classification of its severity. This paper quantitatively analyses several components of cerebellar dysarthria. The methodology described in this study will be extended to other types of dysarthria via systematic analysis. The speech production model is characterized as a second-order singleinput and single-output (SISO), linear, time-invariant (LTI) system in our study. A comparative study on the behavior of the damping ratio and resonant frequency for dysarthric and non-dysarthric subjects is presented. The results are further analyzed using the Principal component analysis (PCA) technique to emphasize the variation and uncover strong patterns in the selected features. The effects of some other related factors like decay time and Q-factor are also highlighted.",11-Jan-18
10739183,CNN-Driven Innovations in Dysarthria Classification and Speech Disorder Management,"This research article addresses dysarthria, a speech disorder frequently observed in individuals with cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS). Early detection of dysarthria is essential for effective treatment and improved patient outcomes, as it significantly impacts communication abilities. Utilizing the TORGO database, which comprises 2000 speech samples from both dysarthric and non-dysarthric individuals across various genders, this study employs a Convolutional Neural Network (CNN) for classification. The dataset includes 500 samples each from both groups, collected in different sessions. The CNN approach achieves an impressive 96% accuracy in distinguishing dysarthric from non-dysarthric speech, showcasing the potential of deep learning technology in facilitating early dysarthria diagnosis and enabling timely interventions. This study makes substantial contributions to enhancing diagnostic capabilities and offers a promising avenue for improving the quality of life for individuals with speech disorders.",4-Nov-24
10800051,Constant Q Transform for Audio-Visual Dysarthria Severity Assessment,"This paper describes an automatic dysarthria severity assessment system submitted for the MDSA2024 challenge. The system utilizes audio and visual features to classify the severity of dysarthria. We investigate the effectiveness of different acoustic feature combinations, such as Mel spectrogram, filterbank and constant Q transform. Different encoders for audio data processing are compared in the experiments. The results demonstrate that the Conformer encoder achieves superior performance compared to the Densenet encoder on pure audio features. We further explore model-level fusion by combining audio and visual embeddings, leading to improvements in precision¡¯ recall, and accuracy metrics. The best-achieved score on the test set is 7.5579, with an individual F1-score of 0.7028. The findings suggest that the proposed system with Conformer encoder and model-level fusion holds promise for automatic dysarthria assessment.",23-Dec-24
10781584,Dysarthria Detection with Deep Representation Learning for Patients with Parkinson¡¯s Disease,"Dysarthria is a very common motor speech symptom in Parkinson¡¯s disease impairing normal communications of patients. Detection of dysarthria could assist clinical diagnosis and intervention of Parkinson¡¯s disease, provide monitoring approach for treatment-related side effects, and lead to effective speech therapy to prevent further communication and social deficits. Applying machine learning techniques to speech analysis for patients offers more resource-efficient, accessible and objective tools for screening and assessment of dysarthria. In this study, we constructed a multi-task speech dataset recorded from 600 participants with high data diversity to facilitate the development of detection models. We established a remote data acquisition and end-to-end prediction pipeline with deep representation learning, compared the performance with different feature-based learning and classification methods, and achieved a superior accuracy of over 90%. Different affecting factors were analyzed for model performance. Our proposed framework demonstrates the potential of developing and deploying an automated self-monitoring approach of dysarthria for patients with Parkinson¡¯s disease, which could benefit a large-scale population and their disease managements.",17-Dec-24
7953122,Automatic assessment of dysarthria severity level using audio descriptors,"Dysarthria is a motor speech impairment, often characterized by speech that is generally indiscernible by human listeners. Assessment of the severity level of dysarthria provides an understanding of the patient's progression in the underlying cause and is essential for planning therapy, as well as improving automatic dysarthric speech recognition. In this paper, we propose a non-linguistic manner of automatic assessment of severity levels using audio descriptors or a set of features traditionally used to define timbre of musical instruments and have been modified to suit this purpose. Multitapered spectral estimation based features were computed and used for classification, in addition to the audio descriptors for timbre. An Artificial Neural Network (ANN) was trained to classify speech into various severity levels within Universal Access dysarthric speech corpus and the TORGO database. An average classification accuracy of 96.44% and 98.7% was obtained for UA speech corpus and TORGO database respectively.",19-Jun-17
9287741,Automated Dysarthria Severity Classification Using Deep Learning Frameworks,"Dysarthria is a neuro-motor speech disorder that renders speech unintelligible, in proportional to its severity. Assessing the severity level of dysarthria, apart from being a diagnostic step to evaluate the patient's improvement, is also capable of aiding automatic dysarthric speech recognition systems. In this paper, a detailed study on dysarthia severity classification using various deep learning architectural choices, namely deep neural network (DNN), convolutional neural network (CNN) and long short-term memory network (LSTM) is carried out. Mel frequency cepstral coefficients (MFCCs) and its derivatives are used as features. Performance of these models are compared with a baseline support vector machine (SVM) classifier using the UA-Speech corpus and the TORGO database. The highest classification accuracy of 96.18% and 93.24% are reported for TORGO and UA-Speech respectively. Detailed analysis on performance of these models shows that a proper choice of a deep learning architecture can ensure better performance than the conventionally used SVM classifier.",18-Dec-20
10584052,Deep Learning Based Speech Recognition for Hyperkinetic Dysarthria Disorder,"Speech recognition is a technology that aims to transform human speech into text and has applications in a variety of fields, including information technology, healthcare, automobiles, and others. This research explores the advantages of employing deep learning methods to provide individualized assistance technology solutions for people with dysarthria. We proposed a Convolutional Temporal Bidirectional Network (CTBNet) model for translating Russian Hyperkinetic Dysarthria Disorder (RHDD) speech into text. CTBNet encodes input audio features using 1D convolution layers, and BidirectionalGRU (Bi-GRU) layers. The encoder effectively captures both short-term and long-term spatial temporal information. More importantly, CTBNet includes with an attention-CTC decoder, that is responsible for producing output texts. We utilized a dataset of 2797 recordings of RHDD speech, with a cumulative recorded duration of 2 hours and 33 minutes, for training purposes. The CTBNet model has achieved a 15% Character Error Rate (CER) and a 59% Word Error Rate (WER) on the dataset proposed. Our experimental findings show superior performance compared to state-of-the-art models, namely, 3xCNN, and 3xLSTM, when evaluated on the same dataset.",9-Jul-24
10805075,Developing a Hyperkinetic Dysarthria Speech Classification System using Residual Learning,"Hyperkinetic dysarthria abnormalities are exceedingly widespread across the worldwide populace. One of the most effective methodologies for disordered audio speech identification is classical deep learning technique. However, the efficiency of classification is impacted by the limitations imposed by the quality of the training dataset, such as expense and limited resources, data imbalance, and data annotation difficulties. Accordingly, we suggest implementing a residual learning framework (ResN et architecture) with various conditions and hyperparameters (batch size and learning rate) that improve the training process of deeper networks compared to earlier approaches. Pre-emphasis, windowing, and lifting techniques are applied to improve the quality of Mel-Frequency Cepstral Coefficients. In addition, we have introduced the hyperkinetic dysarthria speech dataset in the Russian language, consisting of 4 hours and 4 minutes of recorded speech. The empirical findings demonstrate that ResNet40 has an overall validation accuracy of 86.7%, surpassing other research models. It is anticipated that it will be recognized as an alternative diagnostic instrument for physicians in the future as research continues to progress.",25-Dec-24
10889800,Multilingual Speaker-Invariant Dysarthria Severity Assessment Using Adversarial Domain Adaptation and Self-Supervised Learning,"Traditional assessments for dysarthria are subjective and time-consuming, highlighting the need for automated, objective approaches that can be scaled for remote and resource-constrained environments. This paper introduces an adversarial domain adaptation framework tailored for dysarthria severity assessment, addressing the challenges of high intra-class variability and limited availability of dysarthric speech data. By framing speaker variability as a domain adaptation problem, we utilise an adversarially trained feature extractor to derive speaker-invariant yet discriminatively powerful representations utilising speech features learned through self-supervised learning. Experiments on previously unseen and diverse speakers reveal that the proposed approach yields a 7.86% average improvement across multilingual datasets compared to traditional severity-discriminative training, outperforming competitive baselines by 12.33% on average. Additionally, the method inherently supports privacy-preserving applications by minimising reliance on speaker-specific information. The results demonstrate strong alignment with clinical assessments, reinforcing our model¡¯s clinical relevance and effectiveness.",7-Mar-25
10929844,AI-Enabled Speech Monitoring for Dysarthria Detection in Consumer Electronics,"Speech is essential in human communication, and recent advancements in artificial intelligence (AI) have enabled new applications for voice data, particularly in health monitoring. Building on this progress, a home-based health detection system that utilizes voice signals provides an accessible method for users to independently identify and respond to conditions such as dysarthria, without the need for hospital or clinic visits. In this study, we developed and evaluated convolutional neural network (CNN) models to classify audio data from both healthy individuals and individuals with dysarthria. The dataset comprised command-based speech samples, which were segmented into sentence-specific input. Preprocessing steps included segmentation, downsampling, and feature extraction tailored for CNN input. The models exhibited high potential in distinguishing between normal and dysarthric states, with the most effective model achieving an f1-score of 96.18¡À4.7% and an accuracy of 96.01¡À5.02%. Furthermore, sentence structure and composition significantly influenced model performance, with specific sentences demonstrating higher classification accuracy. These findings suggest that AI-driven speech analysis may support detecting and managing specific health conditions in non-clinical environments. However, further work is needed to address data imbalance and sentence variability limitations. Future research could expand on real-world applications, particularly in settings with limited traditional health monitoring.",26-Mar-25
10848959,Dysarthria Severity Classification Using Phase Based Features of LP Residual,"Classifying the severity of speech impairment due to dysarthria is crucial for optimizing care and enhancing communication abilities for affected individuals. This study explores the use of the Modified Group Delay Function (MGDF) of LP residual signal in classifying dysarthria severity-levels. Evaluations were conducted using standard UA-Speech and TORGO datasets. A stratified Convolutional Neural Network (CNN) with 5-fold cross-validation validated the results. Baseline features included Linear Frequency Cepstral Coefficients (LFCC), Mel Frequency Cepstral Coefficients (MFCC), and Whisper module. Key performance evaluation metrics were accuracy, precision, recall, and F1-score. Finally, the latency period was analyzed for practical deployment of the system, system¡¯s ability to accurately recognize and process speech from any speaker, without needing to be specifically trained or adapted to individual voice characteristics.",27-Jan-25
10200180,Automatic Early Detection of Dysarthria using Deep Neural Network,"Dysarthria is dis-coordination among articulatory muscles responsible for articulation in the production of speech. A person with dysarthric disorder cannot control their tongue, hence, are prone to slurred speech or swallowing words which lead to improper pronunciation and less intelligibility of speech. This work focuses on the automatic early detection of Dysarthria. To elucidate the main idea, it must be understood that the whole detection procedure revolves around the speech intelligibility of a person. It becomes an arduous job to distinguish between a healthy person's speech and a person who is slowly evolving with the disorder. The prime motive of the work is to provide a proper classification of the disorder in its earliest stages. The common words and phrases recorded in the Universal Access database are used for this work. Mel Frequency Cepstral Coefficients (MFCC) are extracted from both controlled and high intelligible speech data, and fed to a Deep Neural Network (DNN) classifier. MFCC fed to the DNN classifier has provided the best classification accuracy for the above experimental setup.",7-Aug-23
8682324,Learning to Detect Dysarthria from Raw Speech,"Speech classifiers of paralinguistic traits traditionally learn from diverse hand-crafted low-level features, by selecting the relevant information for the task at hand. We explore an alternative to this selection, by learning jointly the classifier, and the feature extraction. Recent work on speech recognition has shown improved performance over speech features by learning from the waveform. We extend this approach to paralinguistic classification and propose a neural network that can learn a filterbank, a normalization factor and a compression power from the raw speech, jointly with the rest of the architecture. We apply this model to dysarthria detection from sentence-level audio recordings. Starting from a strong attention-based baseline on which mel-filterbanks outperform standard low-level descriptors, we show that learning the filters or the normalization and compression improves over fixed features by 10% absolute accuracy. We also observe a gain over OpenSmile features by learning jointly the feature extraction, the normalization, and the compression factor with the architecture. This constitutes a first attempt at learning jointly all these operations from raw audio for a speech classification task.",17-Apr-19
7078586,Modeling fundamental frequency dynamics in hypokinetic dysarthria,"Hypokinetic dysarthria (Hd), which often accompanies Parkinson's Disease (PD), is characterized by hypernasality and by compromised phonation, prosody, and articulation. This paper proposes automated methods for detection of Hd. Whereas most such studies focus on measures of phonation, this paper focuses on prosody, specifically on fundamental frequency (F0) dynamics. Prosody in Hd is clinically described as involving monopitch, which has been confirmed in numerous studies reporting reduced within-utterance pitch variability. We show that a new measure of F0 dynamics, based on a superpositional pitch model that decomposes the F0 contour into a declining phrase curve and (generally, single-peaked) accent curves, performs more accurate Hd vs. Control classification than simpler versions of the model or than conventional variability statistics.",2-Apr-15
8361563,Automatic detection of speech disorder in dysarthria using extended speech feature extraction and neural networks classification,"This paper presents an automatic detection of Dysarthria, a motor speech disorder, using extended speech features called Centroid Formants. Centroid Formants are the weighted averages of the formants extracted from a speech signal. This involves extraction of the first four formants of a speech signal and averaging their weighted values. The weights are determined by the peak energies of the bands of frequency resonance, formants. The resulting weighted averages are called the Centroid Formants. In our proposed methodology, these centroid formants are used to automatically detect Dysarthric speech using neural network classification technique. The experimental results recorded after testing this algorithm are presented. The experimental data consists of 200 speech samples from 10 Dysarthric speakers and 200 speech samples from 10 age-matched healthy speakers. The experimental results show a high performance using neural networks classification. A possible future research related to this work is the use of these extended features in speaker identification and recognition of disordered speech.",21-May-18
9076507,Analysis of Time Domain Features of Dysarthria Speech,"In general, Speech can be described as the ability to express thoughts and feelings by articulating sounds in order to communicate with the person who understand the speech and accordingly interpret their action. The types of communication disorders that affects a person¡¯s ability to produce speech sounds due to the lack of control over motor functions and articulators are speech disorders. Many people of varying age groups suffer from speech disorders and require early treatment in order to correct them. This paper analyses the time domain features such as jitter and shimmer that are extracted from the speech samples of dysarthria and healthy people. This is done by looking for dissimilarities between the different speech features preset in the normal healthy person and the disordered one by employing steps such as pre-processing followed by feature extraction.",23-Apr-20
9291830,Emotional Communication Assist Interface App for People with Dysarthria,"Text to speech (TTS) helps people who have speech disorders communicate with other people. The current TTS can express emotion, but this requires extra time and effort. We developed a TTS application by which users can render messages with emotion with ease by changing the pitch angle of a smartphone. We designed two types of TTS: free input and phrase selection. Also, we calculated the TTS editing parameters for each degree of emotion on the basis of the Online Game Voice Chat Corpus (OGVC).",21-Dec-20
10661368,Fuzzy Expectation Maximization Phoneme Prediction in Diffusion Model-based Dysarthria Voice Conversion,"In this paper proposed an effective fuzzy expectation-maximization phoneme prediction method in diffusion model-based dysarthria voice conversion (FEMPPDM-DVC) which is accessible to (i) training without parallel data (ii) converting a longer duration of the audio data (iii) preserves speaker identity. By integrating Fuzzy Expectation-Maximization (FEM) clustering and Diffusion model-based dysarthria voice conversion approach, the proposed method is able gradually generate normal utterances. Feature extraction is performed using Mel-frequency cepstral coefficients (MFCCs), a robust method in acoustic feature extraction in Text-to-Speech systems. Ensures the effectiveness and accuracy, through repeated parameter adjustment using the FEM clustering algorithm. The conversion network is a diffusion model-based structure, which can convert normal utterances to dysarthria utterances in the forward diffusion process. After forward diffusion process, the dysarthria utterance will go through a reverse diffusion process to convert dysarthria voice to normal utterance. Once converted, a GAN-based vocoder is applied to convert mel-frequency spectrogram to waveform. Objective evaluation is conducted on the Saarbr¨¹cken Voice Database (SVD) dataset show that FEMDDPM-DVC is able to improve the intelligibility and naturalness of dysarthria utterances in 15 kinds of dysarthria voice. The proposed method is compared with five other dysarthria voice conversion methods, show that the proposed method has the most performance among other method.",6-Sep-24
10912315,Revolutionary Dysarthria Analysis Through Convolutional Neural Networks,"Dysarthria occurs when there are impairments in the muscles necessary for speech, including those in the lips, tongue, voice box, and breathing muscles. This condition can result in unclear speech, even in individuals who are skilled communicators. Dysarthria can range from mild speech difficulties, where speech is hard to understand, to severe cases, where speech is completely unclear. A method for distinguishing between different types of speech involves using recordings and advanced computational techniques such as convolutional neural networks (CNNs). The strengths of CNNs are leveraged to construct a highly effective model for detecting dysarthria in speech samples. The dataset utilized includes recordings from individuals with and without dysarthria. The results indicate that the CNN model performs exceptionally well, achieving precision, recall, and F1-scores of 0.99 for both categories. With an accuracy of 0.99, the model demonstrates a high level of proficiency in differentiating between speech affected by dysarthria and normal speech. These findings highlight the effectiveness and utility of this CNN-based approach in diagnosing and assessing dysarthria. It offers valuable potential for assisting healthcare professionals and enhancing personalized speech therapy interventions.",13-Mar-25
10675073,A Study of Speech Recognition Techniques for Dysarthria Speeches Based on Digit Recognition,"With the introduction of speech recognition technology into people's lives, the application of which is no longer limited to ordinary people, but begins to target special populations, such as patients with dysarthria. It has become a major research challenge to build a high-performance speech recognition system for patients with dysarthria. To address this problem, in this paper the speech data of four patients with dysarthria and four healthy speakers on digital commands are firstly collected, secondly several speech recognition experiments are separately conducted by using Aishell-2 and Wenetspeech, two pre-trained models based on the WeNet open-source architecture, as well as the four major commercial recognition API systems, at the end a method to optimize the dysarthria data by using the so-vits-svc tool is proposed. The experiments show that the current state-of-the-art speech recognition model has a high recognition rate for speech data from the general population, but there is still room for improvement in the recognition performance of speech data from individuals with dysarthria. Later the optimization method for the dysarthria data proposed in this paper effectively improves the quality of speech data. For the two above open-source pre-trained models, the recognition rates have increased by 60% and 67.64 % compared to the original data, respectively.",24-Sep-24
7897299,Fractal features for automatic detection of dysarthria,"Amytrophic lateral sclerosis (ALS) is an incurable neurodegenerative disease. Difficulty articulating speech, dysarthria, is a common early symptom of ALS. Detecting dysarthria currently requires manual analysis of several different speech tasks by pathology experts. This is time consuming and can lead to misdiagnosis. Many existing automatic classification approaches require manually preprocessing recordings, separating individual spoken utterances from a repetitive task. In this paper, we propose a fully automated approach which does not rely on manual preprocessing. The proposed method uses novel features based on fractal analysis. Acoustic and associated articulatory recordings of a standard speech diagnostic task, the diadochokinetic test (DDK), are used for classification. This study's experiments show that this approach attains 90.2% accuracy with 94.2% sensitivity and 85.1% specificity.",13-Apr-17
6190184,Assessing Dysarthria severity using global statistics and boosting,"A new method for automatic assessment of Dysarthria severity is described. It uses the forward selection method (FSM) on global statistics of low-complexity features to find effective feature sets. FSM is embedded in a boosting algorithm that combines multiple weak classifiers to achieve a single strong classifier. Unlike standard boosting, this uses nonlinear class boundaries and unique feature sets per iteration. Results on a 39 speaker dysarthria database are described.",26-Apr-12
10250600,An Intelligent System for Dysarthria Classification of Male and Female Processed Dataset using Sequential Model Parameters,"There are several current studies including various methods for treating dysarthria in various developing countries. Research-based dysarthria treatments take a multidisciplinary approach that encompasses speech therapy, assistive technology, neurosurgery, pharmaceutical therapies, non-invasive brain stimulation, machine learning and AI methods. These methods seek to raise the general quality of life, communication and speaking abilities of dysarthria sufferers. With a 90% accuracy rate, the proposed sequential model was found to have good classification performance for identifying Dysarthria. Researchers have also been looking at the use of Machine Learning (ML) and Artificial Intelligence (AI) approaches to create tools and systems that can help people with dysarthria to speak and communicate for social welfare and provide access to best remedies.",22-Sep-23
7344537,Dysarthria diagnosis via respiration and phonation,This report discusses the implementation of a computerized application - the Computerised Frenchay Dysarthria Assessment Procedure (CFDA) - which uses digital signal processing (DSP) techniques to objectively evaluate digitised speech recordings in order to detect any symptoms of dysarthria (a type of motor speech disorder). This investigation focuses specifically on two CFDA diagnostic sub-applications which assess a patient's ability to maintain a prolonged exhalation (the ¡°Respiration at Rest¡± task) as well as execute a steady state phonation (i.e. the ¡°Sustained Phonation¡± task). It is demonstrated that combining the functionality of these two sub-applications substantially increases their diagnostic effectiveness in the context of identifying a particular variety of dysarthria known as spastic dysarthria. It is further demonstrated that certain patterns of energy fluctuations are closely correlated with manifestations of spastic dysarthria. The CFDA is intended for use in real-world conditions to assist speech and language therapists when conducting clinical evaluations.,3-Dec-15
9629802,"Brain Signals to Rescue Aphasia, Apraxia and Dysarthria Speech Recognition","In this paper, we propose a deep learning-based algorithm to improve the performance of automatic speech recognition (ASR) systems for aphasia, apraxia, and dysarthria speech by utilizing electroencephalography (EEG) features recorded synchronously with aphasia, apraxia, and dysarthria speech. We demonstrate a significant decoding performance improvement by more than 50% during test time for isolated speech recognition task and we also provide preliminary results indicating performance improvement for the more challenging continuous speech recognition task by utilizing EEG features. The results presented in this paper show the first step towards demonstrating the possibility of utilizing non-invasive neural signals to design a real-time robust speech prosthetic for stroke survivors recovering from aphasia, apraxia, and dysarthria. Our aphasia, apraxia, and dysarthria speech-EEG data set will be released to the public to help further advance this interesting and crucial research.",9-Dec-21
1660840,Hmm-Based and Svm-Based Recognition of the Speech of Talkers With Spastic Dysarthria,"This paper studies the speech of three talkers with spastic dysarthria caused by cerebral palsy. All three subjects share the symptom of low intelligibility, but causes differ. First, all subjects tend to reduce or delete word-initial consonants; one subject deletes all consonants. Second, one subject exhibits a painstaking stutter. Two algorithms were used to develop automatic isolated digit recognition systems for these subjects. HMM-based recognition was successful for two subjects, but failed for the subject who deletes all consonants. Conversely, digit recognition experiments assuming a fixed word length (using SVMs) were successful for two subjects, but failed for the subject with the stutter.",24-Jul-06
5495563,Design of a dysarthria classifier using global statistics of speech features,"Dysarthria is a neurological disorder in which the speech production system is impaired. There are five main types of dysarthrias depending on the location of the lesion in the nervous system. There is evidence suggesting a relationship between the location of the lesion and the resulting speech characteristics. This paper describes a non-intrusive classifier to identify the dysarthria type in a person using global statistics, e.g., mean, variance, etc., of speech features. A tree-based classifier was developed using multiple low-level maximum likelihood classifiers as inputs. An error of 10.5% was achieved in the classification of three types of dysarthrias.",28-Jun-10
10157285,Dysarthria Speech Disorder Classification Using Traditional and Deep Learning Models,"Dysarthria is a motor speech disorder that results in speech difficulties due to the weakness of associated muscles. This unclear speech makes it difficult for dysarthric patients to present himself understood. This neurological limitation is usually occurs due to damages to the brain or central nervous system. Speech therapy can be effectively employed to enhance the range and consistency of voice production and improve intelligibility and communicative effectiveness. Assessing the degree of severity of dysarthria provides vital information on the patient's progress which inturn assists pathologists in arriving at a treatment plan that includes developing automated voice recognition system suitable for dysarthria patients. This work performs an exhaustive study on dysarthria severity level classification using deep neural network (DNN) and convolution neural network (CNN) architectures. Mel Frequency Cepstral Coefficients (MFCCs) and their derivatives constitute feature vectors for classification. Using the UA-Speech database, the performance metrics of DNN/CNN based learning models have been compared to baseline classifiers like support vector machine (SVM) and Random Forest (RF). The highest classification accuracy of 97.6\% is reported for DNN under UA speech database. A detailed examination of the performance from the models discussed above reveal that appropriate choice of deep learning architecture ensures better results than traditional classifiers like SVM and Random Forest.",26-Jun-23
10527645,Harnessing Deep Learning Techniques for Dysarthria Detection,"Dysarthria, a motor speech disorder resulting from neurological impairments. This study explores various approaches for the automated detection of dysarthria, integrating both traditional and emerging technologies. Speech assessments by acoustic analysis, machine learning models, and deep learning techniques are considered. Machine learning models are trained on datasets containing normal and dysarthric speech for males and females, while deep learning methods, including convolutional and recurrent neural networks, are employed to automatically learn features from speech data. Our goal is to develop a reliable and accessible dysarthria detection system thatcomplements the expertise of healthcare professionals. Validation using diverse datasets is emphasized, acknowledging the importance of early detection and intervention in improving outcomes for individuals with dysarthria.",16-May-24
10696797,Next-Gen Speech Disorder Diagnostics: CNN Methods for Dysarthria Classification,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. Dysarthria has a significant impact on communication capacity, making early diagnosis essential for effective therapies and improved patient outcomes. The research used a Convolutional Neural Network (CNN) to categorise speech using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. There are 500 samples from each gender in the collection, representing dysarthric and non-dysarthric people who were recorded during different sessions. Highlighting the promise of deep learning technology in aiding early identification of dysarthria and enabling rapid therapy for affected individuals, the CNN-based approach exhibits an amazing 96% accuracy in discriminating between dysarthric and non-dysarthric cases. This study offers a promising chance to enhance the quality of life for those with speech impairments while also making substantial contributions to the development of diagnostic capabilities.",4-Oct-24
10730941,Advancing Speech Disorder Diagnostics: CNN Innovations in Dysarthria Recognition,"Neurological disorders such as amyotrophic lateral sclerosis (ALS) and cerebral palsy (CP) are common causes of dysarthria, the subject of this research article. The capacity to communicate is greatly affected by dysarthria, thus early diagnosis is critical for effective therapies and improved patient outcomes. The study employed a Convolutional Neural Network (CNN) for speech classification using the TORGO database, which includes 2000 samples of individuals with and without dysarthria, representing different genders. With 500 samples each, collected over distinct sessions, the dataset contains both dysarthric and non-dysarthric people of both sexes. Distinguishing between dysarthric and non-dysarthric occurrences, the CNN-based approach achieves an astonishing 96% accuracy. This shows how deep learning technology may help with early dysarthria identification and enable rapid therapy for affected individuals. The findings of this study have important implications for the development of diagnostic tools and may lead to better living conditions for those who struggle with speaking.",29-Oct-24
10340908,A preliminary study on self-care telemonitoring of dysarthria in spinal muscular atrophy,"Spinal muscular atrophy (SMA) is a rare neuromuscular disease which may cause impairments in oro-facial musculature. Most of the individuals with SMA present bulbar signs such as flaccid dysarthria which mines their abilities to speak and, as consequence, their psychic balance. To support clinicians, recent work has demonstrated the feasibility of video-based techniques for assessing the oro-facial functions in patients with neurological disorders such as amyotrophic lateral sclerosis. However, no work has so far focused on automatic and quantitative monitoring of dysarthria in SMA. To overcome limitations this work¡¯s aim is to propose a cloud-based store-and-forward telemonitoring system for automatic and quantitative evaluation of oro-facial muscles in individuals with SMA. The system integrates a convolutional neural network (CNN) aimed at identifying the position of facial landmarks from video recordings acquired via a web application by an SMA patient.Clinical relevance¡ª The proposed work is in the preliminary stage, but it represents the first step towards a better understanding of the bulbar-functions¡¯ evolution in patients with SMA.",11-Dec-23
9414283,"Automatic And Perceptual Discrimination Between Dysarthria, Apraxia of Speech, and Neurotypical Speech","Automatic techniques in the context of motor speech disorders (MSDs) are typically two-class techniques aiming to discriminate between dysarthria and neurotypical speech or between dysarthria and apraxia of speech (AoS). Further, although such techniques are proposed to support the perceptual assessment of clinicians, the automatic and perceptual classification accuracy has never been compared. In this paper, we investigate a three-class automatic technique and a set of handcrafted features for the discrimination of dysarthria, AoS and neurotypical speech. Instead of following the commonly used One-versus-One or One-versus-Rest approaches for multi-class classification, a hierarchical approach is proposed. Further, a perceptual study is conducted where speech and language pathologists are asked to listen to recordings of dysarthria, AoS, and neurotypical speech and decide which class the recordings belong to. The proposed automatic technique is evaluated on the same recordings and the automatic and perceptual classification performance are compared. The presented results show that the hierarchical classification approach yields a higher classification accuracy than baseline One-versus-One and One-versus-Rest approaches. Further, the presented results show that the automatic approach yields a higher classification accuracy than the perceptual assessment of speech and language pathologists, demonstrating the potential advantages of integrating automatic tools in clinical practice.",13-May-21
